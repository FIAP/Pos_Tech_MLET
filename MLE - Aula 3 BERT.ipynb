{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c310fd9a-0ec2-4ca2-a0fd-1d00af2f8de0",
   "metadata": {},
   "source": [
    "# BERT\n",
    "\n",
    "BERT, Bidirectional Encoder Representatios from Transformers, é um outro tipo de modelo de representação de linguagem. Foi introduzido em 2018 pelo Google e seu artigo pode ser consultado aqui: [link](https://arxiv.org/pdf/1810.04805)\n",
    "\n",
    "Três razões principais tornam o BERT um dos grandes avanços em NLP:\n",
    "\n",
    "1. demonstra um sofisticado conhecimento de linguagem, atingindo performance humana em algumas tarefas\n",
    "2. pode ser aplicado numa variedade de tarefas\n",
    "3. oferece o benefício de pré-treino + fine-tuning: o BERT foi treinado pelo Google num corpus de texto muito grande e você pode se apoderar desse conhecimento de linguagem tomando o modelo pré-treinado e aplicar o fine-tuning em sua própria aplicação. \n",
    "\n",
    "Entretanto, não estamos ainda no nível de por o BERT em qualquer problema e esperar grandes resultados. Assim, o objetivo dessa aula será o de fornecer o entendimento de como BERT funciona e o que ele pode ou não pode fazer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c3b82f-aea7-4900-97fe-85824c7d3a69",
   "metadata": {},
   "source": [
    "## Pre-training e Fine-tuning\n",
    "\n",
    "Antes de adentrarmos em como o BERT funciona é importante que tenhamos conceitos claros do que é **pre-training** e **fine-tuning**, o que, combinados, formam a técnica que chamamos de *transfer learning*. \n",
    "\n",
    "Quando estudamos o BERT, vemos que as duas principais contribuições são essas duas:\n",
    "\n",
    "1. *Masked Language Model (MLM)*\n",
    "2. *Next Sentence Prediction (NSP)*\n",
    "\n",
    "Considere o seguinte exemplo sobre essas duas atividades:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df57ca1d-d9e7-45f0-9421-74f104e03a94",
   "metadata": {},
   "source": [
    "<img src=\"img/MLM_NSP.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3477215-aaea-4fed-a0c6-fbf341280a96",
   "metadata": {},
   "source": [
    "Isto é que o BERT deve fazer: \n",
    "\n",
    "1. MLM - predizer a palavra tracejada (simple)\n",
    "2. NSP - a sentença B (laranja) foi encontrada imediatamente depois da sentenca A (azul) ou em outro lugar? O BERT deveria retornar que elas são consecutivas.\n",
    "\n",
    "Extrapolando, o BERT foi treinado para executar essas duas tarefas puramente como uma forma de forçar um sofisticado entendimento da linguagem. \n",
    "\n",
    "Mas o BERT não seria tão interessante se tudo o que ele pode fazer fosse predizer palavras faltantes (MLM) e dizer se duas sentenças são consecutivas ou não. A principal parte do BERT é uma rede neural de 12 camadas extensa que processa texto. O MLM e o NSP adicionam, cada um, uma única camada de classificação ao output do BERT para executar suas respectivas atividades. \n",
    "\n",
    "Observe a ilustração abaixo que mostra que o mesmo modelo BERT pré-treinado pode ser usada para executar Análise de Sentimento ou Extração de Entidade Nomeada (NER) com a única diferença sendo a camada final do modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e1cceb-6c03-4b58-a0dc-ab9dcfbd6855",
   "metadata": {},
   "source": [
    "<img src=\"img/bert_tasks.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca3d754-f436-47c3-87be-88b25c732fc3",
   "metadata": {},
   "source": [
    "Assim, por exemplo, se você deseja aplicar o BERT para uma tarefa específica de classificação de texto, você deveria pegar o modelo BERT pré-treinado, adicionar uma camada de neurônios não treinados no final e treinar o novo modelo combinado no seu dataset. Este passo final é denominado *fine-tuning*, visto que a quantidade de treino requirido para adaptar o BERT para sua tarefa é muito pequena quando comparada ao tempo que a Google gastou para treinar o BERT. Mesmo assim, a tarefa fine-tuning é custosa computacionalmente falando. \n",
    "\n",
    "Dessa maneira, esta técnica de adicionar uma pequena tarefa específica ao final de um grande modelo pré-treinado e aplicar fine-tuning ao resultado é conhecido como **Transfer Learning**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc31423a-aaaa-4925-9abb-2a077591c1dc",
   "metadata": {},
   "source": [
    "Mas afinal, por qual motivo usar Transfer Learning ao invés de treinar diretamente um modelo de deep learning? Exsitem três principais razões:\n",
    "\n",
    "1. **Desenvolvimento rápido:** como já há uma quantidade massiva de dados treinados, os autores recomendam de 2 a 4 épocas de treinamento para fine-tuning do BERT para uma tarefa específica. \n",
    "\n",
    "2. **Menos dados:** visto que a grande maioria de dados já foi usada para treinar o BERT\n",
    "\n",
    "3. **Melhores resultados:** este procedimento de fine-tuning demonstrou atingir resultados do estado-da-arte em tarefas como classificação, QA, similaridade semântica, entre outros. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aff093-c0d7-4c53-b85b-8332d0e7678d",
   "metadata": {},
   "source": [
    "### Formato de Input e Output do BERT\n",
    "\n",
    "Antes de entrar nos detalhes da arquitetura interna do BERT, é importante ter uma clara ideia de como o BERT faz a ingestão de texto e o que exatamente ele retorna. \n",
    "\n",
    "O primeiro passo é o **tokenizer**, que toma um texto limpo e o divide em tokens que o BERT faz ingestão. O motivo do BERT prover seu próprio tokenizer é que ele possui um vocabulário fixo de tokens, com um embedding associado a cada um. Mas ai surge uma questão: como ele lida com palavras que não estão no vocabulário? Ai entra em cena o segundo passo: **lidando com palavras fora do vocabulário**. \n",
    "\n",
    "Se uma palavra não está presente no vobabulário do BERT ele quebra ela em sub-palavras. E, se mesmo assim as sub-palavras não estiverem no vocabulário, o BERT pode as quebrar em caracteres individuais. Cada sub-palavra ou caracter individual se torna um token separado, representado por seu próprio embedding. Além disso, o BERT possui tokens para representar caracteres de pontuação e a única coisa que ele descarta no processo de tekenização é o espaço em branco. \n",
    "\n",
    "Assim, quando aplicamos o BERT a um pedaço de texto, o tokenizer irá dividir o texto em tokens, procurar os embeddings desses tokens e estes serão os reais inputs do BERT, sendo cada um deles composto por 768 features. De maneira bem simples, o que o BERT faz é tomar esses embeddings como input e solta como output uma versão melhorada desses embeddings. \n",
    "\n",
    "E para entender como o BERT cria essa versão melhorada de uma única palavra (embedding), considere o exemplo abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bd044a-4e58-4238-a419-e64ae27b1b40",
   "metadata": {},
   "source": [
    "<img src=\"img/input_melhorado.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f474c20-ccaf-451d-964b-84f4aaa15504",
   "metadata": {},
   "source": [
    "Entretanto, na prática, o BERT processa cada palavra independentemente e, por isso, é possível paralelizar o processo e executar todas as palavras de input através do BERT \"de uma só vez\". Veja a imagem abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddbb315-f6dc-4ccc-b87b-9d456b31918b",
   "metadata": {},
   "source": [
    "<img src=\"img/bert_paralel.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca765db-74cc-4ae0-9ba8-9a7ee3d4c500",
   "metadata": {},
   "source": [
    "Essa rede de conexões ilustra que, para cada palavra de input, vamos incorporar todos os embeddings das outras palavras também.\n",
    "\n",
    "Esse processo de pegar um conjunto de embeddings e melhorá-lo é, na verdade, repetido 12 vezes no BERT, como pode ser visto na imagem abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db17f27-5a1e-4bd6-9e58-3f2588576cab",
   "metadata": {},
   "source": [
    "<img src=\"img/12_layers.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333bd15d-0099-4b54-b9d3-1613ff7f199c",
   "metadata": {},
   "source": [
    "Esse processo ilustra alguns aspectos importantes do BERT:\n",
    "\n",
    "* a \"rede de conexão\" mostra que todas as palavras são incorporadas em processar cada palavra\n",
    "* a mesma arquitetura é aplicada a cada palavra em paralelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d8f175-0492-4157-96f1-50dfc03a3dc4",
   "metadata": {},
   "source": [
    "Um ponto importante a ser dito é que o arranjo de palavras do exemplo acima, em que elas aparcem na ordem de uma correta sentença, não é uma necessidade do BERT. Na realidade, o BERT não posssui nenhum conhecimento explícito da ordem da palavra. Entretanto, ele requer alguma noção de ordem da palavra e a maneira como ele faz isso é bastante particular. O BERT possui um conjunto de 512 embeddings conhecidos como **positional encoding (PE)**, que simplesmente somamos ao embedding da palavra correspondente, conforme ilustração a seguir:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27e924f-f62e-4066-868a-d6547035a40c",
   "metadata": {},
   "source": [
    "<img src=\"img/PE.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63b88ad-b7d7-4842-93f8-fc8f43ce6975",
   "metadata": {},
   "source": [
    "Importante notar que o PE é adicionado apenas antes da primeira camada e não entre quaisquer outras camadas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77520c55-ce75-4c04-bbfc-97bd2a275d44",
   "metadata": {},
   "source": [
    "## Arquitetura do BERT\n",
    "\n",
    "Até aqui, sabemos como o BERT tokeniza o texto e sabemos que ele produz um conjunto melhorado de embeddings para cada token, mas qual o mecanismo por trás desse processo de melhora? Como o BERT realmente dá sentido a linguagem?\n",
    "\n",
    "A arquitetura do BERT vem diretamente da arquitetura do Transformer - que está mais bem explicada no material de apoio e será objetivo de estudo na disciplina de IA Generativa. A parte mais importante dessa arquitetura é uma técnica denominada **Self-attention**.\n",
    "\n",
    "Anteriormente, analisamos o exemplo abaixo em que comentamos que, ao melhorar o embedding da palavra \"like\", também incorporamos os embeddings de outras palavras na sentença. \n",
    "\n",
    "Self-attention é o pedaço que realiza essa incorporação de outros embeddings.\n",
    "\n",
    "Quando produz um embedding melhorado para uma palavra, self-attention irá pegar a média ponderada dos embeddings de outras palavras de contexto. O peso do self-attention atribui para cada palavra de contexto o quanto de atenção que será dada a essa palavra de contexto. Considere o seguinte exemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61835b9-f07f-4eb5-8d6d-b3cef3938b8b",
   "metadata": {},
   "source": [
    "<img src=\"img/self_attention.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34b6a4f-8427-4b72-a739-70dd3daf8856",
   "metadata": {},
   "source": [
    "Ao processar a palavra \"he\", self-attention fornece pesos para as diferentes palavras na sentença (quanto mais escuro o tom, maior o peso). Neste caso, BERT está focando primeiramente no nome do personagem a quem \"he\" se refere - \"Bert\". \n",
    "\n",
    "Algumas notas importantes: \n",
    "\n",
    "1. Será atribuído um peso a cada palavra\n",
    "2. O embedding para a palavra de input é incluído na média ponderada\n",
    "3. Os pesos são calculados com a função SoftMax\n",
    "\n",
    "Assim, o resultado de uma palavra melhorada é dado pela seguinte função:\n",
    "\n",
    "$\\bar{x} = \\sum_{i=1}^{n} w_i x_i$\n",
    "\n",
    "em que:\n",
    "\n",
    "* $n$ é o número de palavras na sentença\n",
    "* $i$ é a posição da palavra na sentença\n",
    "* $x_i$ é o embedding da palavra na posição $i$\n",
    "* $w_i$ é o valor do peso dado a palavra na posição $i$\n",
    "* $\\bar{x}$ é o embedding melhorado da palavra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cd8972-a682-4c18-9d64-6c3c2030d6ab",
   "metadata": {},
   "source": [
    "Então, como calculamos os pesos que serão atribuídos a cada palavra numa sentença? Essencialmente, iremos calcular o produto escalar da palavra de input pela palavra de contexto, que é a que queremos determinar o peso. Isso será feito para todas as palavras de contexto, passa por uma função SoftMax e obteremos nossos pesos, conforme detalhado na imagem abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99cf222-a455-461f-bea0-a34447666060",
   "metadata": {},
   "source": [
    "<img src=\"img/calculo_pesos.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7128e02-fdcc-407c-9113-24952008e503",
   "metadata": {},
   "source": [
    "Dentro de uma única camada do BERT, existe mais um componente relevante depois do self-attention: uma rede neural de 3 camadas, referenciada como Feed Forward Neural Network no paper original. A imagem abaixo ilustra essa rede:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1d6f9-f1ab-4ab2-add6-21e9c200a8b3",
   "metadata": {},
   "source": [
    "<img src=\"img/ffn.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce6bff-df54-44de-943f-ca57734175b2",
   "metadata": {},
   "source": [
    "A convenção adotada no paper tanto do Transformer quanto do BERT foi de configurar o número de neurônios na camada oculta como sendo 4x o tamanho do embedding. Assim $4x768 = 3072$ neurônios ocultos. Além disso, a função de ativação GeLu (mais detalhes [aqui](https://medium.com/@shauryagoel/gelu-gaussian-error-linear-unit-4ec59fb2e47c)) e essa FFN é responsável pela maior parte dos pesos do BERT. \n",
    "\n",
    "Mas anteriormente dissemos que o BERT possui 12 camadas e cada uma delas é responsável por prestar atenção numa determinada porção do texto, ou, tecnicamente dizendo, cada uma responsável por executar uma função. Esse mecanismo é conhecido como **Multi-headed attention**. Dessa, uma única palavra de input será executada, junto com suas palavras de contexto, através de 12 únicas instâncias de self-attention, o que, consequentemente, gera 12 únicos embeddings melhorados. Assim, fica a questão: como combinar esses 12 resultados em apenas um? \n",
    "\n",
    "Para resolver esse problema, adicionamos uma nova camada para melhor combinar esses 12 resultados num embedding de dimensão 768."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee85f3a7-8efb-47c8-8e8d-79a413192c2d",
   "metadata": {},
   "source": [
    "# Prática\n",
    "\n",
    "Vamos agora entender como aplicar o BERT a um problema de classificação de texto.\n",
    "\n",
    "Para construir um modelo de classificação de texto usando BERT, podemos aplicar duas estratégias (ligeiramente) diferentes. Como mencionado acima, o BERT é usado para codificar textos em um vetor. O modelo de classificação que construímos no BERT consiste em classificar esses vetores usando algoritmos de ML. Então, podemos:\n",
    "\n",
    "1. Aplicar BERT aos textos como etapas de pré-processamento e, em seguida, construir um modelo de ML que classifica esses vetores\n",
    "2. Construir um modelo que começa com BERT (onde congelamos os parâmetros ao treinar o modelo) e, em seguida, construir sobre o BERT uma camada que classifica esses vetores\n",
    "\n",
    "A vantagem do primeiro método é que precisamos passar o texto (dados de treinamento e teste) apenas uma vez pelo BERT, e não para cada época no treinamento, reduzindo significativamente o tempo de treinamento. A vantagem do segundo método é que não precisamos construir uma etapa adicional para o pipeline, uma vez que o de ponta a ponta (do texto à classificação) é fornecido pelo tokenizador e o próprio modelo.\n",
    "\n",
    "Para fins pedagógicos, usaremos a segunda abordagem. Em um caso real, a escolha da abordagem dependeria do uso do modelo. Se precisarmos treinar o modelo regularmente, eu preferiria a primeira abordagem. Se o modelo tiver que ser treinado apenas uma vez, eu escolheria a segunda abordagem.\n",
    "\n",
    "Usaremos o modelo DistilBERT da biblioteca Python transformers, que é fornecida pela empresa Hugging Face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96097ace-d3e1-4bdb-bb90-fd0e000dfaf1",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Vamos usar um pequeno dataset nessa prática: o BBC News, que consistem em aproximadamente 2000 amostras e pode ser obtido [aqui](https://www.kaggle.com/datasets/sainijagjit/bbc-dataset?resource=download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27641524-a1fa-4428-8555-e750c0d2f4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "\n",
    "# Download the dataset and put it in subfolder called data\n",
    "df = pd.read_csv(\"bases/bbc-text.csv\")\n",
    "df = df[[\"category\", \"text\"]]\n",
    "\n",
    "# Show the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4487c8-2ebf-44f6-95b4-7102306fe23f",
   "metadata": {},
   "source": [
    "Primeiro, vamos analisar os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e302e09-51fd-4057-91f8-52bafeef5b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of news: 2225\n",
      "----------------------------------------\n",
      "Split by category:\n",
      "sport            511\n",
      "business         510\n",
      "politics         417\n",
      "tech             401\n",
      "entertainment    386\n",
      "Name: category, dtype: int64\n",
      "----------------------------------------\n",
      "Number of categories: 5\n"
     ]
    }
   ],
   "source": [
    "print('Total number of news: {}'.format(len(df)))\n",
    "print(40*'-')\n",
    "print('Split by category:')\n",
    "print(df[\"category\"].value_counts())\n",
    "print(40*'-')\n",
    "nr_categories = len(df[\"category\"].unique())\n",
    "print(\"Number of categories: {n}\".format(n=nr_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b753f7c-e152-41dd-987f-4c840a1141a3",
   "metadata": {},
   "source": [
    "Obtemos um número total de entradas de 2.225, que são relativamente uniformemente divididas em cinco classes. Isso nos permite aplicar métodos padrão, pois não há necessidade de super ou subponderar algumas classes.\n",
    "\n",
    "Finalmente, vamos dar uma olhada em um exemplo específico para ter uma impressão concreta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df660dcf-eb30-4c0c-8e2b-0856b61b49a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category:  entertainment\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Text:\n",
      "housewives lift channel 4 ratings the debut of us television hit desperate housewives has helped lift channel 4 s january audience share by 12% compared to last year.  other successes such as celebrity big brother and the simpsons have enabled the broadcaster to surpass bbc two for the first month since last july. bbc two s share of the audience fell from 11.2% to 9.6% last month in comparison with january 2004. celebrity big brother attracted fewer viewers than its 2002 series.  comedy drama desperate housewives managed to pull in five million viewers at one point during its run to date  attracting a quarter of the television audience. the two main television channels  bbc1 and itv1  have both seen their monthly audience share decline in a year on year comparison for january  while five s proportion remained the same at a slender 6.3%. digital multi-channel tv is continuing to be the strongest area of growth  with the bbc reporting freeview box ownership of five million  including one million sales in the last portion of 2004. its share of the audience soared by 20% in january 2005 compared with last year  and currently stands at an average of 28.6%.\n"
     ]
    }
   ],
   "source": [
    "n=100\n",
    "print('Category: ',df['category'][n])\n",
    "print(100*'-')\n",
    "print('Text:')\n",
    "print(df['text'][n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd850c43-1bb8-4f9f-8f94-6813078ca612",
   "metadata": {},
   "source": [
    "As labels precisam ser convertidas para números. Vamos fazer isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3357353b-9f8a-4f54-ad41-0fb467b738da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 3 ... 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "X = df['text']\n",
    "y=np.unique(df['category'], return_inverse=True)[1]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ead568-aa0a-49dd-998d-97970c7b0774",
   "metadata": {},
   "source": [
    "Vamos instanciar o tokenizer do BERT que será usado posteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95cb2ce0-9ae9-4aa2-b75d-2726c9c63684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f70c3-af96-4882-8467-8ebcca042816",
   "metadata": {},
   "source": [
    "### Preparando o Datset\n",
    "\n",
    "Em uma primeira etapa, converteremos o conjunto de dados em tensores do pytorch, depois os empacotaremos em uma classe Dataset e, finalmente, incorporaremos o Dataset em um Dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "309dc0e8-932b-44ba-8f46-c7f496b7e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_list=X.to_list()\n",
    "X_pt = tokenizer(X_list, padding='max_length', max_length = 512, truncation=True, return_tensors='pt')[\"input_ids\"]\n",
    "\n",
    "y_list=y.tolist()\n",
    "y_pt = torch.Tensor(y_list).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9c6d160-4a45-483d-9127-513383d0629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pt_train, X_pt_test, y_pt_train, y_pt_test = train_test_split(X_pt, y_pt, test_size=0.3, random_state=42, stratify=y_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb5b05f-3dc9-463c-ac83-5423ffdf71cc",
   "metadata": {},
   "source": [
    "Criamos uma classe Dataset e instanciaremos os conjuntos de dados de treinamento e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f045edb6-79f0-4ea2-ab19-5526067c437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class BBCNewsDataset(Dataset):\n",
    "    \"\"\"Custom-built BBC News dataset\"\"\"\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X, y as Torch tensors\n",
    "        \"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_train[idx], self.y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d8108e-1df1-437c-bb25-0dd0700122d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtém conjunto de treino e teste no formato Dataset\n",
    "train_data_pt = BBCNewsDataset(X=X_pt_train, y=y_pt_train)\n",
    "test_data_pt = BBCNewsDataset(X=X_pt_test, y=y_pt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5725a4-c278-402a-aa83-c32fc84f0535",
   "metadata": {},
   "source": [
    "Incorporamos o dataset em um Dataloader para preparar o dataset para ser usado para treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffc23b65-e76c-4224-9218-2ae5dadd912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_pt = DataLoader(train_data_pt, batch_size=32)\n",
    "test_loader_pt = DataLoader(test_data_pt, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ced3b2-d449-40db-8844-76f69337cc72",
   "metadata": {},
   "source": [
    "### Construindo o modelo\n",
    "\n",
    "Vamos construir o modelo. Para isso, primeiro precisamos obter a camada BERT da biblioteca do Transformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63b17a9c-66a9-4944-8559-53dbe3c40f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "config = transformers.DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
    "dbert_pt = transformers.DistilBertModel.from_pretrained('distilbert-base-uncased', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d5aec4-189c-4cae-81d8-47e5cc14a74c",
   "metadata": {},
   "source": [
    "Vamos tentar entender melhor esse modelo dando uma olhada mais de perto em sua saída. Para isso, vamos pegar uma amostra do nosso conjunto de dados de treinamento (pegamos uma amostra de tamanho cinco) e olhar a saída por meio do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "935ddbcc-cb54-4ecd-a9a6-1a1e0c8a5bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type:  <class 'transformers.modeling_outputs.BaseModelOutput'>\n",
      "Output format (shape):  torch.Size([5, 512, 768])\n",
      "Output used as input for the classifier (shape):  torch.Size([5, 768])\n"
     ]
    }
   ],
   "source": [
    "sample = X_pt_train[0:5]\n",
    "print('Object type: ', type(dbert_pt(sample)))\n",
    "print('Output format (shape): ',dbert_pt(sample)[0].shape)\n",
    "print('Output used as input for the classifier (shape): ', dbert_pt(sample)[0][:,0,:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8c2b3e-2d7b-4012-a0a8-516d729b84a3",
   "metadata": {},
   "source": [
    "A saída é um objeto Python específico. Entre outras informações, obtemos um Tensor de tamanho (N, M, S), onde N é o tamanho do conjunto de dados (no nosso caso, cinco exemplos), M é o comprimento da amostra (número de palavras no texto) e S é o tamanho do vetor de saída (a saída do modelo). Normalmente, para uma tarefa de classificação, usamos o primeiro vetor de saída de uma frase como entrada para o restante do modelo de classificação, já que esse primeiro vetor \"codifica\" informações sobre a frase geral. Alternativamente, uma média de agrupamento de todos os vetores de saída também pode ser usada como entrada para o classificador.\n",
    "\n",
    "Agora é hora de construir o modelo de classificação! Ele consistirá em:\n",
    "\n",
    "* Modelo Distil Bert: para codificar os dados de entrada em uma nova sequência de vetores (que é a saída do BERT). Apenas o primeiro vetor desta sequência será usado como entrada para o resto do classificador\n",
    "* Camada de Dropout: para regularização\n",
    "* Camada densa (com função de ativação relu, com 64 neurônios): para resolver o problema específico de classificação\n",
    "* Camada densa (com função de ativação softmax): para uma distribuição de probabilidade para cada rótulo\n",
    "\n",
    "A camada de Dropout é usada apenas durante o treinamento. Alguns links entre as camadas são definidos como zero de propósito, para que seus \"vizinhos\" assumam seu papel. Isso torna a previsão geral mais robusta. Ao usar o modelo para inferência (predição), as camadas de abandono são ignoradas e a saída é redimensionada de acordo. Observe que esta é uma das razões pelas quais temos que informar ao modelo se ele está em modo de treinamento ou avaliação.\n",
    "\n",
    "No PyTorch, precisamos definir as camadas e, em seguida, definir uma função de avanço que faça uso das camadas. Cada camada obtém o tamanho de entrada e o tamanho de saída como parâmetros de configuração, então as informações sobre as dimensões dos tensores já estão contidas no próprio modelo. Por exemplo, a camada \"linear1\" obtém um vetor de tamanho 768 como entrada e retorna um vetor de tamanho 64 como saída. Esses dois números são parte de sua definição. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45c4951f-df3b-4e90-a519-39626b4d3887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class DistilBertClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistilBertClassification, self).__init__()\n",
    "        self.dbert = dbert_pt\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.linear1 = nn.Linear(768,64)\n",
    "        self.ReLu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(64,5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dbert(input_ids=x)\n",
    "        x = x[\"last_hidden_state\"][:,0,:]\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.ReLu(x)\n",
    "        logits = self.linear2(x)\n",
    "        # No need for a softmax, because it is already included in the CrossEntropyLoss\n",
    "        return logits\n",
    "\n",
    "model_pt = DistilBertClassification().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e950d3f5-65ea-4acf-a83e-a09cd4559ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertClassification(\n",
      "  (dbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (linear1): Linear(in_features=768, out_features=64, bias=True)\n",
      "  (ReLu): ReLU()\n",
      "  (linear2): Linear(in_features=64, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff1298-92f2-4afa-96e6-330c4d06900a",
   "metadata": {},
   "source": [
    "Ainda precisamos definir os parâmetros da parte BERT do modelo como \"não treinável\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffc460cb-0141-440c-9440-c7d8438321fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_pt.dbert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc6f79-d068-4db5-8ad9-d0736e6ce325",
   "metadata": {},
   "source": [
    "Vejamos o número de parâmetros (treináveis e não treináveis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67c1ef93-1876-4ee4-b2bf-727596725ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  66412421\n",
      "Number of trainable parameters:  49541\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model_pt.parameters())\n",
    "total_params_trainable = sum(p.numel() for p in model_pt.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \", total_params)\n",
    "print(\"Number of trainable parameters: \", total_params_trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa8e21-3ca9-44c3-8c73-18b513581eed",
   "metadata": {},
   "source": [
    "Vamos verificar rapidamente se o número de parâmetros treináveis (que estão apenas nas camadas densas, BERT sendo \"congelado\") faz sentido. O vetor que sai do BERT é um vetor de tamanho 768 (por definição do modelo BERT). Cada um desses elementos está vinculado a cada um dos 64 neurônios da camada densa, levando a 768x64=49152 parâmetros. Cada neurônio tem um parâmetro adicional, o bias, ou seja, 64 parâmetros. A saída da camada densa consiste em 64 elementos, que se conectam a todos os cinco elementos da camada de classificação, ou seja, 64x5. A camada de classificação também tem 5 bias.\n",
    "\n",
    "No total, o número de parâmetros treináveis é: 768x64+64+64*5+5 = 49541! Chegamos lá :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d9b56d-1014-4573-ba61-f1c4701a3d01",
   "metadata": {},
   "source": [
    "### Treinando o Modelo\n",
    "\n",
    "Agora é hora de treinar o modelo! Vamos fazer isso tendo em mente que queremos medir o desempenho (tanto em termos de acurácia quanto de tempo de treinamento), então vamos colocar a medição em prática.\n",
    "\n",
    "No Pytorch, precisamos definir um loop de treinamento, que fará um loop em épocas (alto nível) e lotes (baixo nível). Mas, ao codificar os loops de treinamento nós mesmos, isso nos dá total transparência sobre o que está sendo feito!\n",
    "\n",
    "Queremos rastrear o progresso do treinamento e, por isso, introduzimos o dicionário \"history\", que coleta vários indicadores-chave de desempenho durante o treinamento.\n",
    "\n",
    "Antes de começarmos o treinamento, precisamos configurar o número de épocas, o critério (qual é a função a ser minimizada) e o otimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57d6ca0d-4322-4898-95b2-4282c7199a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_pt.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36b0f9ea-acfb-4760-8698-f92fa2423f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 49/49 [22:38<00:00, 27.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t\t Training Loss:      1.133 \t\t Validation Loss:      0.615\n",
      "\t\t Training Accuracy:    63.712% \t\t Validation Accuracy:    88.473%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 49/49 [23:33<00:00, 28.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 \t\t Training Loss:      0.458 \t\t Validation Loss:      0.252\n",
      "\t\t Training Accuracy:    91.458% \t\t Validation Accuracy:    94.611%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 49/49 [22:56<00:00, 28.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 \t\t Training Loss:      0.257 \t\t Validation Loss:      0.164\n",
      "\t\t Training Accuracy:    94.605% \t\t Validation Accuracy:    95.359%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 49/49 [22:49<00:00, 27.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 \t\t Training Loss:      0.192 \t\t Validation Loss:      0.129\n",
      "\t\t Training Accuracy:    94.926% \t\t Validation Accuracy:    95.808%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 49/49 [23:14<00:00, 28.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 \t\t Training Loss:      0.151 \t\t Validation Loss:      0.113\n",
      "\t\t Training Accuracy:    96.146% \t\t Validation Accuracy:    95.958%\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Define o dicionário \"history\" que irá coletar indicadores de performance durante o treino\n",
    "history = {}\n",
    "history[\"epoch\"]=[]\n",
    "history[\"train_loss\"]=[]\n",
    "history[\"valid_loss\"]=[]\n",
    "history[\"train_accuracy\"]=[]\n",
    "history[\"valid_accuracy\"]=[]\n",
    "\n",
    "# Mensura o tempo para treinamento\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Loop nas épocas\n",
    "for e in range(epochs):\n",
    "    \n",
    "    # Configura o modo para treino\n",
    "    model_pt.train()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    train_accuracy = []\n",
    "    \n",
    "    # itera sobre os batches\n",
    "    for X, y in tqdm(train_loader_pt):\n",
    "        \n",
    "        # Obtém predições e Loss\n",
    "        prediction = model_pt(X)\n",
    "        loss = criterion(prediction, y)\n",
    "        \n",
    "        # Ajusta os parametros do modelo\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        prediction_index = prediction.argmax(axis=1)\n",
    "        accuracy = (prediction_index==y)\n",
    "        train_accuracy += accuracy\n",
    "    \n",
    "    train_accuracy = (sum(train_accuracy) / len(train_accuracy)).item()\n",
    "    \n",
    "    # Calcula a loss no conjunto de teste depois de cada época\n",
    "    # Configura o modo para avaliacao\n",
    "    model_pt.eval()\n",
    "    valid_loss = 0.0\n",
    "    valid_accuracy = []\n",
    "    for X, y in test_loader_pt:\n",
    "         \n",
    "        prediction = model_pt(X)\n",
    "        loss = criterion(prediction, y)\n",
    "\n",
    "        valid_loss += loss.item()\n",
    "        \n",
    "        prediction_index = prediction.argmax(axis=1)\n",
    "        accuracy = (prediction_index==y)\n",
    "        valid_accuracy += accuracy\n",
    "    valid_accuracy = (sum(valid_accuracy) / len(valid_accuracy)).item()\n",
    "    \n",
    "    history[\"epoch\"].append(e+1)\n",
    "    history[\"train_loss\"].append(train_loss / len(train_loader_pt))\n",
    "    history[\"valid_loss\"].append(valid_loss / len(test_loader_pt))\n",
    "    history[\"train_accuracy\"].append(train_accuracy)\n",
    "    history[\"valid_accuracy\"].append(valid_accuracy)    \n",
    "        \n",
    "    print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss / len(train_loader_pt) :10.3f} \\t\\t Validation Loss: {valid_loss / len(test_loader_pt) :10.3f}')\n",
    "    print(f'\\t\\t Training Accuracy: {train_accuracy :10.3%} \\t\\t Validation Accuracy: {valid_accuracy :10.3%}')\n",
    "    \n",
    "# Mensura tempo de treinamento\n",
    "end_time = datetime.now()\n",
    "training_time_pt = (end_time - start_time).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81e3ba8d-e1c5-4be7-9fdd-d5c4a43cf8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc8cb082f20>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "ax[0].set(title='Loss')\n",
    "ax[0].plot(history['train_loss'], label='Training')\n",
    "ax[0].plot(history['valid_loss'], label='Validation')\n",
    "ax[0].legend(loc=\"upper right\")\n",
    "\n",
    "ax[1].set(title='Accuracy')\n",
    "ax[1].plot(history['train_accuracy'], label='Training')\n",
    "ax[1].plot(history['valid_accuracy'], label='Validation')\n",
    "ax[1].legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "027a24d0-5b7c-4e38-8335-ba8d64ec54f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training data: 96.1%\n",
      "Accuracy Test data: 96.0%\n",
      "Training time: 9043.7s (or 150.7 minutes)\n"
     ]
    }
   ],
   "source": [
    "accuracy_pt = history['valid_accuracy'][-1]\n",
    "print('Accuracy Training data: {:.1%}'.format(history['train_accuracy'][-1]))\n",
    "print('Accuracy Test data: {:.1%}'.format(history['valid_accuracy'][-1]))\n",
    "print('Training time: {:.1f}s (or {:.1f} minutes)'.format(training_time_pt, training_time_pt/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecf05a3-902a-4bb7-a65d-273abda94b61",
   "metadata": {},
   "source": [
    "A acurácia parece boa (>95%)! Também observamos que a acurácia aumenta com as épocas, e as acurácias de treino e validação são próximas uma da outra, o que significa que parece não haver overfitting. \n",
    "\n",
    "Nosso modelo está treinado! Para manter este modelo, vamos salvá-lo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f066ab-e44a-46ca-a785-cbdcb7f490cd",
   "metadata": {},
   "source": [
    "### Salvando o modelo\n",
    "\n",
    "Existem duas abordagens para salvar um modelo e abordaremos ambas nesta seção.\n",
    "\n",
    "É possível salvar apenas os parâmetros do modelo. Então, para carregar o modelo, primeiro teremos que instanciar o modelo (o modelo DistilBertClassification) e, em seguida, carregar todos os seus parâmetros (treinados) neste modelo. Esta é uma maneira conveniente de armazenar um modelo, no entanto, só é possível se você tiver detalhes completos sobre a arquitetura do modelo original.\n",
    "\n",
    "Uma alternativa é salvar o modelo inteiro. Ao fazer isso, é mais fácil carregar o modelo de seu local salvo. Vamos dar uma olhada nas duas abordagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf17508a-83ae-4ce6-8fd8-3f10ff9999fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertClassification(\n",
       "  (dbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (linear1): Linear(in_features=768, out_features=64, bias=True)\n",
       "  (ReLu): ReLU()\n",
       "  (linear2): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salve apenas os parâmetros do modelo, mas não o modelo em si, e recupere-o\n",
    "torch.save(model_pt.state_dict(), 'PyModel.sd')\n",
    "model_reloaded = DistilBertClassification()\n",
    "model_reloaded.load_state_dict(torch.load('PyModel.sd'))\n",
    "model_reloaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0573e55c-d8c9-4071-88be-a5bcad55eb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertClassification(\n",
       "  (dbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (linear1): Linear(in_features=768, out_features=64, bias=True)\n",
       "  (ReLu): ReLU()\n",
       "  (linear2): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salve o modelo todo e recupere-o\n",
    "torch.save(model_pt, 'PyModelComplete.pt')\n",
    "model_reloaded2 = torch.load('PyModelComplete.pt')\n",
    "model_reloaded2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510a6224-0317-4745-b9fe-7d76c3e35c0c",
   "metadata": {},
   "source": [
    "# O que você viu nessa aula?\n",
    "\n",
    "Nessa aula, apresentamos o BERT, um LLM que pode ser usado para várias tarefas em NLP. Dentre elas, apresentamos um caso para classificação de texto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46276c19-6002-4322-8e68-822516bbaba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
