{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Reconhecimento de Entidades Nomeadas (NER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos de Reconhecimento de Entidades Nomeadas visam extrair do texto informações categorizadas como:\n",
    "- Pessoa (PER): Nome de pessoas.\n",
    "- Organização (ORG): Empresas e instituições.\n",
    "- Localização (LOC): Cidades, países, regiões geográficas.\n",
    "- Miscellaneous (MISC): Outros, o que não for das categorias acima mas ainda assim for importante, como evento ou produtos.\n",
    "<br>A ideia do NER é classificar cada token dentro do texto entre uma dessas opções.\n",
    "<br><br>A forma de classificação mais comum é a Inside-Outside-Beginning (IOB):\n",
    "- B- (Beginning): Marca o início de uma entidade.\n",
    "- I- (Inside): Marca o token de dentro da entidade, contínuo ao anterior.\n",
    "- O (Outside): Marca um token que não faz parte de nenhuma entidade nomeada.\n",
    "<br>Nesse formato, o modelo tem todas as informações para distinguir de forma clara quando uma entidade nomeada começa e quando termina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando modelos pré-treinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/dhenyfernandes/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/dhenyfernandes/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/dhenyfernandes/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/dhenyfernandes/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE Bem/NNP)\n",
      "  vindos/VBZ\n",
      "  a/DT\n",
      "  aula/NN\n",
      "  de/FW\n",
      "  (ORGANIZATION Reconhecimento/NNP)\n",
      "  de/FW\n",
      "  (PERSON Entidades/NNP Nomeadas/NNP)\n",
      "  da/NN\n",
      "  (ORGANIZATION FIAP/NNP)\n",
      "  ministrada/NNP\n",
      "  pelo/NN\n",
      "  professor/NN\n",
      "  (PERSON Dheny/NNP Fernandes/NNP))\n"
     ]
    }
   ],
   "source": [
    "texto = \"Bem vindos a aula de Reconhecimento de Entidades Nomeadas da FIAP ministrada pelo professor Dheny Fernandes\"\n",
    "tokens = word_tokenize(texto) # separa o texto em tokens\n",
    "taggeado = pos_tag(tokens) # realiza o processo de POS-tagging\n",
    "entidades = ne_chunk(taggeado) # detecta as entidades\n",
    "print(entidades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLTK\n",
    "Modelo pré-treinado no idioma inglês.\n",
    "Podemos ver que ele se perde bastante no exemplo usado, classificando o \"Bem\" como GPE (localização), Reconhecimento como organização, mas também acertar em outras, como FIAP como Organização e Dheny Fernandes como pessoa.\n",
    "\n",
    "Ainda conseguimos usar mesmo que com um erro maior alguns modelos pré-treinados em outros idiomas, desde que eles possuam padrões em comum. Por exemplo, as línguas da família Indo-Européia como espanhol, inglês, português, russo, alemão, francês e outros, possuem padrões que podem fazer com que um modelo pré-treinado em uma, possa ser usado em outra. Já se fossemos testar em textos japoneses, esses modelos teriam uma performance bem mais baixa, visto que são idiomas bem diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se testaremos o mesmo texto em inglês, vemos que o resultado melhora bastante, mesmo que ainda fazendo um pequeno erro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Welcome/VB\n",
      "  to/TO\n",
      "  the/DT\n",
      "  (ORGANIZATION Named/NNP Entity/NNP)\n",
      "  Recognition/NNP\n",
      "  class/NN\n",
      "  from/IN\n",
      "  (ORGANIZATION FIAP/NNP)\n",
      "  lectured/VBN\n",
      "  by/IN\n",
      "  professor/NN\n",
      "  (PERSON Dheny/NNP Fernandes/NNP))\n"
     ]
    }
   ],
   "source": [
    "text = \"Welcome to the Named Entity Recognition class from FIAP lectured by professor Dheny Fernandes\"\n",
    "tokens = word_tokenize(text)\n",
    "taggeado = pos_tag(tokens)\n",
    "entidades = ne_chunk(taggeado)\n",
    "print(entidades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spacy\n",
    "A biblioteca spacy possui um modelo NER pré-treinado no idioma português, vamos ver como ele se sai:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIAP ORG\n",
      "Dheny Fernandes PER\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "doc = nlp(texto)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fine-tuned BERT\n",
    "O modelo abaixo foi pré-treinado na tarefa de reconhecimento de entidades nomeadas usando o BERTimbau, que é pré-treinado na língua portuguesa. O modelo foi pré-treinado usando artigos da Globo News. Mais informações sobre o modelo estão disponíveis na [documentação](https://huggingface.co/monilouise/ner_news_portuguese).\n",
    "\n",
    "Abaixo podemos ver que FIAP não foi identificada como uma entidade nomeada, mas Dheny foi identifado, mas nao da maneira esperada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'DistilBertTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'DistilBertTokenizerFast'.\n",
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:135: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: PESSOA (0.95)\n",
      "##hen: PESSOA (0.78)\n",
      "##y: PESSOA (0.44)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForTokenClassification, DistilBertTokenizerFast, pipeline\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    'monilouise/ner_pt_br', cache_dir=\"../models/\"\n",
    ")\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\n",
    "    'neuralmind/bert-base-portuguese-cased',\n",
    "    model_max_length=512,\n",
    "    do_lower_case=False,\n",
    "    cache_dir=\"../models/\"\n",
    ")\n",
    "ner = pipeline('ner', model=model, tokenizer=tokenizer, grouped_entities=True)\n",
    "entidades = ner(texto)\n",
    "for ent in entidades:\n",
    "    print(f\"{ent['word']}: {ent['entity_group']} ({ent['score']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos testar mais um exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "João: PESSOA (0.74)\n",
      "banco: ORG (0.53)\n",
      "Ita: ORG (0.90)\n",
      "##u: ORG (0.73)\n"
     ]
    }
   ],
   "source": [
    "entidades = ner(\"João é funcionário do banco Itau\")\n",
    "for ent in entidades:\n",
    "    print(f\"{ent['word']}: {ent['entity_group']} ({ent['score']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já usamos modelos prontos, vamos ver como treinar o nosso próprio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando um modelo multi linguagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos treinar um modelo multi linguagem para Reconhecimento de Entidade Nomeada. Para isso, vamos usar um pedaço do dataset “XTREME” (Cross-lingual TRansfer Evaluation of Multilingual Encoders), chamado de WikiANN ou PAN-X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: datasets in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (2.21.0)\n",
      "Requirement already satisfied: aiohttp in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: multiprocess in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from datasets) (0.24.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: packaging in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: filelock in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: xxhash in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: fsspec[http]<=2024.6.1,>=2023.1.0 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from datasets) (2024.6.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.7.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import DatasetDict, load_dataset, get_dataset_config_names\n",
    "from transformers import (\n",
    "    XLMRobertaForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from seqeval.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse dataset possui 183 subsets (idiomas), com um padrão de PAN-x. e a sigla do idioma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928dc544e2214df082cc70e3ef86d8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/131k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTREME possui 183 configurações.\n",
      "['PAN-X.af', 'PAN-X.ar', 'PAN-X.bg']\n"
     ]
    }
   ],
   "source": [
    "xtreme_subsets = get_dataset_config_names(\"xtreme\") \n",
    "print(f\"XTREME possui {len(xtreme_subsets)} configurações.\") \n",
    "panx_subsets = [s for s in xtreme_subsets if s.startswith(\"PAN\")]\n",
    "print(panx_subsets[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos pegar os seguintes idiomas: inglês, português e francês. Além disso, vamos fazer uma redução do dataset por proporções para termos uma visão mais realista. Datasets desbalanceados são muito comuns em problemas na vida real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966351ce20e64c948ff8d2ecc1560f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/770k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcefe9f9fab743a0954ace20ad861a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/388k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d193c7af81924d2b9e53803dd143ff19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/383k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db8acf4157b4363935d8ab306745744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cac023da1734eaa90c1fda7797413a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6acb166d1e475d97dc45426cccc22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2c95d130bd430c935af7c9239a75f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/942k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323cc865005c41118531e36d773c317e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/472k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95dc26087eaa47318a4fa1cd9a1000d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/472k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e623e812b8c642868779e147a6735b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f0c40576764f96bd2f3d436758a996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0740b9e574fb4bdfb6cb3cfab1ec343e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ac4fa4d692460da3f55bc7f0ff92ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/837k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7ac1aa8a534e09acfa7afab4b718d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/419k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051c294c7e59497aa11a14f862b68424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/423k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f00fffc5e1845339157a1f98d515ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fedcb3e60cc4505a753632788f4d64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2378b85137ed4833b66a01a1b2c15359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pt</th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Número de observações de treino</th>\n",
       "      <td>2600</td>\n",
       "      <td>14400</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   pt     en    fr\n",
       "Número de observações de treino  2600  14400  3000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs = ['pt', 'en', 'fr']\n",
    "prop = [0.13, 0.72, 0.15]\n",
    "panx_ch = defaultdict(DatasetDict)\n",
    "for lang, prop in zip(langs, prop):\n",
    "\tds = load_dataset('xtreme', name=f'PAN-X.{lang}')\n",
    "\tfor split in ds:\n",
    "\t\tpanx_ch[lang][split] = ds[split].shuffle(seed=0).select(\n",
    "            range(int(prop * ds[split].num_rows))\n",
    "        )\n",
    "pd.DataFrame(\n",
    "\t{\n",
    "\t\tlang: [panx_ch[lang]['train'].num_rows]\n",
    "\t\tfor lang in langs\n",
    "\t}, index=['Número de observações de treino']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente vamos treinar nosso modelo na língua inglesa e testarmos ele na língua inglesa, portuguesa e francesa.\n",
    "Vamos inspecionar um exemplo no dataset inglês."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: [\"'\", \"''\", 'Toronto', 'Lynx', \"''\", \"'\"]\n",
      "ner_tags: [0, 0, 3, 4, 0, 0]\n",
      "langs: ['en', 'en', 'en', 'en', 'en', 'en']\n"
     ]
    }
   ],
   "source": [
    "exemplo = panx_ch['en']['train'][0]\n",
    "for key, value in exemplo.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que a coluna ner_tags corresponde a um código mapeado, então vamos transformá-lo em uma nova coluna mais familiar, com as tags LOC, PER e ORG. Podemos fazer isso através do atributo features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n",
      "ner_tags: Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)\n",
      "langs: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n"
     ]
    }
   ],
   "source": [
    "for key, value in panx_ch['en']['train'].features.items():\n",
    "\tprint(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos criar uma função que cria a coluna ner_tags_str usando a feature ner_tags que possui uma classe ClassLabel que mapeia o id com a tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7155cbc6c9ff4b5fbf769cf51c165104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3d8de35ec14c7c997e89ca1dcf640c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76914fa8d63463cb897288a65a2a7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>'</td>\n",
       "      <td>''</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Lynx</td>\n",
       "      <td>''</td>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1        2      3   4  5\n",
       "tokens  '  ''  Toronto   Lynx  ''  '\n",
       "tags    O   O    B-ORG  I-ORG   O  O"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = panx_ch['en']['train'].features['ner_tags'].feature\n",
    "def create_tag_names_column(batch):\n",
    "\treturn {'ner_tags_str': [tags.int2str(idx) for idx in batch['ner_tags']]}\n",
    "panx_en = panx_ch['en'].map(create_tag_names_column)\n",
    "exemplo = panx_en['train'][0]\n",
    "pd.DataFrame([exemplo['tokens'], exemplo['ner_tags_str']], ['tokens', 'tags'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima já vemos alguns desafios que enfrentamos lidando com idiomas: Toronto é uma cidade, que seria classificado como local, mas Toronto Lynx é um time de futebol, então é classificado como organização. Outro desafio importante é a criação das tags, podemos ver que é bem trabalhoso e complexo de taggear todas as sentenças de um dataset inteiro para treinarmos o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora faremos uma Análise Exploratória para entender a quantidade de tags que temos em cada dataset e ver se estão homogênias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "      <th>LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>6715</td>\n",
       "      <td>6542</td>\n",
       "      <td>6767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>3364</td>\n",
       "      <td>3276</td>\n",
       "      <td>3458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3385</td>\n",
       "      <td>3339</td>\n",
       "      <td>3357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ORG   PER   LOC\n",
       "train       6715  6542  6767\n",
       "validation  3364  3276  3458\n",
       "test        3385  3339  3357"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split2freqs = defaultdict(Counter)\n",
    "for split, dataset in panx_en.items():\n",
    "\tfor row in dataset['ner_tags_str']:\n",
    "\t\tfor tag in row:\n",
    "\t\t\tif tag.startswith('B'):\n",
    "\t\t\t\ttag_type = tag.split('-')[1]\n",
    "\t\t\t\tsplit2freqs[split][tag_type] += 1\n",
    "pd.DataFrame.from_dict(split2freqs, orient='index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que vimos o dataset, vamos para o modelo.\n",
    "\n",
    "Nesse exemplo, usaremos o modelo [XLM-RoBERTa](https://huggingface.co/docs/transformers/model_doc/xlm-roberta). O modelo RoBERTa modifica o pré-treinamento do BERT, melhorando-o ao treinar com mais dados por mais tempo, além de não realizar a tarefa de Next Sentence Prediction. O XLM-RoBERTa, por sua vez, estende o RoBERTa para um pré-treinamento multi-língua. Outra diferença para o BERT é a tokenização: Enquanto o BERT tokeniza usando WordPiece, o XLM-RoBERTa utiliza o SentencePiece. Essa mudança de tokenização é especialmente importante para lidar com línguas em que a separação por espaço não faz sentido, como na língua japonesa, sendo mais agnóstica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff925d7d8c7749f585872b5f0be65506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31cb3894404465997feb9335d6c1207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563601db71ed43369a326539471d972c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435cd714fbf54caab123b29c97416ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eff1a26f0d24138bc6cad493e74a872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"../models/\")\n",
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}\n",
    "config = AutoConfig.from_pretrained(\n",
    "\tmodel_name,\n",
    "\tnum_labels=tags.num_classes,\n",
    "\tid2label=index2tag,\n",
    "\tlabel2id=tag2index,\n",
    "    cache_dir=\"../models/\"\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = XLMRobertaForTokenClassification.from_pretrained(\n",
    "    model_name, config=config, cache_dir=\"../models/\"\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de fazer o fine-tuning do modelo, precisamos tokenizar nosso dataset e alinhar e limpar nossos labels. \n",
    "\n",
    "Não queremos que tokens de caracter especial, como o `<s>` e o `<\\s>`,que indicam início e fim de sentença, sejam classificados, e também queremos ignorar a classificação das subpalavras; somente a primeira deve ser classificada, as demais serão tratadas posteriormente quando juntarmos os tokens em palavras. Para isso, vamos usar os word_ids. Vamos ver um exemplo abaixo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁'</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁Toronto</td>\n",
       "      <td>▁Lyn</td>\n",
       "      <td>x</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word Ids</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0   1    2         3     4  5    6   7     8\n",
       "Tokens     <s>  ▁'  ▁''  ▁Toronto  ▁Lyn  x  ▁''  ▁'  </s>\n",
       "Word Ids  None   0    1         2     3  3    4   5  None"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = tokenizer(exemplo['tokens'], is_split_into_words=True) \n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"]) \n",
    "word_ids = tokenized_input.word_ids()\n",
    "pd.DataFrame([tokens, word_ids], index=[\"Tokens\", \"Word Ids\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver acima que os caracteres especiais estão com Ids None. Além disso, as subpalavras possuem o mesmo id da anterior: A palavra Lynx foi dividida em ▁Lyn e x por exemplo, ambas com o id 3. Com isso, podemos tratar os labels para quando forem None ou iguais ao anterior, alocamos o label id -100. Porque -100? Porque a classe torch.nn.CrossEntropyLoss possui um atributo chamado ignore_index com valor -100. Dessa forma, os tokens associados com label -100 serão ignorados durante o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae00426030614861babab9b2dd8403af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4d02cc62aa475785c5d07fa2b435dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42941611f87c46d2b7503ec2a3a1d120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "\ttokenized_inputs = tokenizer(\n",
    "\t\texamples['tokens'], truncation=True, is_split_into_words=True\n",
    "\t)\n",
    "\tlabels = []\n",
    "\tfor idx, label in enumerate(examples['ner_tags']):\n",
    "\t\tword_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "\t\tprevious_word_idx = None\n",
    "\t\tlabels_ids = []\n",
    "\t\tfor word_idx in word_ids:\n",
    "\t\t\tif word_idx is None or word_idx == previous_word_idx:\n",
    "\t\t\t\tlabels_ids.append(-100)\n",
    "\t\t\telse:\n",
    "\t\t\t\tlabels_ids.append(label[word_idx])\n",
    "\t\t\tprevious_word_idx = word_idx\n",
    "\t\tlabels.append(labels_ids)\n",
    "\ttokenized_inputs['labels'] = labels\n",
    "\treturn tokenized_inputs\n",
    "def encode_panx_dataset(corpus):\n",
    "\treturn corpus.map(\n",
    "\t\ttokenize_and_align_labels,\n",
    "\t\tbatched=True,\n",
    "\t\tremove_columns=['langs', 'ner_tags', 'tokens']\n",
    "\t)\n",
    "panx_en_encoded = encode_panx_dataset(panx_ch['en'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A avaliação de um modelo NER é similar ao de modelos de classificação, usando métricas como acuracidade, precision, recall, f1-score. A diferença é que todas as palavras de uma entidade precisam ser previstas corretamente para uma previsão contar como correta. Para isso, usaremos a biblioteca seqeval, que faz exatamente isso. Veja um exemplo abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from seqeval) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from seqeval) (1.2.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (2.2.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16164 sha256=f01a5dd40f789f2ab9504914e064172e83af1247a334aa4968d27c0462459785\n",
      "  Stored in directory: /Users/dhenyfernandes/Library/Caches/pip/wheels/ba/ef/95/d29a28e6aefb85dae6cd361a97add9c6a3e3d00687b954d7a4\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       0.00      0.00      0.00         1\n",
      "         PER       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.50      0.50         2\n",
      "weighted avg       0.50      0.50      0.50         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "y_true = [\n",
    "    ['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'],\n",
    "    ['B-PER', 'I-PER', 'O']\n",
    "]\n",
    "y_pred = [\n",
    "    ['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'],\n",
    "    ['B-PER', 'I-PER', 'O']\n",
    "]\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar essa biblioteca, precisaremos formatar as previsões e os labels para formato de lista de listas, conforme visto acima, onde cada lista corresponde a um registro do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_predictions(predictions, label_ids):\n",
    "\tpreds = np.argmax(predictions, axis=2)\n",
    "\tbatch_size, seq_len = preds.shape\n",
    "\tlabels_list, preds_list = [], []\n",
    "\tfor batch_idx in range(batch_size):\n",
    "\t\texample_label, example_preds = [], []\n",
    "\t\tfor seq_idx in range(seq_len):\n",
    "\t\t\tif label_ids[batch_idx, seq_idx] != -100:\n",
    "\t\t\t\texample_label.append(\n",
    "                    index2tag[label_ids[batch_idx][seq_idx]]\n",
    "                )\n",
    "\t\t\t\texample_preds.append(\n",
    "                    index2tag[preds[batch_idx][seq_idx]]\n",
    "                )\n",
    "\t\tlabels_list.append(example_label)\n",
    "\t\tpreds_list.append(example_preds)\n",
    "\treturn preds_list, labels_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos tudo que precisamos para fazer o fine-tuning do XLM-RoBERTa. Primeiramente, faremos somente no subset do idioma inglês e testaremos o modelo nos demais idiomas, português e francês."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "batch_size = 24\n",
    "logging_steps = len(panx_en_encoded['train']) // batch_size\n",
    "finetuned_model_name = f'../models/{model_name}-finetuned-panx-en'\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=finetuned_model_name,\n",
    "    log_level='error',\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_steps=1e6,\n",
    "    weight_decay=0.01,\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\ty_pred, y_true = align_predictions(\n",
    "        eval_pred.predictions, eval_pred.label_ids\n",
    "    )\n",
    "\treturn {'f1': f1_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, precisamos aplicar o método pad para deixar todas as sequências do mesmo tamanho em uma batch (lote). Para isso, usaremos o data collator. Precisamos aplicá-lo tanto no texto como nos labels, porque agora temos labels de tamanhos diferentes, são labels sequenciais. O pad seguirá a mesma lógica implementada, transformando os tokens pad para ids de -100 para serem ignorados durante o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhenyfernandes/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1800/1800 5:28:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.433300</td>\n",
       "      <td>0.306285</td>\n",
       "      <td>0.768064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.248300</td>\n",
       "      <td>0.272279</td>\n",
       "      <td>0.795956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>0.267555</td>\n",
       "      <td>0.814082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1800, training_loss=0.2866471184624566, metrics={'train_runtime': 19697.444, 'train_samples_per_second': 2.193, 'train_steps_per_second': 0.091, 'total_flos': 841458503224944.0, 'train_loss': 0.2866471184624566, 'epoch': 3.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=panx_en_encoded['train'],\n",
    "    eval_dataset=panx_en_encoded['validation'],\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O treinamento pode demorar bastante, tenha paciência. Acima podemos ver que os resultados foram muito bons! Com F1 de cerca de 81%! Após, já teremos nosso modelo treinado, agora é só formatar o resultado final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text, tags, model, tokenizer):\n",
    "\ttokens = tokenizer(text).tokens()\n",
    "\tinput_ids = tokenizer(text, return_tensors='pt').input_ids.to(device)\n",
    "\toutputs = model(input_ids)[0]\n",
    "\tpredictions = torch.argmax(outputs, dim=2)\n",
    "\tpreds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "\treturn pd.Dataframe([tokens, preds], index=['Tokens', 'Tags'])\n",
    "\n",
    "def get_f1_score(trainer, dataset):\n",
    "    return trainer.predict(dataset).metrics['test_f1']\n",
    "\n",
    "def evaluate_lang_performance(lang, trainer):\n",
    "\tpanx_ds = encode_panx_dataset(panx_ch[lang])\n",
    "\treturn get_f1_score(trainer, panx_ds['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nosso modelo até então foi treinado somente em texto do idioma inglês, será que ele já performa bem nos idiomas português e francês?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25c2d1add2c4df8a70ae4713141edc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced34b5883ad429a88d41f0f38acffaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c8a208476945dbbf5a76d025541f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62aefb4a4b348168db4acb8d2ade899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a22268ca4549458222e25d5cfc02ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8d7240f3314cd8ac931f81a728d36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4bda0e42e1e4915b693603218d31398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721fa9278ee94ef4b93f4f499a2d3205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18f7637fb704c49b99646bc26d33058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'en': {'pt': 0.7586608442503638,\n",
       "              'en': 0.8201911296250919,\n",
       "              'fr': 0.7640117994100295}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores = defaultdict(dict)\n",
    "for lang in langs:\n",
    "\tf1_scores['en'][lang] = evaluate_lang_performance(lang, trainer)\n",
    "f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incrível! Mesmo o treinamento sendo no idioma inglês, já conseguimos usar esse modelo nos outros idiomas com uma boa performance, com F1 de cerca de 75%.\n",
    "<br>Mas ainda podemos melhorar, podemos treinar um modelo em todos os idiomas de uma vez.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2502' max='2502' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2502/2502 9:09:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.244800</td>\n",
       "      <td>0.291451</td>\n",
       "      <td>0.807264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.169900</td>\n",
       "      <td>0.282273</td>\n",
       "      <td>0.826070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.298266</td>\n",
       "      <td>0.832603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2502, training_loss=0.17537855406363995, metrics={'train_runtime': 32960.5245, 'train_samples_per_second': 1.82, 'train_steps_per_second': 0.076, 'total_flos': 1144017079118496.0, 'train_loss': 0.17537855406363995, 'epoch': 3.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "def concatenate_splits(corpus):\n",
    "\tmulti_corpus = DatasetDict()\n",
    "\tfor split in corpus[0].keys():\n",
    "\t\tmulti_corpus[split] = concatenate_datasets(\n",
    "\t\t\t[data[split] for data in corpus]\n",
    "\t\t).shuffle(seed=42)\n",
    "\treturn multi_corpus\n",
    "\n",
    "panx_all_encoded = [panx_en_encoded]\n",
    "for lang in ['pt', 'fr']:\n",
    "\tpanx_encoded = encode_panx_dataset(panx_ch[lang])\n",
    "\tpanx_all_encoded.append(panx_encoded)\n",
    "corpus = concatenate_splits(panx_all_encoded)\n",
    "training_args.output_dir = f'../models/{model_name}-finetuned-panx-all'\n",
    "training_args.logging_steps = len(corpus['train']) // batch_size\n",
    "trainer = Trainer(model,args=training_args, data_collator=data_collator, compute_metrics=compute_metrics, train_dataset=corpus['train'], eval_dataset=corpus['validation'], tokenizer=tokenizer)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que resultado! 83% de F1 score no total! Agora vamos testar o modelo multi linguagem nos nossos datasets e ver como ficou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Evaluated on</th>\n",
       "      <th>pt</th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fine-tuned on</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.8202</td>\n",
       "      <td>0.7640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.8241</td>\n",
       "      <td>0.8737</td>\n",
       "      <td>0.8604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluated on       pt      en      fr\n",
       "Fine-tuned on                        \n",
       "en             0.7587  0.8202  0.7640\n",
       "all            0.8241  0.8737  0.8604"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, lang in enumerate(langs):\n",
    "\tf1_scores['all'][lang] = get_f1_score(\n",
    "\t\ttrainer, panx_all_encoded[idx]['test']\n",
    "\t)\n",
    "scores_data = {\n",
    "\t'en': f1_scores['en'],\n",
    "\t'all': f1_scores['all'],\n",
    "}\n",
    "f1_scores_df = pd.DataFrame(scores_data).T.round(4).rename_axis(\n",
    "\tindex='Fine-tuned on', columns= 'Evaluated on'\n",
    ")\n",
    "f1_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que usar outros idiomas no treinamento aumentou o resultado testando somente no dataset em inglês também, indo de 82% para 87% em F1! Isso porque ele aprendeu outros padrões com os outros idiomas que puderam ser aproveitados. No entanto, isso é verdade para aqueles idiomas que são similares, conforme comentamos anteriormente, todos os idiomas testados pertencem à família Indo-Européia, que compartilham padrões entre si. Esses padrões fazem com que o modelo performe de forma quase equivalente nesses idiomas, podemos ver que o F1 em todos os três idiomas ficou bem parecido, em torno de 85%, o que é muito bom para um modelo de Reconhecimento de Entidade Nomeada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise de Erro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, é sempre importante fazer uma análise de erro para entender as fraquezas e forças do seu modelo, entendendo potenciais melhorias ou até vendo possíveis viéses.\n",
    "<br>Podemos fazer isso extraindo a loss e a classe prevista para cada token de cada registro, comparando com a classe verdadeira do token do registro. Na análise de erro, podemos olhar para os registros com as maiores loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def forward_pass_with_label(batch):\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        output = trainer.model(input_ids, attention_mask)\n",
    "        predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "    loss = cross_entropy(output.logits.view(-1,7), labels.view(-1), reduction=\"none\")\n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
    "    return {\"loss\": loss, \"predicted_label\": predicted_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f288a2815d4cf4912187a60e35640b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_set = panx_en_encoded[\"validation\"]\n",
    "valid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)\n",
    "df = valid_set.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos extrair is tokens, até então só temos os ids para melhorar nossa leitura. Além disso, vamos retirar o padding adicionado anteriormente limitando pelo tamanho do dado de entrada (input_ids)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 111767, 87, 1529, 5861, 1650, 194397, 70, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, O, B-ORG, I-ORG, IGN, I-ORG, I-ORG, I-OR...</td>\n",
       "      <td>[0.0, 0.00039033423, 0.0019378946, 0.000969535...</td>\n",
       "      <td>[I-ORG, O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, ...</td>\n",
       "      <td>[&lt;s&gt;, ▁``, ▁I, ▁He, ard, ▁It, ▁Through, ▁the, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids  \\\n",
       "0  [0, 111767, 87, 1529, 5861, 1650, 194397, 70, ...   \n",
       "\n",
       "                            attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [IGN, O, B-ORG, I-ORG, IGN, I-ORG, I-ORG, I-OR...   \n",
       "\n",
       "                                                loss  \\\n",
       "0  [0.0, 0.00039033423, 0.0019378946, 0.000969535...   \n",
       "\n",
       "                                     predicted_label  \\\n",
       "0  [I-ORG, O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, ...   \n",
       "\n",
       "                                        input_tokens  \n",
       "0  [<s>, ▁``, ▁I, ▁He, ard, ▁It, ▁Through, ▁the, ...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2tag[-100] = \"IGN\"\n",
    "df[\"input_tokens\"] = df[\"input_ids\"].apply(lambda x: tokenizer.convert_ids_to_tokens(x))\n",
    "for label in [\"predicted_label\", \"labels\"]:\n",
    "    df[label] = df[label].apply(lambda x: [index2tag[i] for i in x])\n",
    "for col in [\"loss\", \"predicted_label\"]:\n",
    "    df[col] = df.apply(lambda x: x[col][:len(x[\"input_ids\"])], axis=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos olhar para os tokens de forma individual, explodindo as listas, criando uma linha por token. Também vamos retirar os labels IGN que possuem loss zero de qualquer forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111767</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>▁``</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>▁I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1529</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁He</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1650</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁It</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194397</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁Through</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input_ids attention_mask labels  loss predicted_label input_tokens\n",
       "0    111767              1      O   0.0               O          ▁``\n",
       "0        87              1  B-ORG   0.0           B-ORG           ▁I\n",
       "0      1529              1  I-ORG   0.0           I-ORG          ▁He\n",
       "0      1650              1  I-ORG   0.0           I-ORG          ▁It\n",
       "0    194397              1  I-ORG   0.0           I-ORG     ▁Through"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = df.apply(pd.Series.explode)\n",
    "df_tokens = df_tokens[df_tokens[\"labels\"] != \"IGN\"]\n",
    "df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
    "df_tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos agrupar os dados por token e agregar a loss, extraindo contagem, média e soma. Podemos ver que o token que acumulou a maior loss no dataset de validação é o _, seguido por _of e assim por diante...\n",
    "<br>Isso nos dá alguns insights importantes:\n",
    "- o token `_` representa espaço, ele ter obtido a maior loss acumulada não é surpresa, visto que ele é o token mais frequente também. Além disso, a média da loss desse token indica que o modelo não tem problemas em classificar ele.\n",
    "- os tokens `_of`, `_the`, `_and` e outros na lista aparencem com bastante frequência. Esses tokens aparecem bastante juntos com entidade nomeadas e as vezes fazem parte delas, o que explica o porque o modelo fica confuso com eles.\n",
    "- Parênteses no início das palavras apareceram com uma frequencia relativamente alta e uma média de loss bem alta também, precisando de investigação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_tokens</th>\n",
       "      <td>▁</td>\n",
       "      <td>▁of</td>\n",
       "      <td>▁)</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁the</td>\n",
       "      <td>▁and</td>\n",
       "      <td>▁The</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5550</td>\n",
       "      <td>1356</td>\n",
       "      <td>1927</td>\n",
       "      <td>1931</td>\n",
       "      <td>1142</td>\n",
       "      <td>726</td>\n",
       "      <td>336</td>\n",
       "      <td>2775</td>\n",
       "      <td>910</td>\n",
       "      <td>1317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>905.49</td>\n",
       "      <td>595.24</td>\n",
       "      <td>466.63</td>\n",
       "      <td>460.9</td>\n",
       "      <td>328.1</td>\n",
       "      <td>226.09</td>\n",
       "      <td>179.0</td>\n",
       "      <td>155.51</td>\n",
       "      <td>135.23</td>\n",
       "      <td>133.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0       1       2      3      4       5      6       7  \\\n",
       "input_tokens       ▁     ▁of      ▁)     ▁(   ▁the    ▁and   ▁The     ▁''   \n",
       "count           5550    1356    1927   1931   1142     726    336    2775   \n",
       "mean            0.16    0.44    0.24   0.24   0.29    0.31   0.53    0.06   \n",
       "sum           905.49  595.24  466.63  460.9  328.1  226.09  179.0  155.51   \n",
       "\n",
       "                   8       9  \n",
       "input_tokens     ▁in      ▁'  \n",
       "count            910    1317  \n",
       "mean            0.15     0.1  \n",
       "sum           135.23  133.68  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens.groupby(\"input_tokens\")[[\"loss\"]].agg(\n",
    "    [\"count\", \"mean\", \"sum\"]\n",
    ").droplevel(level=0, axis=1).sort_values(\n",
    "    by=\"sum\", ascending=False\n",
    ").reset_index().round(2).head(10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando pelos labels, podemos ver que a maior loss acumulada é da classe I-ORG, sendo onde nosso modelo tem maior dificuldade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8384</td>\n",
       "      <td>4564</td>\n",
       "      <td>5337</td>\n",
       "      <td>3364</td>\n",
       "      <td>29398</td>\n",
       "      <td>3458</td>\n",
       "      <td>3276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>4119.23</td>\n",
       "      <td>2913.32</td>\n",
       "      <td>2602.94</td>\n",
       "      <td>2412.29</td>\n",
       "      <td>2342.42</td>\n",
       "      <td>1467.08</td>\n",
       "      <td>1287.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1        2        3        4        5        6\n",
       "labels    I-ORG    I-LOC    I-PER    B-ORG        O    B-LOC    B-PER\n",
       "count      8384     4564     5337     3364    29398     3458     3276\n",
       "mean       0.49     0.64     0.49     0.72     0.08     0.42     0.39\n",
       "sum     4119.23  2913.32  2602.94  2412.29  2342.42  1467.08  1287.69"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens.groupby(\"labels\")[[\"loss\"]].agg(\n",
    "    [\"count\", \"mean\", \"sum\"]\n",
    ").droplevel(level=0, axis=1).sort_values(\n",
    "    by=\"sum\", ascending=False\n",
    ").reset_index().round(2).head(10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos quebrar ainda mais e ver a matriz de confusão. Abaixo vemos que:\n",
    "- Nosso modelo se confunde entre o B-ORG (início de organização) e o I-ORG (token subsequente).\n",
    "- O modelo também se confunde bastante entre a classe B-PER com O e I-PER.\n",
    "- Em geral nosso modelo é um bom modelo, podemos ver isso claremente pela diagonal da matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAIhCAYAAACCK4oJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAACmVUlEQVR4nOzdd1QUVxsG8GcBwUKRvtgARYoVC9VEwd577Bowzd5jjzW2JPae2AWxghJRYwFrENSIHdAICkoHQbHQ9vtjZWHZBUVp8+X5nbPnyOw7s/e+e2f23Tuzo0gikUhAREREVMGplHcDiIiIiD4GixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixb6v7Zr1y6IRCKIRCKcP39e4XmJRAILCwuIRCK4uLh80mts2rQJu3btKtY658+fL7RNJWXBggUQiUSltv2yNHfuXNSpUwdqamqoXr16qbzGmjVroKWlhQ4dOuDRo0fo1q0b9uzZUyqv9f8kMjISIpFIbh/I3e8iIyPLtC1ubm4wMzMr09ekssWihf4TtLS0sH37doXlFy5cwL///gstLa1P3vanFC3NmzdHYGAgmjdv/smv+19x7NgxLFmyBCNGjMCFCxdw9uzZUnmdFStWYM2aNWjQoAGaN2+OmJgY9OzZs1Re6/9dt27dEBgYCBMTk/JuCv2fUSvvBhCVhYEDB8LT0xMbN26Etra2bPn27dvh5OSEtLS0MmlHZmYmRCIRtLW14ejoWCavKXR3794FAEyYMAFGRkal9joxMTGyf69du7bUXqe0vXnzBpUrVy7XWTZDQ0MYGhqW2+vT/y/OtNB/wuDBgwEAXl5esmWpqak4cuQIRo4cqXSdhQsXwsHBAXp6etDW1kbz5s2xfft25P8/Rs3MzHDv3j1cuHBBdhoqd3o69xTQ3r17MXXqVNSsWRMaGhp49OiRwumh3Cn2wh4f4ufnB1tbW2hoaMDc3By//fab0jiJRIJNmzbB1tYWVapUga6uLvr374/Hjx9/TBoRGhqKwYMHw9jYGBoaGqhTpw5GjBiBd+/eyWLu3r2LXr16QVdXF5UrV4atrS12794tt53c/nt5eWHOnDmoUaMGtLW10b59e4SFhcnld+7cuQAAY2NjiEQiLFiwAADk/p2fmZkZ3NzcZH+/fv0a06ZNg7m5OSpXrgw9PT20bNlSbixcv34dgwYNgpmZGapUqQIzMzMMHjwYT548Udj+x/SvMCKRCOPGjcPevXthY2ODqlWromnTpjh+/LhC7OXLl9GuXTtoaWmhatWqcHZ2hp+fn1xM7mmY06dPY+TIkTA0NETVqlXx7t07uLi4oFGjRggMDISzs7OsXzt37gQgHTPNmzdH1apV0bhxY5w6dUpu248ePYK7uzvq16+PqlWrombNmujRowfu3LnzwX4WPD2U+34re+Q/nXPgwAF07NgRJiYmqFKlCmxsbDBz5kykp6crfQ0rKytoaGjAxsam0FN5H7Mfk3BwpoX+E7S1tdG/f3/s2LEDP/zwAwBpAaOiooKBAwdizZo1CutERkbihx9+QJ06dQAAV69exfjx4/Hs2TPMmzcPAODj44P+/ftDR0cHmzZtAgBoaGjIbWfWrFlwcnLCli1boKKiAiMjI8TGxsrFmJiYIDAwUG5ZQkIChg0bhpo1axbZt3PnzqFXr15wcnLC/v37kZ2djV9++QVxcXEKsT/88AN27dqFCRMmYMWKFUhOTsaiRYvg7OyMW7duwdjYuNDXuXXrFr744gsYGBhg0aJFqF+/PmJiYuDr64uMjAxoaGggLCwMzs7OMDIywrp166Cvrw8PDw+4ubkhLi4O06dPl9vm7Nmz0apVK2zbtg1paWmYMWMGevTogQcPHkBVVRU+Pj7YuHEjtm/fjlOnTkFHRwe1atUqMh8FTZkyBXv37sXPP/+MZs2aIT09HXfv3kVSUpIsJjIyElZWVhg0aBD09PQQExODzZs3w87ODvfv34eBgQEAFLt/yvj5+eHatWtYtGgRNDU18csvv6BPnz4ICwtD3bp1AUhPW3bo0AFNmjTB9u3boaGhgU2bNqFHjx7w8vLCwIED5bY5cuRIdOvWDXv37kV6ejoqVaoEAIiNjYW7uzumT5+OWrVqYf369Rg5ciSioqJw+PBhzJ49Gzo6Oli0aBF69+6Nx48fo0aNGgCA58+fQ19fH8uXL4ehoSGSk5Oxe/duODg44ObNm7Cysvro9yD3dGh+Dx8+xDfffIOGDRvKLevatSsmTZqEatWqITQ0FCtWrEBwcDD8/f1lcbt27YK7uzt69eqFlStXIjU1FQsWLMC7d++goiL/Xfxj9mMSEAnR/7GdO3dKAEiuXbsmCQgIkACQ3L17VyKRSCR2dnYSNzc3iUQikTRs2FDSpk2bQreTnZ0tyczMlCxatEiir68vycnJkT1X2Lq5r9e6detCnwsICFD6eunp6RJ7e3uJiYmJJDIyssg+Ojg4SGrUqCF58+aNbFlaWppET09Pkn8XDwwMlACQrFy5Um79qKgoSZUqVSTTp08v8nXatm0rqV69uiQ+Pr7QmEGDBkk0NDQkT58+lVvepUsXSdWqVSUvXryQSCR5/e/atatc3MGDByUAJIGBgbJl8+fPlwCQJCQkyMUCkMyfP1+hDaamppKvv/5a9nejRo0kvXv3LrJvBWVlZUlevXolqVatmmTt2rXF7l9hAEiMjY0laWlpsmWxsbESFRUVybJly2TLHB0dJUZGRpKXL1/KtalRo0aSWrVqycZf7vgeMWKEwmu1adNGAkBy/fp12bKkpCSJqqqqpEqVKpJnz57JloeEhEgASNatW1dkTjIyMiT169eXTJ48WbY8IiJCAkCyc+dO2bLcdkVERCjdVlxcnKRu3bqShg0bSlJSUpTG5OTkSDIzMyUXLlyQAJDcunVLIpFI98UaNWpImjdvLrcfRkZGSipVqiQxNTUttA9F7cckDDw9RP8Zbdq0Qb169bBjxw7cuXMH165dK/TUEAD4+/ujffv20NHRgaqqKipVqoR58+YhKSkJ8fHxH/26/fr1K1Y7s7OzMXDgQDx48AAnTpyAqalpobHp6em4du0a+vbti8qVK8uWa2lpoUePHnKxx48fh0gkwrBhw5CVlSV7iMViNG3atMhfMr1+/RoXLlzAgAEDirxWwd/fH+3atUPt2rXllru5ueH169cK37YLXujapEkTAFB6WuZT2dvb4+TJk5g5cybOnz+PN2/eKMS8evUKM2bMgIWFBdTU1KCmpgZNTU2kp6fjwYMHsrji9k8ZV1dXuQu/jY2NYWRkJOtzeno6goKC0L9/f2hqasriVFVVMXz4cERHR8udQgMKH2MmJiZo0aKF7G89PT0YGRnB1tZWNqMCADY2NgDk856VlYWlS5eiQYMGUFdXh5qaGtTV1fHw4UO5nBRXeno6unXrhrdv3+LkyZNyvwZ7/PgxhgwZArFYLNvn2rRpAwCy1wwLC8Pz588xZMgQuVOnpqamcHZ2Vni9ktqPqWLg6SH6zxCJRHB3d8e6devw9u1bWFpa4ssvv1QaGxwcjI4dO8LFxQV//PEHatWqBXV1dRw9ehRLlixR+sFXmOL+gmLUqFE4deqU7DqVoqSkpCAnJwdisVjhuYLL4uLiIJFICj0FlHtqorDXyc7O/uCpmaSkJKX9zf2AzH9KBgD09fXl/s49tVac/H7IunXrUKtWLRw4cAArVqxA5cqV0alTJ/z666+oX78+AGDIkCE4d+4cfvrpJ9jZ2UFbWxsikQhdu3aVa0tx+6dMwT4D0n7nvk5KSgokEkmxXqewMaanp6ewTF1dXWG5uro6AODt27eyZVOmTMHGjRsxY8YMtGnTBrq6ulBRUcG33377ye9PVlYW+vfvj/DwcFy8eFGu+Hv16hW+/PJLVK5cGT///DMsLS1RtWpVREVFoW/fvrLXzO17YWM+/8+sS3I/poqBRQv9p7i5uWHevHnYsmULlixZUmjc/v37UalSJRw/flxuBuPo0aPFfs3i/IpjwYIF2LZtG3bu3ImOHTt+MF5XVxcikUjhGhkACssMDAwgEolw6dIlhetuAMVrcfLT09ODqqoqoqOji2yPvr6+3K9wcj1//lzWhpKioaEhdwFwroIf6NWqVcPChQuxcOFCxMXFyWZdevTogdDQUKSmpuL48eOYP38+Zs6cKVvv3bt3SE5OlttWWfQvtzgozuuUxi+FPDw8MGLECCxdulRueWJi4iffK+f777/HuXPncOLECTRt2lTuOX9/fzx//hznz5+Xza4AwIsXL+Ticou+jxnzJbkfU8XA00P0n1KzZk38+OOP6NGjB77++utC40QiEdTU1KCqqipb9ubNG+zdu1chNv+35M+xfft2LFy4EIsWLZL79UtRqlWrBnt7e3h7e8t9S3758iX+/PNPudju3btDIpHg2bNnaNmypcKjcePGhb5OlSpV0KZNGxw6dAiJiYmFxrVr10724ZPfnj17ULVq1RL9mbeZmRlu374tt8zf3x+vXr0qdB1jY2O4ublh8ODBCAsLw+vXryESiSCRSBSKtm3btiE7O1tuWVn0r1q1anBwcIC3t7fcuMrJyYGHhwdq1aoFS0vLz36dDxGJRAo58fPzw7Nnzz5pe3PnzsXOnTuxbds2tG/fXunrAYrF89atW+X+trKygomJCby8vOR+AfTkyRP8/fffCtv82P2YhIEzLfSfs3z58g/GdOvWDatWrcKQIUPw/fffIykpCb/99pvS2YjGjRtj//79OHDgAOrWrYvKlSsXWQAoExgYiFGjRqFVq1bo0KEDrl69Kvd8UR+GixcvRufOndGhQwdMnToV2dnZWLFiBapVqyY3U9CqVSt8//33cHd3x/Xr19G6dWtUq1YNMTExuHz5Mho3bozRo0cX+jqrVq3CF198AQcHB8ycORMWFhaIi4uDr68vtm7dCi0tLcyfPx/Hjx+Hq6sr5s2bBz09PXh6esLPzw+//PILdHR0ipWXogwfPhw//fQT5s2bhzZt2uD+/fvYsGGDwms4ODige/fuaNKkCXR1dfHgwQPs3bsXTk5OqFq1KgCgdevW+PXXX2FgYAAzMzNcuHAB27dvV5hRKKv+LVu2DB06dICrqyumTZsGdXV1bNq0CXfv3oWXl1eZ3IOle/fu2LVrF6ytrdGkSRPcuHEDv/76a7F/vQUAhw4dwpIlS9C/f39YWlrKjW8NDQ00a9YMzs7O0NXVxahRozB//nxUqlQJnp6euHXrlty2VFRUsHjxYnz77bfo06cPvvvuO7x48QILFixQOGVUnP2YBKJcLwMmKmX5fz1UFGW/ANqxY4fEyspKoqGhIalbt65k2bJlku3btyv8KiIyMlLSsWNHiZaWlgSA7NcLub+QOXTokMLrFfz1UG47C3t8iK+vr6RJkyYSdXV1SZ06dSTLly+X/eqmoB07dkgcHBwk1apVk1SpUkVSr149yYgRI+R+ZVKY+/fvS7766iuJvr6+7LXc3Nwkb9++lcXcuXNH0qNHD4mOjo5EXV1d0rRpU7lflhSVG2W/RCns10Pv3r2TTJ8+XVK7dm1JlSpVJG3atJGEhIQo/Hpo5syZkpYtW0p0dXVl7+XkyZMliYmJspjo6GhJv379JLq6uhItLS1J586dJXfv3lXY1sf2rzAAJGPHjlVYrux1Ll26JGnbtq3sfXJ0dJT8+eefcjFFje82bdpIGjZsqPS1unXr9sG2paSkSL755huJkZGRpGrVqpIvvvhCcunSJUmbNm3k9pWP+fVQ7nuo7JH/1z5///23xMnJSVK1alWJoaGh5Ntvv5X8888/CtuXSCSSbdu2SerXry9RV1eXWFpaSnbs2CH5+uuvFX499LH7MQmDSCLhHXaIiIio4uM1LURERCQILFqIiIhIEFi0EBERkSCwaCEiIiJBYNFCREREgsCihYiIiASBN5crBTk5OXj+/Dm0tLTK5CZQREREQiaRSPDy5UvUqFEDKiqFz6ewaCkFz58/V/hfYImIiKhoUVFRRd51mUVLKcj9b+fV2y6GSK3yB6L/v93d7l7eTagQNCtzVyMqSEWFM9G5snP+2/d5ffkyDVZ168g+PwvDI2kpyD0lJFKrDFGlKuXcmvKlpa1d3k2oELRYtBApYNGS579etOT60CUVvBCXiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCoFbeDaCP802XRhjfuxmMdasiNCoZs7dfRuD9mELjv2ptiQl9mqFuDR2kpWfg3M2n+GnXFaS8fCeLGdWjCUZ2boRaBlpIfvkGx/7+F4v2XsW7zOyy6NIn2etzGVv3ByA+OQ2WZmLMG9cb9k3rFRp/NeQRft54DOGRsTDW18YPg9tiWK9WcjHbD12A57EreBb3Ano61dDFpQmmf9cdlTUqlXZ3Ptn2wxexweMc4pLSYG1ugiWT+8KpmUWh8Vf+eYif1vggNCIGYgMdjB/eHu59v5A9H/o4Bsu2+uFWWBSiYpKxZFJfjBrsWhZd+SzMgxTzILXt0EWs9ziHuMRUWNc1wdIp/eBcVB5uPMScNd4IfSzNw4QR7TGy35dyMb7+N7F0ix8iohNhXssAc0f3QHfXpqXdlc+yI994sCrGeAh7Px7GKRkPy/ONh5/LcTxwpkUA+rSywNKRX2DloetoM+UgAu/H4OBPPVDLQFNpvKONCTZPbIe9Zx/AabwX3H/9C80tjLBubFtZzFetLTF/uBN+OXANDuP3YfyGAPT5oj7mDXcsq24V25/+N7Fow1GMG94BJ/6YBrsmdeE243c8i0tRGh8VkwT3GX/ArkldnPhjGsYO64CF63xw8sItWczRMzew4vfjmPh1J5zdMxMrZgzEcf8Q/PLH8bLqVrH5nLmBOau9McW9EwL2zICjbT0MnLwZ0bHJSuOfPE/EoMlb4GhbDwF7ZmCyW0fMWnkYvv4hspjXbzNgVtMA88b0hLG+dhn15PMwD1LMg5T36RuYveoIprp3wgWPmXCyrYcBEzchqrA8PEvEgEmb4WRbDxc8ZmKKeyfM/O0wfP1vymKCbz/GyNk7MaCLHS7tm4kBXezgPms7rt+NLKNeFV/ueJj8fjw42dbDoA+Mh8GTt8Dp/XiY5NYRs1cexp8FxoNpTQP8NKYnjMp5PLBoKSAqKgrffPMNatSoAXV1dZiammLixIlISkoqtzaN6WULj7MPsPfsA4RHp2D29st4lvgSIzs3Uhrf0tIYTxNe4ne/23ga/xJXH8Rg5+l7aGZhKIuxszJGUGgsDl98iKj4lwgIicKRSw/RzMKorLpVbNsOnseArg4Y1N0RFmbGmD++D0wMq8Pj2BWl8R7H/kYNo+qYP74PLMyMMai7I77qao/f9wfIYv65F4mWjczRq0ML1DbRQ2s7a/Rs1xx3QqPKqlvFtskrAEN7OmF4L2dYmYuxdEo/1DDWxY4jl5XG7/S+gppiXSyd0g9W5mIM7+WMoT0csdHznCymeQNTLJzQG307toC6ujAmYJkHKeZBatM+fwzr5YQRvaV5WDa1P2oa62LH4UtK43d4X0YtsS6WTe0PK3MxRvR2xtCejtjgkZeHLV7n4WJvjSnunWBpJsYU905oY2eFzV4BSrdZEWzONx4szcVY8n487CxkPOx6Px6WTOkHy/fjYUgR40GjnMcDi5Z8Hj9+jJYtWyI8PBxeXl549OgRtmzZgnPnzsHJyQnJycor1dJUSU0FtvUM4R/yVG55QEgU7K3FStcJDo1FDX1NdGhhCgAw1KmCXk71cPr6E1nM1QcxsK1niOb1pUWKqbE2OjSvIxdTkWRkZuFueDS+tLOSW/6lnRVuFPKt5+a9SIX41nbWuBMWhcws6Smwlo3NcSc8CiEPpP1++jwRAVfvw9WpQcl3ogRkZGbhVmgUXB2s5Za72lvj2p0IpetcvxMBV/sC8Y42CHnwVJYHoWEepJgHqYzMLISERqGtg43cclcHGwTfVp6Ha3ci4Fogvp1jA9y8n5eH4DsRaOson6u2TjYIvv24BFtfcooaD8GFjIdrSsZD2wo8HoRRQpeRsWPHQl1dHadPn0aVKlUAAHXq1EGzZs1Qr149zJkzB5s3by7TNulrVYaaqgoSXryRW56Q+gZGulWVrhMcFovvV53B9mkdUbmSKiqpqeJEUASm/5H3jcP78iPo61TByaV9IRIBldRUsf3kHazx/qdU+/OpUlLTkZ2dA0M9LbnlhrpaSExOU7pOQvJLGOoWiNfTQlZ2DlJSX8FIXwc92zVH8otX+GrcekgkEmRl52BYr1YYM7R9qfXlcyS9kObBqGAe9LUQd1V5HuKT0mCoLx9v9D4PSS9eQWygU2rtLS3MgxTzIJX04pXy44O+FuKTPj4PhgXyEJ+UprhNPS3EJ70s2Q6UkNzxoDQPxRgPBfNQkXCm5b3k5GT89ddfGDNmjKxgySUWizF06FAcOHAAEolEYd13794hLS1N7lHSJJB/XREAJU0BAFjV0sXy777Erweuw3XqIfRb4AtTYy2sGt1GFtOqUQ1M7d8S07ZegMvUgxi27AQ6tTTDtAEtS7ztJUsk95cEAEQipZFQ8lze+yddHnjzETZ4nMXiyf1x/I+p2LLYHf6B97Bu9+mSa3IpECn06wNpKJg3ifLtCA3zIMU8SBVsvkQiKbJPBZ/JPc7mz09xc1sR/D+PBxYt7z18+BASiQQ2NjZKn7exsUFKSgoSEhIUnlu2bBl0dHRkj9q1a5dYu5JevkVWdg6MqsvPqhjoVEHCi9dK15ncvwWCHsRg/dGbuPckCf4hUZi29SKGt28A4/ezM3OGOODg+TDsPfsA958kwy8oAos9rmJyv+YVcofU1akGVVUVJBSYVUlMeQmDArMpuQz1tJTEv4Kaqgp0daoBAFZtP4G+HVtiUHdHWNergc6tm+DH77phk+dZ5OTklE5nPoN+dWke4gp8e0xMfgkjPeUXyBnpayt820xIeQk1VRXovc+D0DAPUsyDlH51TaiqqijMgCQmv1KYdcglzYNivJqqCvSqV8sXo3jMKWyb5S13PCi0OfklDIsxHhIr8Hhg0fKRcr+hK6s8Z82ahdTUVNkjKqrkLuLMzMpByL8JcLWVL4RcbGsjODRW6TpVNNSQU2AaJvv9B7CoyBgJRBBVyOpavZIaGlnWwuXr4XLLL18PR4tGZkrXadbQTCH+0rUwNLaqjUpqqgCAN+8yFfqroqICiaTwmazypF5JDU2ta+N8cKjc8vPBYbBrbK50nZaNzXE+OExuWUBQKGxt6sjyIDTMgxTzIKVeSQ221rUREFQwD6Gwb6I8D3aNzRXy5h/0AM0a5OXBvrG5wjb9r4bCvkndEmx9ySlqPNgXMh7sBDYeWLS8Z2FhAZFIhPv37yt9PjQ0FLq6ujAwMFB4TkNDA9ra2nKPkrTpWAiGt2+Aoe1sYFlLF0tGtkItAy3s/OseAGDeMEdsnthOFn/qWiR6ONbFyM4NYWqsDQdrMZZ/+yWuh8chNuW1LMa9cyP0/cICdYy04NK0FmYPccDJaxHIyamAn9YAvh3gggN+V3HQLwiPIuOwaIMPnsenYGhPZwDAit+PY8oST1n8sF7OeBaXgsUbjuJRZBwO+gXh4IkgfD8o7/4C7ZwbwvPYFfie+wdRMUm4dC0Mq3acRPtWDaGqWjF3jzGDXeFxLBCevoEIi4jFnNVH8CwuWXZfhUUbfTF6wR5ZvHvfVoiOTcbcNd4Ii4iFp6903bFD88ZMRmYW7oRH4054NDIysxCTkIo74dF4HKU4s1hRMA9SzIPUmCFtsffY3/B4n4fZq44gOjYZ7u/vu7JwwzGMmp+Xh5F9v0BUTDLmrD6CsIhYePgGwuNYIMYNy8vDD4NcEBAUijW7zyA8MhZrdp/BheBQjK7A96wZnW88hOcbD27vx8Pijb4Yk288uOUbD+ECGA8iibKLNP6jOnXqhHv37uHhw4dy17XExsaiXr16GDFixEddiJuWlgYdHR1odPwVokpVPhj/Mb7p0ggT+jSDsW41PHiahDnbL+Pv9zeX2zihLeoYaaPH3KOy+O+6NYZ7p0YwNdZCanoGLt2OxoI9gYhJTgcAqKqIMPWrlhjoYgUTvWpISnuDU9cisdjzKtLSM0qkzQAQue/7EtsWIL253Jb9/khISoOluQl+GtcbDu9vLjd12T5ExybjwNpxsvirIY+weMNRPIyMhZG+DkYNkb+5XFZWNjZ4nIHP6RuITUiFfvVqaOfcENO+7QYdrZJ57wBAq3LJXvO+/XDuTbTSYFPXBD9P7iu7idbYRXsRFZMM380TZfFX/nmIuWu8Efo4FmIDbUwY0UHu5lFPnyehWZ8FCq/TqrmF3HYqGuZBSqh5UFEp2VndbYcuYt3es9I81DPBksn90Kq5NA9jFuzF05gkHN86SRZ/5cZDzF59RJoHQx1MVHJzuWPnbmLJ5uOIfJZ3c7kebW1LtN2AdKa7pOzINx6sC4yHcYv24mkh4yHs/XgYr2Q8NFcyHpxLcDykpaWhhmF1pKamFvnFn0VLPg8fPoSzszNsbGzw888/w9zcHPfu3cOPP/6Id+/e4erVq9DT0/vgdkqjaBGqki5ahKqkixai/wclXbQIWUkWLUL0sUVLxZz/Lif169fH9evXUa9ePQwcOBD16tXD999/D1dXVwQGBn5UwUJERESlg1//CjA1NcXOnTvLuxlERERUAGdaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBDUyrsB/8/u7XCHlrZ2eTejXFmOOlDeTagQHm0dVN5NqBA0K/OQAwDZOZLybgJVMFnZOeXdhHL1sf3nTAsREREJAosWIiIiEgQWLURERCQILFqIiIhIEFi0EBERkSCwaCEiIiJBYNFCREREgsCihYiIiASBRQsREREJAosWIiIiEgQWLURERCQILFqIiIhIEFi0EBERkSCwaCEiIiJBYNFCREREgsCihYiIiASBRQsREREJAosWIiIiEgQWLURERCQILFqIiIhIEFi0EBERkSCwaCEiIiJBYNFCREREgsCihYiIiASBRQsREREJAosWIiIiEgQWLURERCQIauXdAPo4e3wuY6tXABKS01DfTIz543vDvmm9QuOvhjzC4g3H8DAyFkb62hg1pC2G9Wole37ghA24GvKvwnqujjbY9cv3pdKHkuDW1hJjujaAkU4VhD1/gXme1xEUnlBofF8nM4zt2hDmxlp4+SYTAXeeY6HXDaSkZwAAhraxwFet6sK6lg4A4HZkMpYdDsHNx0ll0p9PtdvnMrZ6+SM+KQ2WZmLMn9AHDkWMh8Cbj7B4w1GER8bCWF8Ho4a0xfDereRiUl++xi9/nMCpC7eR+uo1apvo4aexvdHWqUFpd+eTbTt0Ees9ziEuMRXWdU2wdEo/ODezKDT+yo2HmLPGG6GPYyA20MGEEe0xst+XcjG+/jexdIsfIqITYV7LAHNH90B316al3ZXPsuPwRWzwOIe4pDRYmZtgyeS+cCoqD/88xE9rfBAWIc3DuOHt4d73C9nzoY9jsHyrH26FRSEqJhk/T+qLUYNdy6Irn4XjQWrnkUvYtE96fLAyF2PRxL5wtC38+PD3zUdYsM4HYRGxMDbQwdihbfF1n7zx4Hf+FtbuOYPI6ERkZmWjbm1DjBrkiq+62JVFd+RwpkUA/jx3E4vWH8W4ER3gt20a7JvUxdfTf8ezuBSl8U+fJ8Ft+h+wb1IXftumYezwDliw1gcnzt+SxWz92R3XfBbKHmd2T4eqqgq6udqWUa+Kr5e9KRYNbYE1f95Fh3l+CAqLx76pbVFTr6rSePv6hlj/vTP2XXwEl9l/4rsNF2Frro+V3zjKYpytjXH0aiT6LT+L7ov/wrOkdOyf1g5i3Spl1a1i8z33Dxau88H44R1wcvs02DetixE/bi1yPHw9/XfYN62Lk9unYdzw9pi/1ltuPGRkZmHIlM2IjknGlsVuOO85GyumD4LYUKesulVs3qdvYPaqI5jq3gkXPGbCybYeBkzchKjYZKXxT54lYsCkzXCyrYcLHjMxxb0TZv52GL7+N2UxwbcfY+TsnRjQxQ6X9s3EgC52cJ+1HdfvRpZRr4rP58wNzFntjcnunRCwZwacbOth0OTNiC4sD88TMXjyFjjZ1kPAnhmY5NYRs1cexp/+IbKY128zYFrTAD+N6Qkjfe0y6snn4XiQOnr2H8xb64NJX3fEmV0/wqFpPQyZuqWI8ZCEoVO3wqFpPZzZ9SMmjuiAuau9cTwgRBZTXbsqJn3dAcd/n4SAPTMwqKs9Ji3dh4CrD8qoV3kqXNHi5uYGkUgke+jr66Nz5864fft2oetERkbKraOrq4vWrVvjwoULhW4399G5c2dZjJmZmWx5lSpVYG1tjV9//RUSiaRU+/wh2w6ex8BuDhjc3RH1zYwxf0IfmBhWh8fRK0rjPY/9jRpG1TF/Qh/UNzPG4O6OGNDVHr8fCJDFVNeuBiN9bdnj0rVwVNGohG4uFfcbxA+dbeB18V/su/AID2PSMG/fDTxLfo2v21kqjW9hYYCoxHRsPxOGp4npCH6YgL0BD9HUTF8WM3brFezyD8e9pyl4FJOGqTuCoKICfNlAXFbdKrY/DrwfDz2cUN9MjAUT+qKGUXXs9bmsNN7j2BXUNK6OBRP6or6ZGIN7OGFgNwds3e8vizngF4QXaa+xbdk3sGtSF7XEerBvUhcNLGqWVbeKbdM+fwzr5YQRvZ1hZS7Gsqn9UdNYFzsOX1Iav8P7MmqJdbFsan9YmYsxorczhvZ0xAaPc7KYLV7n4WJvjSnunWBpJsYU905oY2eFzV4BSrdZEWz2CsDQnk4Y3ssZluZiLJnSDzWMdbHziPLxsMv7CmqKdbFkSj9YmosxvJczhvRwxEbPvDw0b2CKhRN6o2/HFtBQF8aEPMeD1Nb95zG4hyOG9nSCpZkYiyf1RU0jXez2Uf55scfnCmoZ62LxpL6wNBNjaE8nDO7ugM378vrYqnl9dG3TFJZmYpjVMsB3A13QoF4NBN9+XFbdkqlwRQsAdO7cGTExMYiJicG5c+egpqaG7t27f3C9s2fPIiYmBhcuXIC2tja6du2KiIgIpdvNfXh5ecltY9GiRYiJicGDBw8wbdo0zJ49G7///nuJ9/FjZWRm4U54NL60s5Jb3trOCjcKqfb/uReJ1gXj7a1xJzQKmVnZStc54BeEHu2aoWoVjRJpd0mrpKqCJmZ6OH83Rm75hbsxsLMwVLrOtYcJMNGtinZNagAADLQro7tdHZy99azQ16mioQo1VRW8eJVRco0vQbnjobW9tdzy1nbWhX77u3EvEq3tCsTbW+N2vvFw5spdtGhohrmrDqNZz7loN2I51u85g+zsnFLpx+fKyMxCSGgU2jrYyC13dbBB8O0IpetcuxMB1wLx7Rwb4Ob9p7I8BN+JQFtH+Vy1dbIpl4Pzx8jIzMKt0Ci4Osi32dXeGsF3ishDgfHT1tEGIQ+eFnp8qOg4HqQyMrNwOywKLvbyx/829la4Vsh4uHE3Em0KxLs4WONWqPLxIJFIcOl6GB49jS/ylFNpqZBFi4aGBsRiMcRiMWxtbTFjxgxERUUhIaHwaxcAQF9fH2KxGE2aNMHWrVvx+vVrnD59Wul2cx+6urpy29DS0oJYLIaZmRm+/fZbNGnSRG4bZS0lNR3Z2Tkw0NWSW26gp4WE5DSl6yQkv4SBXoF4XS1kZecg+cUrhfiQ+08QFhGDQd0cFZ6rKPS0NKCmqoKE1DdyyxNS38BQR/mpnOuPEjF2yxVsHfMlorYPwd31/ZH6OgNzPK4V+jpzv2qG2JQ3uHg/ptCY8pT8fjwYFhwPukWMh6SXCuPHsMB4ePo8CScu3EJ2Tg52//oDJozoiN8PBGD9nvIb+0VJevFKmocC49xQXwvxScrzEJ+UBkP9AvF60jwkvc9DfFKa4jb1tBCf9LIEW19ykl6kl0oehIbjQSpZNh7kT+kZ6mkhIVl5m+OTlfVRW+HzIu3VG9Rt9yNqt56CYdN+x5Ip/dCmQPFbFir8vN+rV6/g6ekJCwsL6Ovrf3iF96pWlV7nkJmZ+UmvK5FIcOHCBTx48AD169cvMvbdu3d49+6d7O+0NOU7yecQiUQF2qe4rMh4SJQuB6SzLFbmJrBtYFoCLS1dBc/UiUSiQk/fWdbQwc/DWmLVsTsIuPscxjpVMG9Qc/zytQOm7LiqED+2awP0djRD3+Vn8C6zYs4w5Cr4Nkog+cB4KBAvkR8POTkS6FfXxIofB0JVVQVNrGojLjEVW70CMMm9c8HNVRjK+lVkHgr8Ldsv8j2jfF/7rGaWuuK2WQTFeGXbERqOBymFfkkUl8nFK/RR8fNCs6oGzu2ejvTX73DpejgWrDsK0xr6aNW86M/HklYhZ1qOHz8OTU1NaGpqQktLC76+vjhw4ABUVD6uuenp6Zg1axZUVVXRpk0bpdvNfSxevFhu3RkzZkBTUxMaGhpwdXWFRCLBhAkTiny9ZcuWQUdHR/aoXbt28TtdCF2dalBVVVH4Fp2UovjtOZehnhYSkgrGv4Kaqgp0darJLX/zNgN/+t/EoO4OJdbm0pD88h2ysnNgVF1+VsVAuzIS094qXWd894a49jABm07ex4OoFzh/NwYzdwdjSBsLGBWYnRndxQYTujfCoF/P4UHUi9LqxmfTez8e4gt8a0pKeVX4eNBX/JaV+EJ+PBjpa6NubSOoqubtY/XNjBGfnIaMzKwS7sXn06+uKc1DgW+8icmvFL415jLS11Yar6aqAr3q1fLFyO87iSkvC91medOv/n48FGxz8kuFb9u5CuujmqoK9AocH4SC40FKL3c8JCu2ueDsey4jvcLHQ/7PCxUVFZjXMkQjy1oYPaQturs2xfo9Z0u+Ex9QIYsWV1dXhISEICQkBEFBQejYsSO6dOmCJ0+eoEuXLrKCo2HDhnLrOTs7ywqdP//8E7t27ULjxo2Vbjf3MXbsWLlt/PjjjwgJCcGFCxfg6uqKOXPmwNnZucj2zpo1C6mpqbJHVFRUieVCvZIaGlvWwqXr4XLLL10PR4tGZkrXad7QTDH+WhgaW9dGJTVVueXHA0KQkZmFPh1bllibS0Nmdg5uRyajTUP5C2TbNBTj2iPlpw2rqKshp8AsTHZO7jeIvGVjujTA5J6NMXilP25FKr/CvqKQjYdrYXLLL10LQ8tCxkOLhmYK8ReDQ9Ek33ho2dgckc8SkJOTN8P0OCoBRvraUK9U8SZk1Supwda6NgKCQuWWnw8OhX0Tc6Xr2DU2x/lg+Xj/oAdo1qCOLA/2jc0Vtul/NRT2TeqWYOtLjnolNTS1rq3Qr/PBYbBvXFQe5MdDQFAobG3qKBwfhILjQUq9khqaWNXGhQLv74VrYbArZDy0aGSGCwWOD+eDw9DUuujxIJFI8K4cvtBUyKKlWrVqsLCwgIWFBezt7bF9+3akp6fjjz/+wLZt22QFx4kTJ+TWO3DgAG7duoWEhAQ8e/YMw4YNK3S7uQ89PT25GAMDA1hYWMDJyQlHjhzB6tWrcfZs0dWkhoYGtLW15R4l6dsBLjhw/CoO+AXhYWQcFq33wfP4FAztJS2mVmw9jslLPGXxQ3s541lcChZtOIqHkXE44BeEA35B+H6g4n0WDvhdRccvGivMwFREW089wJA2Fhj8ZT3UN9HGwiEtUFO/Gvb4PwQAzP7KFuu/zyswz4REo2uLOvi6bX3UMdSEXX1DLBlmh3/+TUTcC+m1MWO7NsCMfk0xeXsgohJfwVCnMgx1KqOqRsX7oM713UAX7D9+Ffv9ruJhZCwWrPPBs/gUDHt/35XlW/7EpJ89ZPHDerVCdFwKFq73wcPIWOz3k46lHwa1lcWM6N0KKamvMX+tDx4/jce5v+9hw94z+DrfvTsqmjFD2mLvsb/h4RuIsIhYzF51BNGxyXB/f5+NhRuOYdT8PbL4kX2/QFRMMuasPoKwiFh4+AbC41ggxg1rJ4v5YZALAoJCsWb3GYRHxmLN7jO4EByK0RX4HiWjB7vC41ggPH0DER4Rizmrj+BZXDLc3r93izf6YsyCvDy49W2F6NhkzF3jjfCIWHj6StcdOzQvD7kXfN8Jj0ZGZhZiElJxJzwaj6OKvq6wPHE8SP0wyAX7/ryKfcevIjwyFvPWeuNZXApGvD8+LNn8J8Ytyjs+jOjTCtGxKZi/1gfhkbHYd/wqvP68itFD8vq4bo+030+eJeJhZBy2eAXg0Mlr6N+p7L/sVtwjcz4ikQgqKip48+YNatYs/CeYtWvXRr16JXc1s66uLsaPH49p06bh5s2b5Xa+t0e7ZkhJS8e63X9JbyZmboJdK75HLbG04IpPSsPzfPfoqFNDH7t++Q6L1h/FXp/LMNLXwYKJfdC1wM+ZH0fF49rtCHisHFWm/flUx4KfQFdTA1N6NYZR9SoIffYCQ1cFIDopHQBgrFMFNfXyiq8Dlx9Ds3IljGxvhfmDWiDtdQYuP4jDzwf/kcW4tbWERiVVbB/fRu61fvO5jd+OFv4z+/LUs11zpKS9xtpdf72/eZQJdv/yg2w8xCWlyd2zpU4Nfez+5XssWn8Ue3wuw9hABwsn9pUbDzWMdeG5ahQWrj+Kju6/wNhAByP7t8GYfB9kFU3fji2QnJqOX7adRFxiGmzqmeDAmjGoY/I+D4lpcvemMK1pgINrRmP26iPYdugSxIY6WD6tP3q2bSaLcWhaF9uXuGPJ5uNYuuU4zGsZYMfSkYXOYlUEfTq0QEpqOn7bcQpxiWmwrmsCr9WjUTs3D0mpiM43HkxrGMBr9SjMXeONHYcvQWygjaVT+6NHW1tZTGxCKlyHr5D9vdHzHDZ6noNzcwv4bp5YZn0rDo4Hqd7tmyMlNR2rdvyF+CTpTfY8f/sh33iQPz6Y1tCH58ofMH+tD3Z6X4KxgQ5+ntwX3fPds+v1mwzM/O0QYuJTUVmjEixMjbBh/nD0bt+8rLsHkaS8b0JSgJubG+Li4rBz504AQEpKCjZs2IDNmzfD398fLi4uCutERkbC3NwcN2/ehK2t7UdtN5eamhoMDAwASO/TMmnSJEyaNEn2fEJCAurUqYO9e/eif//+H9WHtLQ06Ojo4FF0IrRKeNZFaCxHHSjvJlQIj7YOKu8mVAialQXxPanU5Z6m/K9TVangV7SWoXeZwvy5eUlJS0tDHbEeUlNTizxbUSGPIKdOnYKJiQkA6U+Qra2tcejQIaUFy6duN5eVlRVCQ0MLWQMwNDTE8OHDsWDBAvTt2/ejLwYmIiKiklXhZlr+H3CmJQ9nWqQ40yLFmRYpzrRIcaYlD2daPm6mhdMGREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAhq5d2A/2fVNNSgqfHfTnH4loHl3YQKoXavX8u7CRVCyl+zyrsJFYKqiqi8m1AhSCSS8m5ChaGu9t+eQ/jY/v+3s0RERESCwaKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQmCWnk3gD7O9sMXscHjHOKS0mBtboIlk/vCqZlFofFX/nmIn9b4IDQiBmIDHYwf3h7ufb+QPR/6OAbLtvrhVlgUomKSsWRSX4wa7FoWXfkse3wuY6tXABKS01DfTIz543vDvmm9QuOvhjzC4g3H8DAyFkb62hg1pC2G9Wole37ghA24GvKvwnqujjbY9cv3pdKHkvBN9+YY/5UDjPU0EfokAbO3nEXg3ehC47/t0Rzf9myBOsY6iI5Pw8r9f+PA2buy561NDTBrxJewtRCjjrg6Zm05iy0+18qiK59l26GLWO9xDnGJqbCua4KlU/rBuaj94sZDzFnjjdDH0v1iwoj2GNnvS7kYX/+bWLrFDxHRiTCvZYC5o3ugu2vT0u7KZ2EepLYfvoj1e98fJ+uaYOlHHCfnrvHJy8Pw9nDv94VcjK9/CJZu9UNkdCLMahlg7qju/7k8PPg3Bst+98Ot0PefF5P7YnQ5fV5wpkUAfM7cwJzV3pji3gkBe2bA0bYeBk7ejOjYZKXxT54nYtDkLXC0rYeAPTMw2a0jZq08DF//EFnM67cZMKtpgHljesJYX7uMevJ5/jx3E4vWH8W4ER3gt20a7JvUxdfTf8ezuBSl8U+fJ8Ft+h+wb1IXftumYezwDliw1gcnzt+SxWz92R3XfBbKHmd2T4eqqgq6udqWUa+Kr08bGywd1R4rvf5GmzE7EHg3Ggd/Hohahsrfx5Hdm+Endxes8LgMp++3YfneS/h1bEd0dsg7iFXRqIQnMS+wcMd5xCa9KqOefB7v0zcwe9URTHXvhAseM+FkWw8DJm5CVGH7xbNEDJi0GU629XDBYyamuHfCzN8Ow9f/piwm+PZjjJy9EwO62OHSvpkY0MUO7rO24/rdyDLqVfExD1LeZ25g9irpcfL8XulxcsCkIo6TzxIxcJL0OHl+r/Q4ObPAcTL4dgS+mbMTA7vY4aLnDAzsYoeRs3f85/Lw5t37z4ux5f95IYiixc3NDb179y70eRcXF4hEIohEImhoaMDS0hJLly5FdnY2AOD8+fOy5ws+YmNjAQALFiyQLVNRUUGNGjUwdOhQREVFlUUXi7TJKwBDezpheC9nWJmLsXRKP9Qw1sWOI5eVxu/0voKaYl0sndIPVuZiDO/ljKE9HLHR85wspnkDUyyc0Bt9O7aAurowJty2HTyPgd0cMLi7I+qbGWP+hD4wMawOj6NXlMZ7HvsbNYyqY/6EPqhvZozB3R0xoKs9fj8QIIuprl0NRvrassela+GoolEJ3Vwq7jepMX3t4fHXLew9dQvhUUmYveUsniWkYWT3ZkrjB7ZrhN0nbsLnwgM8iX0B7wsP4PHXbUwc4CiLuRkeg3nbAuB94QEyMrPKqiufZdM+fwzr5YQRvaX7xbKp/VHTWBc7Dl9SGr/D+zJqiXWxbGp/WJmLMaK3M4b2dMQGj7z9YovXebjYW2OKeydYmokxxb0T2thZYbNXgNJtVgTMg9SmfQEY1jNfHj7yOLns/XFyRG/pcVIuD/sD4GJvhcluHWFpJsZkt45obWeFLfv/W3lo3sAUiyb0Rr8K8HkhiKLlY3z33XeIiYlBWFgYJkyYgLlz5+K3336TiwkLC0NMTIzcw8jISPZ8w4YNERMTg+joaBw4cAB37tzBgAEDyrorcjIys3ArNAquDtZyy13trXHtToTSda7fiYCrfYF4RxuEPHiKzKzsUmtracrIzMKd8Gh8aWclt7y1nRVuFPKt5597kWhdMN7eGndCowrNwwG/IPRo1wxVq2iUSLtLWiU1FdjWF8P/hvx7H3AjAvYNaildR72SKt5myPf37btMNLeqATVVYR4CMjKzEBIahbYONnLLXR1sEHxb+X5x7U4EXAvEt3NsgJv38/aL4DsRaOsov++0dbJB8O3HJdj6ksM8SBV6nHSw/kAeCvSxwHHy2p1IJTGFb7O8lVYeKhJhHrGUqFq1KsRiMczMzDBu3Di0a9cOR48elYsxMjKCWCyWe6io5KVATU0NYrEYNWrUwJdffonvvvsOV69eRVpaWhn3Jk/Si3RkZ+fASE9LbrmhvhbikpS3Kz4pDYb68vFGelrIys5B0gthTP0XlJIqzYOBrny/DPS0kJCsPA8JyS9hUCBvBrrSPCQryUPI/ScIi4jBoG6OCs9VFPraVaGmqoKEF+lyyxNepMNIt5rSdfxvRGB456ZoaiEGANjWF2Nop6ZQr6QKfZ0qpd7m0pD04hWys3NgqGS/iC/GfmFYYL+IT0pT3KaeFuKTXpZg60sO8yCVe5xUdtwrKg/KjqsF82CkJ386xEhP+z+Xh4pEGOcFPkGVKlWQkqL8WoePERsbC29vb6iqqkJVVbXI2Hfv3uHdu3eyv0ujyBGJRHJ/SyRAgUXy8VCMV7YdoVGeh8L7pBAPidLlgHSWxcrcBLYNTEugpaUr9/3MJRKJIFEeil89r8BItxrOrB0BkUiE+JR0eJ25jYkDnJCdXdhawlDwbZRIJEWPhwJ/y8ZDvmeKu69VBMyDlLLjXpHHSSV9LLgdhdxC8p/MQ0Xxf1e05OTk4PTp0/jrr78wadIkuedq1ZKfPq9ZsybCwsJkf9+5cweamprIycnBmzdvAAATJkxAtWrKv8HmWrZsGRYuXFgyHShAv3o1qKqqKMyqJCa/VPgGkMtIX1uhqk5IeQk1VRXo6RTdl4pKV0eah4KzKkkpLxVmX3IZ6mkhIalg/CuoqapAt0Ae3rzNwJ/+NzFlZOeSbXgJS0p7jazsHIVZFQOdqkhISVe6ztuMLIxfdQKT156CkW41xCa/gltXW6Slv0NS2uuyaHaJ06+uCVVVFYVvvInJrxRmCHJJ9wvFeDVVFehVr5YvpsC+lvKy0G2WN+ZBKvc4qey4Z1jEcVLZcbVgHgrGJCT/9/JQkQjq9JCnpyc0NTVlj0uX8i4027RpEzQ1NVG5cmX07NkTw4YNw/z58+XWv3TpEkJCQmSPv/76S+55KysrhISE4Nq1a1iyZAlsbW2xZMmSD7Zr1qxZSE1NlT1K8uJd9UpqaGpdG+eDQ+WWnw8Og11jc6XrtGxsjvPBYXLLAoJCYWtTB5XUip41qqjUK6mhsWUtXLoeLrf80vVwtGhkpnSd5g3NFOOvhaGxdW2FPBwPCEFGZhb6dGxZou0uaZlZOQh5GAvX5vLvvUtzcwTfL/wnzwCQlZ2D54kvkZMjQd82DXA6+JHCjI1QqFdSg611bQQEFdwvQmHfRPl+YdfYXGE/8g96gGYN8vYL+8bmCtv0vxoK+yZ1S7D1JYd5kCrqOFl0Hoo+Tto1NlMaU9g2y1tp5aEiEVTR0rNnT7mio2XLvA+YoUOHIiQkBP/++y/evHmD7du3o2rVqnLrm5ubw8LCQvYwMzOTe15dXR0WFhZo2LAhZs+eDVtbW4wePfqD7dLQ0IC2trbcoySNGewKj2OB8PQNRFhELOasPoJnccmy+64s2uiL0Qv2yOLd+7ZCdGwy5q7xRlhELDx9peuOHdpOFpN7Yeud8GhkZGYhJiEVd8Kj8TgqoUTbXpK+HeCCA8ev4oBfEB5GxmHReh88j0/B0F7OAIAVW49j8hJPWfzQXs54FpeCRRuO4mFkHA74BeGAXxC+H6h4f4EDflfR8YvGCjMwFdEm72AM79wUQzs2gWVtfSz5oR1qGWljp5/0J6vz3Ntg84/dZfH1auphQNuGqFtDF82tTLB9Vi/YmBli0c4LsphKaipoVNcIjeoaoVIlVdTQ10SjukYwr6Fb5v37WGOGtMXeY3/D4/1+MXvVEUTHJsP9/f1GFm44hlHz8/aLkX2/QFRMMuasPoKwiFh4+AbC41ggxg3L2y9+GOSCgKBQrNl9BuGRsViz+wwuBIeW2z0pPgbzIDVmiCv2HguUy8Oz2ALHyfkFjpMxyZiz2jsvD77K87D2fR7W7j6DC8FhGDXov5WH/J8XmeX8eSGo00NaWlrQ0lI+LaejowMLi8JvnvMpfvrpJ1haWmLy5Mlo3rx5iW67OPp0aIHk1HT8uuMU4hLTYFPXBPtXj0ZtEz0AQFxSqty9SkxrGGD/6lGYu8Yb2w9fgthAG8um9kfPtraymNiEVLgMXyH7e4PnOWzwPIdWzS3gu3limfWtOHq0a4aUtHSs2/0X4pPSYGlugl0rvkctsTQP8UlpeJ4vD3Vq6GPXL99h0fqj2OtzGUb6OlgwsQ+6Fvg58+OoeFy7HQGPlaPKtD+fyufCA+hpVcH0oa1grKeJB08SMHDuQUTFS6d4jfU05e7Zoqoiwth+9rCopY+s7GxcuvUUnSbvQVRcqixGrK+FS5u/kf09/itHjP/KEZdvPUGP6fvKrnPF0LejdL/4ZdtJ6X5RzwQH1oxBndz9IjFN7t4UpjUNcHDNaMxefQTbDl2C2FAHy6f1R8+2eT8Vd2haF9uXuGPJ5uNYuuU4zGsZYMfSkWhZyGxeRcA8SPXt0AIpqen4dfupvDzkP04mpiI6/3GypgEOrBmFOavzjpPLCxwnHZrUxbaf3bB0y3Es3eoHs1oG2L7U/T+Xh9iEVLQZlu/zwuMcNnhIPy/+3FK2nxciiaTiTxC7ubnhxYsXCr8GyuXi4gJbW1usWbNG6fPnz5+Hq6srwsLCFGZB9PX1UalSJSxYsABHjx5FSEiI3PP9+vXDu3fvcPz48Y9ub1paGnR0dBCT8KLEZ12E5tU7Ydzzo7SZ9v7tw0H/ASl/zSrvJlAFIoCPHyojaWlpEBtUR2pqapGfm4I6PfS5rKysYGJiIve4ceNGketMnToVfn5+CAoKKqNWEhERkTKCmGkRGs605OFMixRnWqQ400L58eOHcnGmhYiIiP6vsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgqJV3A/6fSd4//su0q1Qq7yZUCCl/zSrvJlQIul/9Ud5NqBAe7RhR3k2oEHSrqZd3EyqMHMl/+9MiO+fj+s+ZFiIiIhKEj5ppWbdu3UdvcMKECZ/cGCIiIqLCfFTRsnr16o/amEgkYtFCREREpeKjipaIiIjSbgcRERFRkT75mpaMjAyEhYUhKyurJNtDREREpFSxi5bXr1/jm2++QdWqVdGwYUM8ffoUgPRaluXLl5d4A4mIiIiATyhaZs2ahVu3buH8+fOoXLmybHn79u1x4MCBEm0cERERUa5i36fl6NGjOHDgABwdHSESiWTLGzRogH///bdEG0dERESUq9gzLQkJCTAyMlJYnp6eLlfEEBEREZWkYhctdnZ28PPzk/2dW6j88ccfcHJyKrmWEREREeVT7NNDy5YtQ+fOnXH//n1kZWVh7dq1uHfvHgIDA3HhwoXSaCMRERFR8WdanJ2dceXKFbx+/Rr16tXD6dOnYWxsjMDAQLRo0aI02khERET0af9hYuPGjbF79+6SbgsRERFRoT6paMnOzoaPjw8ePHgAkUgEGxsb9OrVC2pq/E+jiYiIqHQUu8q4e/cuevXqhdjYWFhZWQEAwsPDYWhoCF9fXzRu3LjEG0lERERU7Gtavv32WzRs2BDR0dH4559/8M8//yAqKgpNmjTB999/XxptJCIiIir+TMutW7dw/fp16Orqypbp6upiyZIlsLOzK9HGEREREeUq9kyLlZUV4uLiFJbHx8fDwsKiRBpFREREVNBHFS1paWmyx9KlSzFhwgQcPnwY0dHRiI6OxuHDhzFp0iSsWLGitNtLRERE/1EfdXqoevXqcrfol0gkGDBggGyZRCIBAPTo0QPZ2dml0EwiIiL6r/uooiUgIKC020FERERUpI8qWtq0aVPa7SAiIiIq0iffDe7169d4+vQpMjIy5JY3adLksxtFREREVFCxi5aEhAS4u7vj5MmTSp/nNS1ERERUGor9k+dJkyYhJSUFV69eRZUqVXDq1Cns3r0b9evXh6+vb2m0kYiIiKj4My3+/v44duwY7OzsoKKiAlNTU3To0AHa2tpYtmwZunXrVhrtJCIiov+4Ys+0pKenw8jICACgp6eHhIQEANL/+fmff/4p2dYRERERvVfsmRYrKyuEhYXBzMwMtra22Lp1K8zMzLBlyxaYmJiURhsJwI7DF7HB4xziktJgZW6CJZP7wqlZ4XcgvvLPQ/y0xgdhETEQG+hg3PD2cO/7hez5PUev4OCJYDx4HAMAaGpdG3NH90Dzhmal3ZXPsu3QRaz3OIe4xFRY1zXB0in94FxUHm48xJw13gh9LM3DhBHtMbLfl3Ixvv43sXSLHyKiE2FeywBzR/dAd9empd2Vz8I8SH3T0QbjezWFcfUqCI1OweydVxEYGlto/Fdf1MOEXk1R10QHaa8zcC4kCj/tCULKq3eyGO2q6vhpcEt0dzBH9WrqeBL/Ej/tCcKZm1Fl0aVP4nHsCrYdOI/4pDTUNxNj7thesGtSt9D4oFv/YukmXzyMjIWxgTa+G+iKIT2dZc9nZmVjy75z8P7rOuISU1G3tiF+/L472thbl0V3Ptn2fMdJ62IcJ0PfHyfHFzhOhj6OwbKtfrgVFoWomGQsmdQXowa7lkVXPsuOw5ew0TP380KMnyf3g5NtvULjr/zzEPPW+iAsIlb6eTGsHdzy5WHv0b9x4GQwQnM/L6xqY87oHmje0LTU+1LQJ13TEhMjbfj8+fNx6tQp1KlTB+vWrcPSpUtLvIEE+Jy5gTmrvTHZvRMC9syAk209DJq8GdGxyUrjnzxPxODJW+BkWw8Be2ZgkltHzF55GH/6h8hirvzzCH07tsDRTRNwatsU1DLWQ/8JmxAT/6JsOvUJvE/fwOxVRzDVvRMueMyEk209DJi4CVGF5eFZIgZM2gwn23q44DETU9w7YeZvh+Hrf1MWE3z7MUbO3okBXexwad9MDOhiB/dZ23H9bmQZ9ar4mAepPs51sdTdCSuP3ESb6T4IfBCLg3M6o5ZBNaXxjtbG2DzeBXv9w+A05TDcV51F83qGWDe6tSymkpoKfH7qijpGWnBbeRb2Ew9h0tZLiElOL6tuFZtfwE0s2XgMo4e2g+/vU2DX2BzfzPwDz+NSlMZHxSTh21nbYNfYHL6/T8GoIe2weMNRnLp4WxazesdJ7P8zEPPH98GpndMxuIczxszbiXsPo8uqW8WWe5yc8v446WhbDwM/cJwcNHkLHN8fJye7dcSslYfhm+84+fptBsxqGmDemJ4w1tcuo558Hp8z/2DuGm9McusI/93T4fjBz4skDJmyFY629eC/ezomft0Bs1cdKfB58RB9O7SAz8bxOPnHFNQU6+KrieXzeVHsomXo0KFwc3MDADRr1gyRkZG4du0aoqKiMHDgwGJty83NDSKRSPbQ19dH586dcfv27Q+ue+/ePQwYMACGhobQ0NBA/fr18dNPP+H169dycWZmZrLtV6lSBdbW1vj1119ld/HN78iRI2jbti10dXVRtWpVWFlZYeTIkbh586ZCbFna7BWAoT2dMLyXMyzNxVgypR9qGOti55HLSuN3eV9BTbEulkzpB0tzMYb3csaQHo7Y6HlOFrN10dcY2b81GlvWQn0zMVbPHoycHAkuXg8rq24V26Z9/hjWywkjejvDylyMZVP7o6axLnYcvqQ0fof3ZdQS62LZ1P6wMhdjRG9nDO3piA0eeXnY4nUeLvbWmOLeCZZmYkxx74Q2dlbY7FVxb6jIPEiN6d4YHv5h2OsfhvBnLzB711U8S3yFkR0bKI1vWd8IT+Nf4feT9/A0/iWuhsZh55lQNKtrIIsZ5moFXU0NDP3lNILC4hCV+ApXQ+Nw94nyA35FsOPQRXzVxR4DuznCwtQYc8f1holRdXj6/q003uvPQNQwqo6543rDwtQYA7s5on8Xe2w7eF4Wc/TMDYwa2g4ujjaoU0MfQ3s540s7K2w/dKGMelV8m/IdJ63MxVj6/ji5o5Dj5M73x8mlU/rB6v1xcmiB42TzBqZYOKE3+nZsAXX1T75DSJna4hWAoT0c8z4vJvdDTSNd7PRWnofd3pdR01gXSybLf15s2ueft81FX2Nk/y/ff14YY/WswcjJycHF6+Fl1S2ZYhctBVWtWhXNmzeHgYHBh4OV6Ny5M2JiYhATE4Nz585BTU0N3bt3L3Kdq1evwsHBARkZGfDz80N4eDiWLl2K3bt3o0OHDgr3jlm0aBFiYmLw4MEDTJs2DbNnz8bvv/8uFzNjxgwMHDgQtra28PX1xb179/D777+jXr16mD179if1rSRkZGbhVmgUXB3kp2Vd7a0RfCdC6TrX7kTAtcA0bltHG4Q8eIrMLOU/SX/9NgNZ2dmorq38W2p5y8jMQkhoFNo62Mgtd3WwQfDtIvJQIL6dYwPcvJ+Xh+A7EWjrWCBXTjYIvv24BFtfcpgHqUpqKrCtawD/W8/klgfcfgZ7K2Ol6wSHxaGGfjV0aFYbAGCoUwW9nMxx+p+80z5dWtbBtfA4/PptK4T9MRR/r+yHKX1soaIiUrrN8paRmYW74dH4oqWV3PIvWlrhn3uRSte5ee+JQvyXLa1wNyxKNh4yMrOgoV5JLqayeiXcKOSYU96KOk5eK6TN15UcJ10/cJys6DIys3ArLAouBfLg4lB4Hq7djVSId3WwLjIPb95mICs7B7raVUum4cXwUaXjlClTPnqDq1atKlYDNDQ0IBaLAQBisRgzZsxA69atkZCQAENDQ4V4iUSCb775BjY2NvD29oaKirTuMjU1haWlJZo1a4bVq1djxowZsnW0tLRkr/Htt99i8+bNOH36NH744QcA0iLol19+wdq1azFhwgTZeubm5mjTpo3SWZmykvQiHdnZOTDU05JbbqivhfiraUrXiU9Kg6F+gXg9LWRl5yDpxSuIDXQU1lm80RcmhjpoY2el8FxFkPTiVeF5SPr0PMQnpSluU08L8UkvS7YDJYR5kNLXqgw1VRUkvJCfWU148QZG1asoXSc4PB7frwvA9sltUbmSGiqpqeDEtUhM33FFFmNqrI0vG2ni0OV/MWDZX6gn1sav37aCqqoIvx4u3xlXZVJS05GdkwMDXU255fq6mkhMVv7eJaSkQV9Xfj830NVEVnYOUlLTYaSvjS9bWmHHoQuwb1IXdWro4+9/HuLs3/eQnZNTan35HLnHSSMl+0VcMY6TRh84TlZ0yYV9XhSxLxe27xeVh0WbfCE21EHrcvi8+Kii5WNPj+T/TxU/xatXr+Dp6QkLCwvo6+srjQkJCcH9+/exb98+WcGSq2nTpmjfvj28vLzkipZcEokEFy5cwIMHD1C/fn3Zci8vL2hqamLMmDFKX/ND/Xr37h3evcu7kC8tTflO8jkKtkEiAYpqlgiK8cq2AwDr9p6F95kbOLZpAiprVFJ4viIp2HyJRFLk+1PwGQkk75fnPVPc3FYEzINUwa8TIlHeWC/IqlZ1LHd3wq+Hb8I/JBrGulWxaLg9Vn3/JSZsvggAUBGJkJj2FpO2XkJOjgS3HidCrFcN43s2qZBFi4zCgPjA8aHge11gM3PH9caclQfR0W0FRBChTg199OtshyOnrpVcm0tBaR4nhUQxD5IPjAf5v4vKw/q9Z+Fz5h8c3Ti+XD4vyv0/TDx+/Dg0NaXfEtLT02FiYoLjx48rFCS5wsOl59BsbGyUPm9jY4PLl+XP3c2YMQNz585FRkYGMjMzUblyZbkZlfDwcNStWxdqannpWLVqFebNmyf7+9mzZ9DRUV55L1u2DAsXLvyI3haffvVqUFVVUfgWnZj8EoZ6yi8MM9LXVoxPeQk1VRXo6cif/tngcQ5rdp3GkQ3j0LB+zZJtfAnSr675Pg/y3xYSk18pfEvIJc2DYryaqgr0qlfLF6OYq8K2Wd6YB6mkl2+RlZ0Do+ry09MGOlWQkPpG6TqT+9giKCwO632l18zde5qM1+8ycXJxTyzxuoa4F28Q9+I1MrNykJOTV/mER6dArFsVldRUkJlVsWYadHWqQVVFRWFWJenFK+jrKn/vDHW1FeNTpOMh9/SwfnVNbFk8Eu8yMpGS+hrGBtr49Q8/1BLrlU5HPlPucTJOyXHSqBjHyYRCjpNCoVfY50VKMY8PheRho+c5rNl9BkfWjy23z4vPvqblc7m6uiIkJAQhISEICgpCx44d0aVLFzx58gRdunSBpqYmNDU10bBhw4/anrJvnD/++CNCQkJw4cIFuLq6Ys6cOXB2dpaLKbjOyJEjERISgq1btyI9Pb3IU0SzZs1Camqq7BEVVXI/jVSvpIam1rVxPjhUbvn54DDYNzZXuo5dY3OcD5a/oDYgKBS2NnVQSU1Vtmz93rNYueMUDq4ZjWY2dUqszaVBvZIabK1rIyCoYB5CYd+kqDzIx/sHPUCzBnl5sG9srrBN/6uhsC/i56LliXmQyszKQcjjRLg2kT9wujSpieCwOKXrVFFXQ06B/Tj7fXGSu/8Hhcairlhb7ptnvRo6iElOr3AFCyAdD40sa+HyDfkLIi/fCC/09gXNGpoqxl8PQyOr2nLHBwDQUK8EsaEOsrJzcOribbRv1ahE219SijpO2hVynGz5kcdJIVGvpIamVrVxoUC/LgSHFpoHu0ZmuFAwb0rysMHjHFbu+AsH1oyCbTl+XpR70VKtWjVYWFjAwsIC9vb22L59O9LT0/HHH39g27ZtsoLmxIkTAABLS0sAwP3795VuLzQ0VO7UDwAYGBjAwsICTk5OOHLkCFavXo2zZ8/Knq9fvz7+/fdfZGZmypZVr14dFhYWqFnzw9WkhoYGtLW15R4lafRgV3gcC4SnbyDCI2IxZ/URPItLlv2OfvFGX4xZsEcW79a3FaJjkzF3jTfCI2Lh6Stdd+zQdrKYdXvPYtlWP6ybOxS1a+gjLikNcUlpePX6ncLrVxRjhrTF3mN/w8M3EGERsZi96giiY5Ph/v5+Iws3HMOo+Xl5GNn3C0TFJGPO6iMIi4iFh28gPI4FYtywvDz8MMgFAUGhWLP7DMIjY7Fm9xlcCA7F6Ap8LwbmQWrT8TsY3s4KQ10tYVmzOpZ87YhaBprYefoBAGDeEDtsHuciiz914wl62JtjZEcbmBppwcHKGMvdnXH9YTxiU6TXxuw4/QC6WhpY7u6MeiY66Ni8Nqb0scX2v5QfbyqCkV+1xqETQTh0MgiPnsTh543HEBOXgiE9nAAAv/7hh2nL9sniB/dwwvO4FCzZdAyPnsTh0MkgHDoZjG8HuMhiQh48wV8Xb+Pp8yRcu/0YI2f8DolEgu8HVdzxMCbfcTIs33Ey974rizb6YnS+46R7vuNkWCHHyYzMLNwJj8ad8GhkZGYhJiEVd8Kj8Tgqocz797FGDXaFh28gPP+Ufl7MXeON6LgUuPV5/3mxyRdjF+6VxX/d9wtEx6bgp9zPiz8D4fnnVYwZ0lYWs37vWSzbehxr5wxBbZPy/byocL/hEolEUFFRwZs3b5QWDLa2trC2tsbq1asxaNAgudNIt27dwtmzZ7Fs2bJCt6+rq4vx48dj2rRpuHnzJkQiEQYPHoz169dj06ZNmDhxYqn063P06dACKanp+G3HKcQlpsG6rgm8Vo9GbRPpVG1cUiqi892TwbSGAbxWj8LcNd7YcfgSxAbaWDq1P3q0tZXF7DxyCRmZWXCftV3utX78tgtmfNe1TPpVXH07tkByajp+2XYScYlpsKlnggNrxqBObh4S0+TuRWBa0wAH14zG7NVHsO3QJYgNdbB8Wn/0bNtMFuPQtC62L3HHks3HsXTLcZjXMsCOpSPRspFZWXfvozEPUj5/P4aepgam928OY92qeBCVjIFLTyEq8RUAwFi3qtw9W7zOP4RmZXV827khFo9wRGr6O1y6+xwLPINlMc+S0tHv55NY8rUjLv/WFzHJr7H1xD2sOXarzPv3sbq5NkNK2mts2HMG8clpsDQzwbZl36Lm+1M5CclpeJ7vfhq1TfSxbdm3WLLxGDyOXYGxvg5+GtcbnVs3kcW8y8jCqp2nEPU8CdWqqKONgw1+mzUE2prKL3KuCPp0kO4Xv74/TtrUNcH+AsfJZwWOk/vfHye3vz9OLpvaHz3zHSdjE1LhMnyF7O8NnuewwfMcWjW3gO/mivdZAQB9OjRHSmo6Vm7/C3FJ0ptPeq0alZeHxDREx+bPgz72rfoBP63xwY4jlyA20MHSKf0KfF5cRkZmNkbO3iH3Wj9+0xnTy/jzQiQpx5/GuLm5IS4uDjt37gQApKSkYMOGDdi8eTP8/f3h4uKidL0rV66gY8eO6NixI2bNmgWxWIygoCBMnToVtWvXhr+/PzQ0NABI79MyadIkTJo0SbZ+QkIC6tSpg71796J///4AgGnTpmHNmjWYMGEC+vbti9q1ayMmJgYbN26Ep6cnXrx48dEzKGlpadDR0cHzhI9f5/+VagX9qSiVD92v/ijvJlQIj3aMKO8mVAi61dTLuwkVRsFTl/81aWlpqGmki9TU1CI/N8v99NCpU6dgYmICExMTODg44Nq1azh06FChBQsAtGrVClevXoWqqiq6du0KCwsLzJo1C19//TXOnDkjK1gKY2hoiOHDh2PBggXIef8Tvt9++w379u3DzZs30b17d9SvXx9fffUVcnJyEBgY+J8vPoiIiMrbJ8207N27F1u2bEFERAQCAwNhamqKNWvWwNzcHL169SqNdgoKZ1rycKaF8uNMixRnWqQ405KHMy2lNNOyefNmTJkyBV27dsWLFy+QnS29Y1716tWxZs2aT24wERERUVGKXbSsX78ef/zxB+bMmQNV1byfQ7Vs2RJ37twp0cYRERER5Sp20RIREYFmzZopLNfQ0EB6esX9n1CJiIhI2IpdtJibmyMkJERh+cmTJ9GggfL/XZWIiIjocxX7Pi0//vgjxo4di7dv30IikSA4OBheXl5YtmwZtm3bVhptJCIiIip+0eLu7o6srCxMnz4dr1+/xpAhQ1CzZk2sXbsWgwYNKo02EhEREX3aHXG/++47fPfdd0hMTEROTg6MjIxKul1EREREcj7rNv4GBgYl1Q4iIiKiIhW7aDE3N1f4H5Hze/z48Wc1iIiIiEiZYhct+f8PHwDIzMzEzZs3cerUKfz4448l1S4iIiIiOcUuWgr7X5A3btyI69evf3aDiIiIiJQpsf8wsUuXLjhy5EhJbY6IiIhITokVLYcPH4aenl5JbY6IiIhITrFPDzVr1kzuQlyJRILY2FgkJCRg06ZNJdo4IiIiolzFLlp69+4t97eKigoMDQ3h4uICa2vrkmoXERERkZxiFS1ZWVkwMzNDp06dIBaLS6tNRERERAqKdU2LmpoaRo8ejXfv3pVWe4iIiIiUKvaFuA4ODrh582ZptIWIiIioUMW+pmXMmDGYOnUqoqOj0aJFC1SrVk3u+SZNmpRY44iIiIhyfXTRMnLkSKxZswYDBw4EAEyYMEH2nEgkgkQigUgkQnZ2dsm3koiIiP7zPrpo2b17N5YvX46IiIjSbA8RERGRUh9dtEgkEgCAqalpqTWGiIiIqDDFuhC3qP/dmYiIiKg0FetCXEtLyw8WLsnJyZ/VICIiIiJlilW0LFy4EDo6OqXVFiIiIqJCiSS5F6t8gIqKCmJjY2FkZFTabRK8tLQ06OjoIDbxBbS1tcu7OeXq40bX/z8VFZ5aBYBXb7PKuwkVgqn73vJuQoUQtWt4eTehwlD9jx8j0tLSUEesh9TU1CI/Nz/6mhZez0JERETl6aOLlo+ckCEiIiIqFR99TUtOTk5ptoOIiIioSMX+v4eIiIiIygOLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEQa28G0AfZ/vhi1i/9xziktJgXdcESyf3hVMzi0Ljr/zzEHPX+CD0cQzEBjqYMLw93Pt9IRfj6x+CpVv9EBmdCLNaBpg7qju6uzYt7a58lu2HL2KDx/s8mJtgyUfk4ac1PgiNkOZh/PD2cO+bl4fQxzFYttUPt8KiEBWTjCWT+mLUYNey6Mpn2XboItZ7nENcYqp0PEzpB+ei8nDjIeas8c4bDyPaY2S/L+VifP1vYukWP0REJ8K8lgHmju5R4cfDbp/L2Orlj/ikNFiaiTF/Qh84NK1XaHzgzUdYvOEowiNjYayvg1FD2mJ471ZyMakvX+OXP07g1IXbSH31GrVN9PDT2N5o69SgtLvzyUZ2sMa47o1gXL0KQqNfYM6eYFwNiys0vn+ruhjfozHqirWR9joD/reeYZ7nNaS8egcAGNzaAhtGf6mwXo0Re/AuM7vU+vG5dnlfxpZ842HhxA+Ph4Xr88bD6KFtMSLfeDhwIghTlnoprPfvuV9RWaNSqfShJOw8cgmb9knzYGUuxqKJfeFoW3ge/r75CAvW+SAsIhbGBjoYO7Qtvu6Td5z0O38La/ecQWR0IjKzslG3tiFGDXLFV13syqI7cjjTIgDeZ25g9ipvTHHvhPN7Z8DRth4GTNqM6NhkpfFPniVi4KQtcLSth/N7Z2CyW0fMXHkYvv4hspjg2xH4Zs5ODOxih4ueMzCwix1Gzt6B63cjy6ZTn8DnzA3MWS3NQ8AeaR4GTi4iD88TMWiyNA8Be6R5mFUgD6/fZsCspgHmjekJY33tMurJ5/E+fQOzVx3BVPdOuOAxE0629TBg4iZEFTEeBkzaDCfberjgMRNT3Dth5m+H4et/UxYTfPsxRs7eiQFd7HBp30wM6GIH91nbK/R48D33Dxau88H44R1wcvs02DetixE/bsWzuBSl8U+fJ+Hr6b/DvmldnNw+DeOGt8f8td44cf6WLCYjMwtDpmxGdEwytix2w3nP2VgxfRDEhjpl1a1i6+1ojiUj7LHq6C24zvLF1bA4HJjZATX1qymNd7AywqYxX8IzIBytfvTByLUBaFbPAGu/ly/e0l5nwGbUfrlHRS5Yjp37BwvW+WDCiA74a4d0PAybthXPYgsfD8N/lI6Hv3ZMw/gR7TFvjTf88o0HANCqVhk3jy2Se1TkguXo2X8wb60PJn3dEWd2/QiHpvUwZOqWIo6TSRg6dSscmtbDmV0/YuKIDpi72hvHA0JkMdW1q2LS1x1w/PdJCNgzA4O62mPS0n0IuPqgjHqVp0IWLW5ubujdu3eRMW/evMH8+fNhZWUFDQ0NGBgYoH///rh3755c3IIFCyASiSASiaCiooIaNWpg6NChiIqKUtjmo0ePMHLkSNSpUwcaGhqoWbMm2rVrB09PT2RlZZVkF4tl074ADOvphBG9nWFlLsayKf1Qw1gXO45cVhq/0/sKaop1sWxKP1iZizGitzOG9nDEBo9zspgt+wPgYm+FyW4dYWkmxmS3jmhtZ4Ut+wPKqlvFtskrAEN7OmF4L2keln5kHpa+z8PwXtI8bPTMy0PzBqZYOKE3+nZsAXV1YUw8btrnj2G98o2Hqf1R01gXOw5fUhq/w/syaol1sWxq/7zx0LPAePA6Dxd7a0xx7wRLMzGmuHdCGzsrbPaquOPhjwPnMbCbAwb3cEJ9MzEWTOiLGkbVsddH+XjwOHYFNY2rY8GEvqhvJsbgHk4Y2M0BW/f7y2IO+AXhRdprbFv2Deya1EUtsR7sm9RFA4uaZdWtYhvTrSE8Ax7CI+Ahwp+nYs6eYDxPSsfIDtZK41taGOFpwiv8/tcDPE14haCweOw+FwbbugZycRKJBPGpb+QeFdkf+89jUHcHDHk/HhZNlI6HPUeVj4e9R6XjYdFE6XgY8n48bPHyl4sTiQAjfW25R0W2df95DO7hiKE9nWBpJsbiSX1R00gXu32uKI3f43MFtYx1sXhSX1iaiTG0pxMGd3fA5n15+36r5vXRtU1TWJqJYVbLAN8NdEGDejUQfPtxWXVLpkIWLR/y7t07tG/fHjt27MDixYsRHh6OEydOIDs7Gw4ODrh69apcfMOGDRETE4Po6GgcOHAAd+7cwYABA+RigoOD0bx5czx48AAbN27E3bt3cfz4cYwcORJbtmxRKIbKSkZmFm6FRsHVQf4A5OpgjeDbEUrXuXYnQiG+raMNQh48RWZW9vuYSCUxhW+zvBWaB3trXLujvM3X70TA1b5AfIE8CE1GZhZCQqPQ1sFGbrmrg80HxoN8fDvHBrh5Py8PwXci0NaxwHhwsimXg9LHyMjMwp3waLQu8P62trMudHboxr1ItLYrEG9vjduhUbI8nLlyFy0ammHuqsNo1nMu2o1YjvV7ziA7O6dU+vG5KqmqoKm5PgJuP5NbHnD7OewsjZSuExwejxp61dDethYAwFCnMno4mOH0TfkvctUqV0LIuq9wZ8MA7PuxPRqb6ZVOJ0pARmYWbodHo02B97fNB8ZDwXiXAuMBANLfZMC+30K06DMfI6b/jrvh0SXe/pKSkZmF22FRcLG3klvext6q0OPkjbuRaFMg3sXBGrdClR8nJRIJLl0Pw6On8UWeciotwvhqWcCaNWsQGBiImzdvomlT6Tl3U1NTHDlyBA4ODvjmm29w9+5diEQiAICamhrEYjEAoEaNGvjuu+8wYcIEpKWlQVtbGxKJBG5ubrC0tMSVK1egopJXyzVr1gxDhw6FRCIp+44CSHqRjuzsHBjqa8ktN9LTQnxSmtJ14pPSYKQnH2+or4Ws7BwkvXgFsYHO+xj5bwxGetqIT3pZsh0oIbl5UNavuKuF50FZ3vLnQWiSXrySjgcleShqPBTMg6Ge4nhQ2KaeVoUdD8mp7/cLXfk2G+hqISFZeR4Skl7CwL5AH3WleUh+8QrGBjp4+jwJf8c+RO8OLbD71x8QEZWAuasPIzs7G5PcO5dafz6VvrYG1FRVEJ/6Vm55QuobGOtUUbrOtYfx+GHDBWyf4AKNSqqopKaCk9efYuauvC97D5+nYtyWS7j/NAVaVdTxQ5cGOLGgG9rMPIbHscrzW55yx4NBgTFsUORx8iUMHBTj848HizrGWD17CKzrmuDV67fYdugieo1eizO7pqNubcNS68+nSs79vChwbDfU00JCsvJ9OT45DYZ61gXiteXyAABpr97Attc8ZGRkQVVVBcumfYU29spn80qTIIuWffv2oUOHDrKCJZeKigomT56MoUOH4tatW7C1tVVYNzY2Ft7e3lBVVYWqqioAICQkBA8ePICXl5dcwZJfbgGkzLt37/Du3TvZ32lpJb9TiyD/+hKJdNqy0HiRYnzB7RRcXwJJkdusCJT1q8g8KMmbsu0IjcJ7J5EU2aeCz0ggeb88/3goXm4rAuVjuIg8KMmbdLn0iZwcCfSra2LFjwOhqqqCJla1EZeYiq1eARWyaMmV+37mEolQ6Bctq5o6WO7miF+9Q+B/+xmMq1fBwqF2WPmNMyb+Lj2FcP1RAq4/SpCtExQeh4ClPfFdJxvM2h1Ueh35TMXeLxR2DPnx0KKRGVo0MpM9bdfYHJ1G/oadRy5i8aR+JdHkUqGsW0Xtyor7vkRhuWZVDZzbPR3pr9/h0vVwLFh3FKY19NGqef0SavXHEeTpofDwcNjY2Ch9Lnd5eHi4bNmdO3egqamJqlWrwsTEBOfPn8fYsWNRrVo1uVgrq7wpsvj4eGhqasoemzZtKrQ9y5Ytg46OjuxRu3btz+5jLv3q1aCqqqLwbSEh5aVCNZ3LSF8bcQXiE5NfQk1VBXrVqxUak5D8UuHbdkWRmwdl/So4Y5TLSF9bad7UVFWgp6P8IsWKTr+65vvxIP+tKTH5VaHvnTQPivEFx0PBXCWmVNzxoKfzfr8o8O0xKeUVDHSVt9lQX/HbZuILaR50dfLyULe2EVRV8w6N9c2MEZ+chozM8ruurTBJae+QlZ2jMKtioF0F8Wlvla4zqVcTBIXFYcPxu7j/NAUBt5/jxx2BGOZqCePqymdnJBLg5uNE1BVXzOs5csdDQpLieCh8v9BSiE9MkR8PBamoqMDWpg4iohKUPl/e9HI/L5IV9+WCs1C5pDPsivEF86CiogLzWoZoZFkLo4e0RXfXpli/52zJd+IDKnTR4unpKVc4XLqk/ELD/JRViFZWVggJCcG1a9ewZMkS2NraYsmSJQrr5l9HX18fISEhCAkJQfXq1ZGRkVHoa86aNQupqamyh7KLfD+VeiU1NLWujfPBoXLLzweHwb6JudJ17Bqb43xwmNyygKBQ2NrUQSU11fcxZkpjCttmeSsqD3aNlbe55UfkQWjUK6nB1ro2AoIK5qHw9046HuTj/YMeoFmDvDzYNzZX2Kb/1VDYN6lbgq0vOeqV1NDYshYuXZN/fy9dC0PLfN+M82vR0Ewh/mJwKJpY15bloWVjc0Q+S0BOTt41LI+jEmCkrw31ShVvYjozOwe3IpLg0qSG3HKXxjVwLTxe6TpV1NWQU2ASJjsn97hZ+Gs1NtVD3IvXn9Xe0qJeSQ1NLGvhYsH393rR4+Hidfn4C9fkx0NBEokE9x4+q7AX46pXUkMTq9q4EFywX4UfJ1s0MsOFAnk7HxyGptZFHyclEgnelUMhX6GLlp49e8oKh5CQELRs2RIAYGlpifv37ytdJzRUeuCtXz9vykpdXR0WFhZo2LAhZs+eDVtbW4wePVr2fG5s7roAoKqqCgsLC1hYWEBNreiDlYaGBrS1teUeJWnMEFfsPRYID99AhEXEYvaqI3gWmyy738iijb4YPX+PLN69bytExyRjzmpvhEXEwsNXuu64Ye1kMT8MckFAUCjW7j6D8MhYrN19BheCwzBqUMW9R8mYwa7wOBYIz/d5mLP6CJ7FFcjDggJ5iE3G3DXSPHj6StcdOzQvD7kXdN4Jj0ZGZhZiElJxJzwajyvoNykAGDOkLfYe+1tuPETHJsP9/X1XFm44hlH5xsPIvl8gKiYZc1YfyRsPx5SPhzXvx8Oa3WdwITgUoyvwPWu+G+iC/cevYr/fVTyMjMWCdT54Fp+CYe/vs7F8y5+Y9LOHLH5Yr1aIjkvBwvU+eBgZi/1+V3HALwg/DGorixnRuxVSUl9j/lofPH4aj3N/38OGvWfwdd8vFF6/otjkdw/DXC0xxKU+LGvo4Ofh9qhpUA07z0qPZz8NaoFN+e658tc/UehuZwr39lYwNdKEvaURln/tgBuPEhCbIv2F0I/9bOHapAZMjTTRyFQP635ohUam+th1NkxpGyqC7wa5wOv4Vew/Lh0P89f54Flciuw+PMu2/IkJi/PGw/DerRAdm4IFuePh+FXsPx6EUYPzxsOqHadwPugBnjxLxN2H0Zi6zAv3Hj5TuLdPRfLDIBfs+/Mq9h2/ivDIWMxb641ncSmy+88s2fwnxi3Ky8OIPtI8zF/rg/DIWOw7fhVef17F6CF5+/66PdLjwZNniXgYGYctXgE4dPIa+ndqWeb9q3hfHfLR0tKClpbilNagQYMwZ84c3Lp1S+66lpycHKxevRoNGjRQuN4lv59++gmWlpaYPHkymjdvjmbNmsHa2hq//fYbBgwYUOh1LeWlb4cWSElNx6/bTyEuMQ029UxwYPVo1DaRXs0fl5iK6Hz3pjCtaYADa0ZhzmpvbD98CWIDbSyf2h8929rKYhya1MW2n92wdMtxLN3qB7NaBti+1L3QbyUVQZ8OLZCcmo5fd7zPQ10T7M+fh6RUuXt0mNYwwP7VozB3TV4elhXIQ2xCKlyGr5D9vcHzHDZ4nkOr5hbw3TyxzPpWHH07SvPwy7aTeeNhzRjUkY2HNLl7MpjWNMDBNaMxe/URbDt0CWJDHSyf1h892zaTxTg0rYvtS9yxZPNxLN1yHOa1DLBj6cgKPR56tmuOlLTXWLvrr/c30TLB7l9+QC1x7nhIkxsPdWroY/cv32PR+qPY43MZxgY6WDixL7q65B0rahjrwnPVKCxcfxQd3X+BsYEORvZvgzH5Ct2K5ujVCOhpaeDHvk1hXL0qHkSlYNCKM4hOTAcAGFevgpoGedP8XhcfQbNKJXzbyQaLhtkj7XUGLt2LwcJ912UxOlXVsfrbVjCqXgVprzNwJzIZ3RedwD//JpZ5/z5Wr3bNkZL6GqvzjYe9v8qPh+cFxsPeX7/HgvVHsdtbOh4WTeqLbvnGQ+qrN5j+y0EkJKdBq1oVNLKsiSMbx6NZA9My79/H6t2+OVJS07Fqx1+IT5LefNLztx/yHSfTChwn9eG58gfMX+uDnd6XYGygg58n90V3V1tZzOs3GZj52yHExKeiskYlWJgaYcP84ejdvnlZdw8iSXn9LKYIbm5uePHiBY4ePar0+bdv38LFxQXPnz/HypUr4eDggLi4OCxduhRnzpzB2bNn4ejoCEB6n5ajR48iJCREbhv9+vXDu3fvcPz4cQDA1atX0aFDBzRq1AizZs2CjY0NMjMzcfHiRUydOhXLly/H+PHjP6r9aWlp0NHRQWziixKfdRGaije6yoeKSgW/orWMvHpb8a4LKQ+m7nvLuwkVQtSu4eXdhApD9T9+jEhLS0MdsR5SU1OL/NysWFMKH6ly5crw9/fH119/jdmzZ8PCwgKdO3eGqqoqrl69KitYijJ16lT4+fkhKEh6JbyjoyNu3LgBKysrjB07Fg0aNICzszO8vLywevVqudNJREREVPYq5EyL0HGmJQ9HlxRnWqQ40yLFmRYpzrTk4UzL//FMCxEREf33sGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQVAr7wb8PxOJRBCJROXdjHL1H+8+FVBVXbW8m1AhPN4+rLybUCHU7L2qvJtQYST6/VjeTShXaqofN4fCmRYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAhq5d0A+jjbDl3Eeo9ziEtMhXVdEyyd0g/OzSwKjb9y4yHmrPFG6OMYiA10MGFEe4zs96VcjK//TSzd4oeI6ESY1zLA3NE90N21aWl35bMwD1LMg9T2wxexweMc4pLSYG1ugiWT+8KpqDz88xA/rfFBaIQ0D+OHt4d73y9kz4c+jsGyrX64FRaFqJhkLJnUF6MGu5ZFVz7LXp/L2Lo/APHJabA0E2PeuN6wb1qv0PirIY/w88ZjCI+MhbG+Nn4Y3BbDerWSPT9w4gYEhfyrsJ6row12rvi+VPpQEr7pZovx/e1hrKeJ0CeJmL3VH4H3oguN/7Z7M3zboznqGGsjOuElVu4PxIFz9+RierSyxOwRX8DcpDoiYl7g592X4Pf3w9LuymfZkW+/sCrGfhH2fr8Yp2S/WJ5vv/i5HPcLzrQIgPfpG5i96gimunfCBY+ZcLKthwETNyEqNllp/JNniRgwaTOcbOvhgsdMTHHvhJm/HYav/01ZTPDtxxg5eycGdLHDpX0zMaCLHdxnbcf1u5Fl1KviYx6kmAcpnzM3MGe1N6a4d0LAnhlwtK2HgZM3I7qwPDxPxKDJW+BoWw8Be2ZgsltHzFp5GL7+IbKY128zYFbTAPPG9ISxvnYZ9eTz/Ol/E4s2HMW44R1w4o9psGtSF24zfsezuBSl8VExSXCf8QfsmtTFiT+mYeywDli4zgcnL9ySxWxd7I5g74Wyx+ld06GqqoKuLrZl1Kvi69PaGkt/aIeV+6+izbhdCLwXjYOL+6OWoZbS+JHdbPGTe2us8LwCp1E7sNzjMn4d0wGdHfKKPTvrGtgxqycOnruHL8fswsFz97BzVk+0sDIpq24VW+5+Mfn9fuFkWw+DPrBfDJ68BU7v94tJbh0xe+Vh/FlgvzCtaYCfxvSEUTnvFxWqaHFzc4NIJJI99PX10blzZ9y+fbvQdSIjIyESiRASElJozN9//42uXbtCV1cXlStXRuPGjbFy5UpkZ2crxAYEBKBr167Q19dH1apV0aBBA0ydOhXPnj0riS5+kk37/DGslxNG9HaGlbkYy6b2R01jXew4fElp/A7vy6gl1sWyqf1hZS7GiN7OGNrTERs8zslitnidh4u9Naa4d4KlmRhT3DuhjZ0VNnsFlFW3io15kGIepDZ5BWBoTycM7yXNw9Ip/VDDWBc7jlxWGr/T+wpqinWxdEo/WJmLMbyXM4b2cMRGz7w8NG9gioUTeqNvxxZQVxfGRPS2g+cxoKsDBnV3hIWZMeaP7wMTw+rwOHZFabzHsb9Rw6g65o/vAwszYwzq7oivutrj9/1573V17Wow0teWPS5dD0cVjUro5lJxZ97G9GkJj9O3sfev2wiPSsbsrf54lvASI7s1Uxo/sG1D7D5xCz4XQ/EkNhXeF0Lhcfo2Jn7lIIsZ1bslzv8TidUHg/AwOhmrDwbhQsgTjO7dsqy6VWyb8+0XluZiLHm/X+wsZL/Y9X6/WDKlHyzf7xdDitgvNMp5v6hQRQsAdO7cGTExMYiJicG5c+egpqaG7t27f/L2fHx80KZNG9SqVQsBAQEIDQ3FxIkTsWTJEgwaNAgSiUQWu3XrVrRv3x5isRhHjhzB/fv3sWXLFqSmpmLlypUl0b1iy8jMQkhoFNo62Mgtd3WwQfDtCKXrXLsTAdcC8e0cG+Dm/afIzJIWasF3ItDW0Voupq2TDYJvPy7B1pcc5kGKeZDKyMzCrdAouDrIt9nV3hrX7ijPw/U7EXC1LxDvaIOQB3l5EJqMzCzcDY/Gl3ZWcsu/tLPCjUJmyW7ei1SIb21njTthUYXm4aBfEHq0bYaqVTRKpN0lrZKaCmzri+H/T6Tc8oB/ImDfoKbSddQrqeJtRpbcsrfvstDc0gRqqtKPRnubGgrb9L8RCXubGiXW9pJU1H4RXMh+cU3JftG2Au8XFe6rhIaGBsRiMQBALBZjxowZaN26NRISEmBoaFisbaWnp+O7775Dz5498fvvv8uWf/vttzA2NkbPnj1x8OBBDBw4ENHR0ZgwYQImTJiA1atXy2LNzMzQunVrvHjxokT6V1xJL14hOzsHhnryU5yG+lqIT0pTuk58UhoM9QvE62khKzsHSS9eQWygI40puE09LcQnvSzZDpQQ5kGKeZBKepGO7OwcGCnJQ9zVj8+DUYE8CE1Karry8aCrhcRk5XlISH4JQ13l4yEl9RWM9OXzEPLgCcIiYrBixsCSbXwJ0teuCjVVFSSkpMstT3jxGka61ZSu438jAsM7N4Ff4EPcehQH2/piDO3YGOqVVKGvXQVxKekw0q2GhBcFt5kOIz3l2yxvufuF0uNDMfaLgseHiqTCFS35vXr1Cp6enrCwsIC+vn6x1z99+jSSkpIwbdo0hed69OgBS0tLeHl5YeDAgTh06BAyMjIwffp0pduqXr16oa/z7t07vHv3TvZ3WprywfE5RCL5vyUSCUQFF+aPL/C3BJL3y/OeKbi+RKL4OhUN8yDFPEgVt80iKMYr247wFOgX8IFEFMxD7oyz4joH/IJgZW4CWxvTz2tiGcg3cQ5A2k1JwYXv/eoVCCO9ajizehhEIhHiU9LhdfYuJn7lgOycvHUUtylSWFbR/D/vFxWuaDl+/Dg0NTUBSGdKTExMcPz4caioFP9MVnh4OADAxsZG6fPW1taymIcPH0JbWxsmJsW/wGrZsmVYuHBhsdf7GPrVNaGqqqLwjTcx+ZVCNZ3LSF9babyaqgr0qlfLFyNfXCWmvCx0m+WNeZBiHqT0q1eDqqoK4gq2OfkljPSUXyiorI8JKS+ledCpmN+cP0RXR5qHhGTF985AV/l7Z6inpSReOh50C+ThzdsMHPe/ickjO5dsw0tYUtprZGXnKMyAGOhURcKL10rXeZuRhfGrT2HyutMw0q2K2OR0uHVpirTX75CUJl0n/v1si8I2C8zoVBS5+4XCvpz8EobF2C8SK/B+UeGuaXF1dUVISAhCQkIQFBSEjh07okuXLnjy5Am6dOkCTU1NaGpqomHDhh+9zcIq7fzfTj/0TbUos2bNQmpqquwRFRX1SdtRRr2SGmytayMgKFRu+fngUNg3MVe6jl1jc5wPlo/3D3qAZg3qoJKaKgDAvrG5wjb9r4bCvkndEmt7SWIepJgHKfVKamhqXVuhX+eDw2DXWHkeWjY2x/ngMLllAUGhsLXJy4PQqFdSQyPLWrh8PVxu+eXr4WjRyEzpOs0aminEX7oWhsZWtRXycDwgBO8ys9CnQ8W98BQAMrNyEPIwFq7NzOSWuzQ3Q/D9on9EkZWdg+eJr5CTI0HfNjY4HfSvbKYh+MFzuDaXn2Fq29wMwQ+el2TzS0xR+4V9IfuFncD2iwpXtFSrVg0WFhawsLCAvb09tm/fjvT0dPzxxx/Ytm2brKA5ceLEB7dlaWkJAHjw4IHS50NDQ1G/fn1ZbGpqKmJiYordZg0NDWhra8s9StKYIW2x99jf8PANRFhELGavOoLo2GS4v7/PxsINxzBq/h5Z/Mi+XyAqJhlzVh9BWEQsPHwD4XEsEOOGtZPF/DDIBQFBoViz+wzCI2OxZvcZXAgOxegKfE8K5kGKeZAaM9gVHscC4fk+D3NWH8GzuGTZ/SUWbfTF6AV5eXDv2wrRscmYu8YbYRGx8PSVrjt2aF4eMjKzcCc8GnfCo5GRmYWYhFTcCY/G46iEMu/fx/p2gAsO+F3FQb8gPIqMw6INPngen4KhPZ0BACt+P44pSzxl8cN6OeNZXAoWbziKR5FxOOgXhIMngvD9IMX3+qDfVXT8orHCDExFtMnnOoZ3aoKhHRvDsrYelnzfFrUMtbHzRAgAYJ5ba2ye2lUWX6+mLga4NkDdGrpobinG9pk9YGNqgEW7Lspith67Dtfm5pj4lT3q19LDxK/s0aaZKTYfvV7W3ftoo/PtF+H59gu39/vF4o2+GJNvv3DLt1+EC2C/qHCnhwoSiURQUVHBmzdvULOm8qvAC9OxY0fo6elh5cqVcHZ2lnvO19cXDx8+xOLFiwEA/fv3x8yZM/HLL7/IXYib68WLF0Ve11Ka+nZsgeTUdPyy7STiEtNgU88EB9aMQR0TPQBAXGKa3G/wTWsa4OCa0Zi9+gi2HboEsaEOlk/rj55t837659C0LrYvcceSzcexdMtxmNcywI6lI9GykG9nFQHzIMU8SPXpIM3DrztOSfNQ1wT7V49G7dw8JKXK3avEtIYB9q8ehblrvLH98CWIDbSxbGp/9GxrK4uJTUiFy/AVsr83eJ7DBs9zaNXcAr6bJ5ZZ34qjR9tmeJGajrV7/kJCUhoszU2wc8X3qCWW5iE+KQ3P4vPyUNtEHztXfIfFG45i79HLMNLXwfwJfdCljfzPmR9HxePanQjs/W1UmfbnU/lcDIWeVmVMH+IMY71qeBCZiIHzDiMqXnrqw1ivGmoZ5X2hVFURYWw/O1jU1ENWdg4u3XqKTlM8ZfGAdKblm+W+mDPiS8we/iUiYl5g5DJf3Agr/pfbstKnQwukpKbjt/f7hXVdE3gV2C+iC+wXXu/3ix3v94ulU/ujR4H9wjXffrHR8xw2ep6DcznsFyJJYedOyoGbmxvi4uKwc+dOAEBKSgo2bNiAzZs3w9/fHy4uLgrrREZGwtzcHPv374eVlfzP+Bo0aABfX18MGjQII0eOxLhx46CtrY1z587hxx9/RLt27XDw4EHZaaFNmzZh3LhxcHd3x4gRI2BmZobo6Gjs2bMHmpqaH/2z57S0NOjo6CAuKbXEZ12IhCwnp8IcbsrVy7dZHw76DzDrp/gF8b8q0e/H8m5CuUpLS0MNw+pITS36c7PCzbScOnVKdjGslpYWrK2tcejQIaUFS36DBg1SWBYREYH+/fsjICAAS5cuRevWrfHmzRtYWFhgzpw5mDRpktx1LGPGjIGlpSV+++039OnTB2/evIGZmRm6d++OKVOmlGg/iYiIqHgq1EzL/wvOtBApx5kWKc60SHGmJQ9nWj5upqXCXYhLREREpAyLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEtfJuABH9d6ioiMq7CRWCVmUeegEg5eT08m5ChaFrN668m1CuJNkZHxXHmRYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWgRi26GLaNprPsStJsFl+Ar8ffNRkfFXbjyEy/AVELeaBNte87HjyCWFGF//m3Ac8DOMnSfBccDPOB5wq7SaX2KYBynmQYp5kNp++CKa9Z6PGl9ORtsRvyDwQ3n45yHajvgFNb6cjOZ9FmCn92W550Mfx+DrGdtg23s+9B3GY4tXQGk2v8RwPEh90/9LhBxdgJjLqxGwZzqcbOsVGf/tV61x9eBcPL+0CsGHf8LArvYKMaMGuyD48E94fmkV7h5fjCWT+0JDXa20ulAoFi0C4H36BmavOoKp7p1wwWMmnGzrYcDETYiKTVYa/+RZIgZM2gwn23q44DETU9w7YeZvh+Hrf1MWE3z7MUbO3okBXexwad9MDOhiB/dZ23H9bmQZ9ar4mAcp5kGKeZDyOXMDc1Z7Y4p7JwTsmQFH23oYOHkzogvLw/NEDJq8BY629RCwZwYmu3XErJWH4esfIot5/TYDZjUNMG9MTxjra5dRTz4Px4NUnw7NsXRKP6zc+RfaDFuOwJB/cXDtGNQy1lUaP7LfF/hpTA+s+OMEnAYtwfKtJ/Dr9AHo/GUjWcxXnVti/the+OWPk3AY8DPGL/ZEnw4tMG9sz7LqlkyFL1rc3NzQu3fvQp93cXHBpEmTCn0+OTkZkyZNgpmZGdTV1WFiYgJ3d3c8ffpUITY2Nhbjx49H3bp1oaGhgdq1a6NHjx44d+5cCfTk023a549hvZwworczrMzFWDa1P2oa62LHYcVvBQCww/syaol1sWxqf1iZizGitzOG9nTEBo+8fmzxOg8Xe2tMce8ESzMxprh3Qhs7K2yuwN+omAcp5kGKeZDa5BWAoT2dMLyXNA9Lp/RDDWNd7DhyWWn8Tu8rqCnWxdIp/WBlLsbwXs4Y2sMRGz3z8tC8gSkWTuiNvh1bQL0cvk1/Co4HqTFD2sLjWCD2HgtEeGQcZq86gmdxKRjZ/0ul8QO72mO3zxX4nPkHT54lwfvMDXj4BmLiiA6yGLvG5gi6/RiH/7qOqJhkBASF4sjp62hmU6esuiVT4YuWz5GcnAxHR0ecPXsWmzZtwqNHj3DgwAH8+++/sLOzw+PHj2WxkZGRaNGiBfz9/fHLL7/gzp07OHXqFFxdXTF27Nhy60NGZhZCQqPQ1sFGbrmrgw2Cb0coXefanQi4Fohv59gAN+8/RWZWNgAg+E4E2jpay8W0dbJB8O3HqIiYBynmQYp5kMrIzMKt0Ci4Osi32dXeGtfuKM/D9TsRcLUvEO9og5AHeXkQGo4HqUpqqrC1rg3/oAdyywOCHsC+ibnSddQrqeFtRqbcsrfvMtG8oSnUVKUlwtWQx7C1ro3mDUwBAKY19dHBuSFOX7lXCr0omjBK6E80Z84cPH/+HI8ePYJYLAYA1KlTB3/99Rfq16+PsWPH4uTJkwCAMWPGQCQSITg4GNWqVZNto2HDhhg5cmS5tB8Akl68QnZ2Dgz1tOSWG+prIT4pTek68UlpMNQvEK+n9b/27j2siSv9A/g3QAj3W1C5RRSQm7qiooJ2q6gUdEVdddFKd6FiW9SitlJ9KiheFqtWxdqKUO8/FxUttlXX4iridcVbjVITQCpQrFBRBAQRCTm/P7KZGhOuIhD7fp5nnsfMnDk5552TycuZGQNZvRwPy6tgY22uKPNinVamuP/wcdt2oI1QHBQoDgoUB4WH5dWor5ejq4Y4/JbZ/Dh0fSEO2obGg4LQwgR6erooLVNtX+nDx+jawGW+U5lS/H3CUPz79E3cyC6Cl0d3hAT5QJ+vB6GFCX57WIlDJ65BaGmCH7Z9BB6PB76eLrZ/cxYbd59oj26peG2TFrlcjv379yMkJIRLWJQMDQ0xe/ZsxMTEoKxMcb0zLS0NcXFxKgmLkoWFRaPvVVtbi9raWu51ZaXmD8nL4PFUXzPGwHtx5fPlX3jNwP63/vctL+7PmPr7dDYUBwWKgwLFQaGlbeZBvbymerQNjQcF5fFU4vF4YC+u/J/Pt6ehq9AMJ3ZGgQfgftlj7Dt6CfNC/VEvlwMAhg3ohQUzAhC1JgXXfipET5E1Vi+YgpIHlVi3Pe0V90bVa5u0lJaWory8HB4eHhq3e3h4gDGGvDzF3eWMMbi7u2ss25TPPvsMy5cvb3VbGyO0MIGuro5aZv+grErtLwClrkIzjeX1dHVgZWH8XBnV5OrBo8cN1tnRKA4KFAcFioOC0MIYuro6+O3FNpc9RlcrzX9Za+pj6aPHijiYq//Rpg1oPCg8LK+CTFaPri/MIFlbmajNvig9ra1D5MpkfLRqH7oKzVDyoAJhfx2GyqoaPCyvBgBER/wFB45dxp7vLwIAJD/fg7GhAPGL38b6HccbTIheBa25pyU5ORkmJibccu6c5purmksZ5Ocz0Nb+lfHpp5+ioqKCW4qKil6qbc/T5+vBy12EjEvZKutPX85u8BrloL49cfqyavlTl6To79kdfD1dAMDgvj3V6jyVmY3Bf3Jqs7a3JYqDAsVBgeKgoM/XQz93kVq/Tl/OwaC+muPg3bcnTl/OUVmXcSkbXh6/x0Hb0HhQqJPVQ6zhHqcRg90bvLdHSVYvx7375ZDLGSa9NRD/OX+L+240NNCHXK6amNTXy8FD+886aU3SMn78eIjFYm7x9vZutHyXLl1gYWEBiUSicXt2djZ4PB6cnZ3Rq1cv8Hg8SKVSjWWbIhAIYGZmprK0pdnTR2LP9//Fvw5fRE5+CRZvSMXdkjK8O1lxN/jyr75HROz/ceVnTHoDRcVliI5PRU5+Cf51+CL+9f1FfPjOKK7MB9NGIONSNjbuPoHcghJs3H0CZy5nY9bbfm3a9rZEcVCgOChQHBRmv+2Hf31/Ecn/i0N0fCp+/a0M7056AwCwYvNhzFr2exzenTQMd0vKELPxEHLyS5B8WLHvnJDf4/CsToas3LvIyr2LZ3UyFJdWICv3Lu4UlbZ7/5qLxoNCwt5T3BNhrj26Ie6jSXCwscLO//0fNEvnjMeWZX/nyjt374rgMYPgJOqCAZ6O2B73Ljyc7LAi4TBXJu3cT3h38huY5D8Q3e2EGDHYHYsjxuGHc1lqycyrpjWXh0xNTWFq2vwpOR0dHQQHByM5ORkrVqxQua+lpqYGCQkJCAgIgJWVFQAgICAAmzdvxty5c9XuaykvL2/yvpZXadJbA1FWUY21237Abw8q4eFsi5SNs9HdVtH23x5UqvyfDI721jiwcRYWx6di28FzsOlijtVRUzB+ZH+uzJB+Ttge9y7ithzFqsSj6OlgjR2rZsC7T4/27l6zURwUKA4KFAeFv/or4vD5jjRFHJxssT9+FkTKODyswK+/PeLKO9pZY398BGI2HsL2b87BxtoMny2YgvEjvbgyJaUVGPH3Ndzrr5LT8VVyOoYNcMHhLfParW8tQeNB4dsTP8LK3BgLZ45BN2szSH8uxtT5CSgqUYyBbtZmcLCx4srr6vAwJ2QkXBy7QSarx7mruQiYuR5Fxb/Hat2ONDDGED1rHGy7mONheRXSzv2ElQlH2r1/PNaeF6NaISwsDOXl5fjuu+80bh8xYgTs7e3xySefqKy3sbGBnp4efHx8YGhoiLVr16JPnz7Iz89HTEwMcnJycPHiRTg5Kab58vPzMXToUFhZWWHFihX405/+BJlMhhMnTmDLli0tmoWprKyEubk5fntY0eazLoQQ7dfef512Vjo6nfyO1nZkOejDjm5Ch2L1z1CbtRUVFY1/b2rN5aHG7N27F/3791dZEhMTYW1tjczMTPj5+eGDDz6Ak5MTgoOD4eTkhCtXrnAJCwD07NkTP/74I/z8/LBgwQL06dMH/v7+SE9Px5YtWzqwd4QQQggBtGCmRRvRTAshpDE006JAMy2/o5mWP9BMCyGEEEJef5S0EEIIIUQrUNJCCCGEEK1ASQshhBBCtAIlLYQQQgjRCpS0EEIIIUQrUNJCCCGEEK1ASQshhBBCtAIlLYQQQgjRCpS0EEIIIUQrUNJCCCGEEK1ASQshhBBCtAIlLYQQQgjRCpS0EEIIIUQrUNJCCCGEEK1ASQshhBBCtAIlLYQQQgjRCpS0EEIIIUQrUNJCCCGEEK1ASQshhBBCtAIlLYQQQgjRCpS0EEIIIUQrUNJCCCGEEK1ASQshhBBCtAIlLYQQQgjRCnod3YDXEWMMAPC4srKDW0II6YzkctbRTegUdHR4Hd2EToPVP+voJnQoZf+V358NoaTlFXj8+DEAwKWnqINbQgghhGiPx48fw9zcvMHtPNZUWkNaTC6X4969ezA1NQWP1zF/SVRWVkIkEqGoqAhmZmYd0obOgOKgQHFQoDgoUBwUKA4KnSEOjDE8fvwYdnZ20NFp+M4Vmml5BXR0dODg4NDRzQAAmJmZ/aE/jEoUBwWKgwLFQYHioEBxUOjoODQ2w6JEN+ISQgghRCtQ0kIIIYQQrUBJy2tKIBAgNjYWAoGgo5vSoSgOChQHBYqDAsVBgeKgoE1xoBtxCSGEEKIVaKaFEEIIIVqBkhZCCCGEaAVKWgghhBCiFShpIYQQQohWoKTlNVNUVITw8HDY2dlBX18fjo6OmDdvHh4+fNjRTWu2sLAw8Hg8bhEKhQgMDMTNmzcb3KegoEBlH0tLS7z55ps4c+ZMg/Uql8DAQK5Mjx49uPWGhoZwd3fH559/3uTvYbxqYWFhmDhxYoPbR4wYwbVbIBDA1dUVq1atQn19PQDg9OnTGvvO4/FQUlICAFi2bBm3TkdHB3Z2dggJCUFRUVF7dFFNa8aB0q1btxAcHIwuXbpAIBCgV69eWLJkCZ48eaJSriXHOzU1FSNHjoSlpSWMjIzg5uaGGTNm4Pr1623W56Y0NQ4AoKamBrGxsXBzc4NAIIC1tTWmTJmCW7duqZRryfHOy8vDjBkz0L17dwgEAtjb22PUqFFITk6GTCZryy426WXOD2KxuMEy//3vfzF27FhYWlrCwMAAffv2xfr167nP0PMyMjIwduxYCIVCGBkZwdPTEwsWLMCvv/7aFl1sseacH+bPn9/g9rKyMsyfPx89evSAvr4+bG1t8e677+KXX35RK1tSUoLIyEg4OTlBIBBAJBIhKCgI6enpbdCTplHS8hq5c+cOvL29kZubi3379iEvLw+JiYlIT0+Hr68vysrKOrqJzRYYGIji4mIUFxcjPT0denp6GDduXJP7nTx5EsXFxThz5gzMzMwwduxY5Ofna6xXuezbt0+ljhUrVqC4uBhSqRRRUVFYvHgxvv766zbvY1t77733UFxcjJycHMydOxcxMTFYt26dSpmcnBy1/nft2pXb3rt3bxQXF+Pu3btISUlBVlYWgoOD27srnNaMg8zMTAwZMgTPnj3Dv//9b+Tm5mLVqlXYvXs3/P398eyZ6g/TNed4L1q0CFOnToWXlxcOHz6MW7du4euvv4azszMWL17c5v1urdraWowePRo7duzAypUrkZubi2PHjqG+vh5DhgxBZmamSvnmHO/Lly9jwIABkEql2Lx5M3766SccPXoUM2bMQGJioloy1B5ae35oyLfffovhw4fDwcEBGRkZyM7Oxrx58xAXF4dp06apJLFJSUkYPXo0bGxskJqaColEgsTERFRUVGD9+vVt0b12VVZWBh8fH5w8eRIJCQnIy8tDSkoKfv75ZwwaNAh37tzhyhYUFGDgwIE4deoU1q5di6ysLKSlpcHPzw9z5sxpnwYz8toIDAxkDg4O7MmTJyrri4uLmZGREYuIiOiglrVMaGgomzBhgsq6s2fPMgDs/v37GvfJz89nANj169e5dXfv3mUAWGJiYoP1vsjR0ZHFx8errBswYACbNGlSS7vRpppq+/Dhw9m8efNU1o0ePZr5+PgwxhjLyMhgANijR48arCM2Npb169dPZd2mTZsYAFZRUdHKlrdea8aBXC5nnp6ezNvbm9XX16tsE4vFjMfjsdWrV3PrmnO8L168yACwL774osH3bC9NjYPVq1czHo/HxGKxyvr6+nrm7e3NPD09ufY253jL5XLm4eHBBg4cqBZPpfbsP2Ntd35QqqqqYkKhUONn/PDhwwwA279/P2OMsaKiIqavr8/mz5+v8X0a+3y9Sq05PyhFREQwY2NjVlxcrLL+yZMnzN7engUGBnLrxowZw+zt7VlVVZVaPe3Vd5ppeU2UlZXh+PHjmD17NgwNDVW22djYICQkBCkpKR1+maM1qqqqkJycDBcXFwiFwmbvZ2RkBACoq6tr1fsyxnD69GlIpVLw+fxW1dGRDA0NW913QDENfOjQIejq6kJXV7cNW9Y6zRkHYrEYEokEH3/8sdqPrvXr1w+jR49Wm1lTauh479u3DyYmJpg9e7bG/TrqR1E12bt3L/z9/dGvXz+V9To6Ovjoo48gkUhw48YNjftqOt5isZibgWroR+w6uv+tPT8o/ec//8HDhw8RFRWlti0oKAiurq7cmDl48CCePXuGhQsXaqzLwsKixe/fkeRyOfbv34+QkBDY2NiobDM0NMTs2bNx/PhxlJWVoaysDGlpaZgzZw6MjY3V6mqvvlPS8pq4ffs2GGPw8PDQuN3DwwOPHj1CaWlpO7esdY4ePQoTExOYmJjA1NQUhw8fRkpKSqO//vm86upqfPrpp9DV1cXw4cM11qtcVq5cqbLvokWLYGJiAoFAAD8/PzDGMHfu3Dbt36skl8uRlpaG48ePY9SoUSrbHBwcVPru5uamsj0rKwsmJiYwMjKCra0tTp8+3eBJqj20dBzk5uYCQKOfA2UZpaaOd25uLpycnKCn9/vvy27YsEEljhUVFS/b1TaRm5vbaN+VZZSaOt7Kss+Pk/v376v0PSEh4VV1p0Eve354XlNjxt3dnStz+/ZtmJmZwdbWtvWN70RKS0tRXl7e6JhhjCEvLw95eXlgjMHd3b2dW6mKkpY/COUMS0f/VdRcfn5+EIvFEIvFuHTpEt566y2MGTMGhYWFGDNmDHfC6t27t8p+Q4cO5U5kR44cwa5du9C3b1+N9SqXF6/FfvLJJxCLxThz5gz8/PwQHR2NoUOHtku/m5KcnKzyhXHu3DluW0JCAkxMTGBgYIDx48fjnXfeQWxsrMr+586dU+n78ePHVba7ublBLBbjypUriIuLg5eXF+Li4tqlb5q0dhw0hDGm9hlozvF+cZ8ZM2ZALBYjKSkJ1dXV7T6D2dg4aIimc0Bzj/fz+wiFQu6YWFhYqN0j1B7aelwAaPAYPj9mNI2fzqQ146Ixz4+ZzvIdotd0EaINXFxcwOPxIJFINN5Fnp2dDUtLS1hbW7d/41rB2NgYLi4u3OuBAwfC3NwcW7duxbZt21BTUwMAapdtUlJS4OnpCQsLC41TxS/Wq4m1tTVcXFzg4uKC1NRUuLi4wMfHB6NHj26Dnr2c8ePHY8iQIdxre3t77t8hISGIjo6GQCCAnZ2dxks6PXv2bHQaV19fn4tP7969cfv2bcyaNQt79uxpu060QEvHgaurKwBAIpHAy8tLrb7s7Gz06tVLZV1Tx7tXr144f/486urquPexsLCAhYUF7t692+Z9bo6GxoGrqyskEonGfbKzswFApf9NHW9l2ezsbC6eurq63D7Pzz61p9aeHzRRjhmpVKrxj5Ps7Gx4enpyZSsqKlBcXNwpZ1saOz9o0qVLF1hYWDQ6Zng8HpydnQEoEhapVNrkE2yvEs20vCaEQiH8/f2RkJDAfWCVSkpKkJycjKlTp3Z4ltxayscya2pqYG9vz33JODo6qpQTiURwdnZu1bVtTSwtLREZGYmoqKhOcT+Qqakp13cXFxeV+5fMzc3h4uICkUjUZvegLFmyBPv27cOPP/7YJvW9rKbGgZeXF9zd3REfHw+5XK6y740bN3Dy5Em8/fbbDdav6Xi//fbbqKqq6pDLIA1paBxMmzYNJ0+eVLtvRS6XIz4+Hp6enmr3uzzvxePdv39/uLu7Y926dWrx7Eyae37Q5K233oKVlZXGJ38OHz6M27dvc2NmypQp0NfXx9q1azXWVV5e/lL9eFmNnR800dHRQXBwMPbu3cv91wdKNTU1SEhIQEBAAKysrGBlZYWAgABs3rwZ1dXVanW1V98paXmNfPXVV6itrUVAQADOnj2LoqIipKWlwd/fH/b29h06zd9StbW1KCkpQUlJCaRSKSIjI1FVVYWgoKA2q1e5PHjwoNF95syZg5ycHKSmpr7Ue3cG9+/fV+t/YzfrOjk5YcKECVi6dGk7tvJ3LR0HPB4P27Ztg0QiweTJk3H58mX88ssvOHjwIIKCguDr69vo/1cBqB9vX19fLFiwAAsWLMDHH3+M8+fPo7CwEJmZmdi+fTv3hdkZfPTRRxg8eDCCgoJw8OBB/PLLL7hy5QomT54MqVTKtbchLx5vHo+HnTt3IicnB8OGDeO+xJWP+ZaWlnbITdqtPT/k5OSoXR7m8/lISkrC999/j/fffx83b95EQUEBtm/fjrCwMEyZMoV7DFwkEiE+Ph5ffPEFwsPDcebMGRQWFuLChQv44IMP1O6P60xKS0vV+l5SUoK4uDjY2NjA398fP/zwA4qKinD27FkEBASgrq4Omzdv5upISEhAfX09Bg8ejNTUVNy+fRtSqRSbNm2Cr69v+3SkXZ5RIu2moKCAhYWFMRsbG8bn85lIJGKRkZHswYMHHd20ZgsNDWUAuMXU1JQNGjSIffPNNw3u09gjjQ3Vq1zc3Ny4MpoegWWMsffee4/17t27wcc+X7WXeaSRsd8feda0XLx4kTGm+RFYxhi7cOECA8AyMzNfshct05pxoHTz5k02efJkJhQKGZ/PZ87OziwmJoZVV1erlGvJ8U5JSWEjRoxg5ubmjM/nMwcHBzZ9+vR2jUtzHtuvrq5mMTExzMXFhfH5fGZlZcUmT57MsrKyVMq15Hjn5OSw0NBQ5uDgwPT09Ji5uTl78803WVJSEqurq2uLrjXby5wfNC35+fmMMcVj04GBgczc3Jzp6+szT09Ptm7dOiaTydTqO3HiBAsICGCWlpbMwMCAubu7s6ioKHbv3r1X1e1GNef8oKnvsbGxjDHGSktLWWRkJBOJRExPT49169aNhYaGssLCQrW67t27x+bMmcMcHR2Zvr4+s7e3Z+PHj2cZGRmvpnMv4DHWCea8CSGEEEKa0DnmNAkhhBBCmkBJCyGEEEK0AiUthBBCCNEKlLQQQgghRCtQ0kIIIYQQrUBJCyGEEEK0AiUthBBCCNEKlLQQQgghRCtQ0kII6VSWLVum8mOHYWFhHfIDbQUFBeDxeBCLxQ2W6dGjBzZu3NjsOnft2tXoD1Y2F4/Hw3fffffS9RCibShpIYQ0KSwsDDweDzweD3w+H05OToiKitL4w2lt7YsvvsCuXbuaVbY5iQYhRHt1zO+KE0K0TmBgIHbu3Im6ujqcO3cOM2fORHV1NbZs2aJWtq6uDnw+v03e19zcvE3qIYRoP5ppIYQ0i0AggI2NDUQiEaZPn46QkBDuEoXyks6OHTvg5OQEgUAAxhgqKirw/vvvo2vXrjAzM8PIkSNx48YNlXpXr16Nbt26wdTUFOHh4Xj69KnK9hcvD8nlcqxZswYuLi4QCATo3r079wvmPXv2BAD0798fPB4PI0aM4PbbuXMnPDw8YGBgAHd3dyQkJKi8z+XLl9G/f38YGBjA29sb169fb3GMNmzYgL59+8LY2BgikQizZ89GVVWVWrnvvvsOrq6uMDAwgL+/P4qKilS2HzlyBAMHDoSBgQGcnJywfPlyyGSyFreHkNcNJS2EkFYxNDREXV0d9zovLw8HDhxAamoqd3nmL3/5C0pKSnDs2DFcu3YNAwYMwKhRo1BWVgYAOHDgAGJjYxEXF4erV6/C1tZWLZl40aeffoo1a9ZgyZIlkEgk2Lt3L7p16wZAkXgAwMmTJ1FcXIxDhw4BALZu3Yro6GjExcVBKpVi1apVWLJkCXbv3g0AqK6uxrhx4+Dm5oZr165h2bJliIqKanFMdHR0sGnTJvz000/YvXs3Tp06hYULF6qUefLkCeLi4rB7925cuHABlZWVmDZtGrf9+PHjeOeddzB37lxIJBIkJSVh165dXGJGyB9au/yWNCFEq4WGhrIJEyZwry9dusSEQiELDg5mjDEWGxvL+Hw+u3//PlcmPT2dmZmZsadPn6rU5ezszJKSkhhjjPn6+rKIiAiV7UOGDGH9+vXT+N6VlZVMIBCwrVu3amxnfn4+A8CuX7+usl4kErG9e/eqrFu5ciXz9fVljDGWlJTErKysWHV1Nbd9y5YtGut6nqOjI4uPj29w+4EDB5hQKORe79y5kwFgmZmZ3DqpVMoAsEuXLjHGGPvzn//MVq1apVLPnj17mK2tLfcaAPv2228bfF9CXld0TwshpFmOHj0KExMTyGQy1NXVYcKECfjyyy+57Y6OjujSpQv3+tq1a6iqqoJQKFSpp6amBj///DMAQCqVIiIiQmW7r68vMjIyNLZBKpWitrYWo0aNana7S0tLUVRUhPDwcLz33nvceplMxt0vI5VK0a9fPxgZGam0o6UyMjKwatUqSCQSVFZWQiaT4enTp6iuroaxsTEAQE9PD97e3tw+7u7usLCwgFQqxeDBg3Ht2jVcuXJFZWalvr4eT58+xZMnT1TaSMgfDSUthJBm8fPzw5YtW8Dn82FnZ6d2o63yS1lJLpfD1tYWp0+fVqurtY/9GhoatngfuVwOQHGJaMiQISrbdHV1AQCMsVa153mFhYUYO3YsIiIisHLlSlhZWeH8+fMIDw9XuYwGKB5ZfpFynVwux/LlyzFp0iS1MgYGBi/dTkK0GSUthJBmMTY2houLS7PLDxgwACUlJdDT00OPHj00lvHw8EBmZib+8Y9/cOsyMzMbrLNXr14wNDREeno6Zs6cqbZdX18fgGJmQqlbt26wt7fHnTt3EBISorFeT09P7NmzBzU1NVxi1Fg7NLl69SpkMhnWr18PHR3F7YIHDhxQKyeTyXD16lUMHjwYAJCTk4Py8nK4u7sDUMQtJyenRbEm5I+CkhZCyCsxevRo+Pr6YuLEiVizZg3c3Nxw7949HDt2DBMnToS3tzfmzZuH0NBQeHt744033kBycjJu3boFJycnjXUaGBhg0aJFWLhwIfT19TFs2DCUlpbi1q1bCA8PR9euXWFoaIi0tDQ4ODjAwMAA5ubmWLZsGebOnQszMzOMGTMGtbW1uHr1Kh49eoSPP/4Y06dPR3R0NMLDwxETE4OCggKsW7euRf11dnaGTCbDl19+iaCgIFy4cAGJiYlq5fh8PiIjI7Fp0ybw+Xx8+OGH8PHx4ZKYpUuXYty4cRCJRPjb3/4GHR0d3Lx5E1lZWfjnP//Z8gNByGuEnh4ihLwSPB4Px44dw5tvvokZM2bA1dUV06ZNQ0FBAfe0z9SpU7F06VIsWrQIAwcORGFhIWbNmtVovUuWLMGCBQuwdOlSeHh4YOrUqbh//z4Axf0imzZtQlJSEuzs7DBhwgQAwMyZM7Ft2zbs2rULffv2xfDhw7Fr1y7uEWkTExMcOXIEEokE/fv3R3R0NNasWdOi/np5eWHDhg1Ys2YN+vTpg+TkZHz22Wdq5YyMjLBo0SJMnz4dvr6+MDQ0xP79+7ntAQEBOHr0KE6cOIFBgwbBx8cHGzZsgKOjY4vaQ8jriMfa4mIuIYQQQsgrRjMthBBCCNEKlLQQQgghRCtQ0kIIIYQQrUBJCyGEEEK0AiUthBBCCNEKlLQQQgghRCtQ0kIIIYQQrUBJCyGEEEK0AiUthBBCCNEKlLQQQgghRCtQ0kIIIYQQrfD/mAAMorx+vFMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    _, ax = plt.subplots(figsize=(6,6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Matriz de confusão normalizada\")\n",
    "    plt.show()\n",
    "plot_confusion_matrix(df_tokens[\"labels\"], df_tokens[\"predicted_label\"], tags.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora analisamos a nível de token, vamos avaliar alguns exemplos (sequências). Para isso, voltamos para nosso dataset não explodido e somamos as losses de cada token na sequência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(df):\n",
    "    for _, row in df.iterrows():\n",
    "        labels, preds, tokens, losses = [], [], [], []\n",
    "        for i, _ in enumerate(row[\"attention_mask\"]):\n",
    "            if i not in {0, len(row[\"attention_mask\"])}:\n",
    "                labels.append(row[\"labels\"][i])\n",
    "                preds.append(row[\"predicted_label\"][i])\n",
    "                tokens.append(row[\"input_tokens\"][i])\n",
    "                losses.append(f\"{row['loss'][i]:.2f}\")\n",
    "        df_tmp = pd.DataFrame({\"tokens\": tokens, \"labels\": labels, \"preds\": preds, \"losses\": losses}).T\n",
    "        yield df_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo podemos ver os 2 registros com maior loss total. Algumas coisas interessantes nesses registros:\n",
    "- Temos um token `_alt` classificado `B-ORG`, mas é uma classificação errada, assim como `Justin Timberlake` não é uma organização, nosso modelo na verdade está correto. Isso pode acontecer, visto que os dados do PAN-X foram gerados em um process automático. Essas classificações são consideradas \"padrão prata\", contrastando com as classificações \"padrão ouro\" feitas por humanos. Mesmo com classificações \"padrão ouro\", ainda podemos ter erros nos labels dos nossos dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁alt</td>\n",
       "      <td>=</td>\n",
       "      <td>High</td>\n",
       "      <td>▁school</td>\n",
       "      <td>▁building</td>\n",
       "      <td>▁with</td>\n",
       "      <td>▁a</td>\n",
       "      <td>▁two</td>\n",
       "      <td>-</td>\n",
       "      <td>story</td>\n",
       "      <td>...</td>\n",
       "      <td>ground</td>\n",
       "      <td>▁and</td>\n",
       "      <td>▁a</td>\n",
       "      <td>▁round</td>\n",
       "      <td>▁auditori</td>\n",
       "      <td>um</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁the</td>\n",
       "      <td>▁background</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>...</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>1.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4.51</td>\n",
       "      <td>7.72</td>\n",
       "      <td>8.10</td>\n",
       "      <td>7.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.25</td>\n",
       "      <td>8.16</td>\n",
       "      <td>6.11</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.31</td>\n",
       "      <td>8.11</td>\n",
       "      <td>7.92</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1      2        3          4      5      6      7     8   \\\n",
       "tokens   ▁alt     =   High  ▁school  ▁building  ▁with     ▁a   ▁two     -   \n",
       "labels  B-ORG   IGN    IGN    I-ORG      I-ORG  I-ORG  I-ORG  I-ORG   IGN   \n",
       "preds       O     O  B-ORG    I-ORG          O      O      O      O     O   \n",
       "losses   1.83  0.00   0.00     0.80       4.51   7.72   8.10   7.02  0.00   \n",
       "\n",
       "           9   ...      20     21     22      23         24    25     26  \\\n",
       "tokens  story  ...  ground   ▁and     ▁a  ▁round  ▁auditori    um    ▁in   \n",
       "labels    IGN  ...     IGN  I-ORG  I-ORG   I-ORG      I-ORG   IGN  I-ORG   \n",
       "preds       O  ...       O      O      O       O          O     O      O   \n",
       "losses   0.00  ...    0.00   8.25   8.16    6.11       3.02  0.00   7.31   \n",
       "\n",
       "           27           28    29  \n",
       "tokens   ▁the  ▁background  </s>  \n",
       "labels  I-ORG        I-ORG   IGN  \n",
       "preds       O            O     O  \n",
       "losses   8.11         7.92  0.00  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁National</td>\n",
       "      <td>▁Register</td>\n",
       "      <td>▁of</td>\n",
       "      <td>▁Historic</td>\n",
       "      <td>▁Place</td>\n",
       "      <td>s</td>\n",
       "      <td>▁list</td>\n",
       "      <td>ings</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁Ja</td>\n",
       "      <td>sper</td>\n",
       "      <td>▁County</td>\n",
       "      <td>▁</td>\n",
       "      <td>,</td>\n",
       "      <td>▁Texas</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>7.15</td>\n",
       "      <td>8.77</td>\n",
       "      <td>8.67</td>\n",
       "      <td>8.62</td>\n",
       "      <td>8.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.73</td>\n",
       "      <td>8.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.25</td>\n",
       "      <td>8.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.38</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1      2          3       4      5      6      7   \\\n",
       "tokens  ▁National  ▁Register    ▁of  ▁Historic  ▁Place      s  ▁list   ings   \n",
       "labels      B-LOC      I-LOC  I-LOC      I-LOC   I-LOC    IGN  I-LOC    IGN   \n",
       "preds       B-ORG      I-ORG  I-ORG      I-ORG   I-ORG  I-ORG  I-ORG  I-ORG   \n",
       "losses       7.15       8.77   8.67       8.62    8.61   0.00   8.65   0.00   \n",
       "\n",
       "           8      9      10       11     12     13      14     15  \n",
       "tokens    ▁in    ▁Ja   sper  ▁County      ▁      ,  ▁Texas   </s>  \n",
       "labels  I-LOC  I-LOC    IGN    I-LOC  I-LOC    IGN   I-LOC    IGN  \n",
       "preds   I-ORG  I-ORG  I-ORG    I-ORG  I-ORG  I-ORG   I-ORG  I-ORG  \n",
       "losses   8.73   8.66   0.00     8.25   8.32   0.00    8.38   0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"total_loss\"] = df[\"loss\"].apply(sum)\n",
    "df_tmp = df.sort_values(by=\"total_loss\", ascending=False).head(2)\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme vimos anteriormente, parênteses tinham uma loss relativamente alta, vamos ver alguns exemplos?\n",
    "<br> Em geral os parênteses e seus conteúdos não fazem parte das entidades nomeadas, mas em alguns casos parece que isso está acontecendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Long</td>\n",
       "      <td>est</td>\n",
       "      <td>▁stretch</td>\n",
       "      <td>es</td>\n",
       "      <td>▁are</td>\n",
       "      <td>▁Helsinki</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁Main</td>\n",
       "      <td>▁road</td>\n",
       "      <td>▁1</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Main</td>\n",
       "      <td>▁road</td>\n",
       "      <td>▁7</td>\n",
       "      <td>▁/</td>\n",
       "      <td>▁E</td>\n",
       "      <td>18</td>\n",
       "      <td>▁)</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>...</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>...</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.05</td>\n",
       "      <td>6.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1         2     3     4          5     6      7      8   \\\n",
       "tokens  ▁Long   est  ▁stretch    es  ▁are  ▁Helsinki    ▁(  ▁Main  ▁road   \n",
       "labels      O   IGN         O   IGN     O      B-LOC     O  B-ORG  I-ORG   \n",
       "preds       O     O         O     O     O      B-ORG     O  B-ORG  I-ORG   \n",
       "losses   0.00  0.00      0.00  0.00  0.00       1.40  0.42   0.05   0.00   \n",
       "\n",
       "           9   ...     41     42     43     44     45     46     47    48  \\\n",
       "tokens     ▁1  ...  ▁Main  ▁road     ▁7     ▁/     ▁E     18     ▁)     ▁   \n",
       "labels  I-ORG  ...  B-ORG  I-ORG  I-ORG      O  B-ORG    IGN      O     O   \n",
       "preds   I-ORG  ...  B-ORG  I-ORG  I-ORG  I-ORG  I-ORG  I-ORG  I-ORG     O   \n",
       "losses   0.00  ...   0.13   0.00   0.00   6.05   6.94   0.00   0.80  0.00   \n",
       "\n",
       "          49     50  \n",
       "tokens     .   </s>  \n",
       "labels   IGN    IGN  \n",
       "preds      O  I-ORG  \n",
       "losses  0.00   0.00  \n",
       "\n",
       "[4 rows x 51 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁'</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁Justin</td>\n",
       "      <td>▁Tim</td>\n",
       "      <td>ber</td>\n",
       "      <td>la</td>\n",
       "      <td>ke</td>\n",
       "      <td>▁-</td>\n",
       "      <td>▁Mirror</td>\n",
       "      <td>s</td>\n",
       "      <td>...</td>\n",
       "      <td>▁40</td>\n",
       "      <td>▁1</td>\n",
       "      <td>▁</td>\n",
       "      <td>,</td>\n",
       "      <td>▁February</td>\n",
       "      <td>▁11</td>\n",
       "      <td>▁)</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>...</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>...</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>5.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.52</td>\n",
       "      <td>7.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>5.17</td>\n",
       "      <td>6.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.95</td>\n",
       "      <td>6.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1        2      3      4      5      6      7        8   \\\n",
       "tokens    ▁'   ▁''  ▁Justin   ▁Tim    ber     la     ke     ▁-  ▁Mirror   \n",
       "labels     O     O    B-ORG  I-ORG    IGN    IGN    IGN  I-ORG    I-ORG   \n",
       "preds      O     O    B-PER  I-PER  I-PER  I-PER  I-PER      O    B-ORG   \n",
       "losses  0.00  0.00     4.25   5.03   0.00   0.00   0.00   7.52     7.46   \n",
       "\n",
       "           9   ...     13     14     15    16         17     18     19    20  \\\n",
       "tokens      s  ...    ▁40     ▁1      ▁     ,  ▁February    ▁11     ▁)   ▁''   \n",
       "labels    IGN  ...  I-ORG  I-ORG  I-ORG   IGN      I-ORG  I-ORG  I-ORG     O   \n",
       "preds   I-ORG  ...  I-ORG      O      O     O          O      O      O     O   \n",
       "losses   0.00  ...   0.07   5.17   6.87  0.00       7.00   5.95   6.91  0.00   \n",
       "\n",
       "          21    22  \n",
       "tokens    ▁'  </s>  \n",
       "labels     O   IGN  \n",
       "preds      O     O  \n",
       "losses  0.00  0.00  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tmp = df.loc[\n",
    "    df[\"input_tokens\"].apply(lambda x: u\"\\u2581(\" in x)\n",
    "].sort_values(by=\"total_loss\", ascending=False).head(2)\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com algumas análises simples, já conseguimos identificar fraquezas e forças dentro do nosso modelo e dos nossos dados. Agora podemos iterar sobre ele para limpar nossos labels, nossos dados, fazer otimização de hiperparâmetro como fizemos no modelo de análise de sentimento da aula passada, reanalisar os errors, e ir cada vez melhorando mais nosso modelo até estarmos satisfeitos com seus performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O que você viu nessa aula?\n",
    "\n",
    "Nessa aula, vimos o que é e como treinar um NER, que é uma tarefa muito comum em classificação de textos. Usamos o BERT para fine-tuning de modelos em português e conseguimos bons resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
