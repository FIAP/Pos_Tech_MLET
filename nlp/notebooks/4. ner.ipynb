{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP\n",
    "### Reconhecimento de Entidades Nomeadas (NER)\n",
    "<b>Objetivo: </b> Entender como modelar e treinar modelos para reconhecimento de entidade nomeada.\n",
    "<br><b>Autora:</b> Renata Gotler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos de Reconhecimento de Entidades Nomeadas visam extrair do texto informa√ß√µes categorizadas como:\n",
    "- Pessoa (PER): Nome de pessoas.\n",
    "- Organiza√ß√£o (ORG): Empresas e institui√ß√µes.\n",
    "- Localiza√ß√£o (LOC): Cidades, pa√≠ses, regi√µes geogr√°ficas.\n",
    "- Miscellaneous (MISC): Outros, o que n√£o for das categorias acima mas ainda assim for importante, como evento ou produtos.\n",
    "<br>A ideia do NER √© classificar cada token dentro do texto entre uma dessas op√ß√µes.\n",
    "<br><br>O forma de classifica√ß√£o mais comum √© a Inside-Outside-Beginning (IOB):\n",
    "- B- (Beginning): Marca o in√≠cio de uma entidade.\n",
    "- I- (Inside): Marca o token de dentro da entidade, cont√≠nuo ao anterior.\n",
    "- O (Outside): Marca um token que n√£o faz parte de nenhuma entidade nomeada.\n",
    "<br>Nesse formato, o modelo tem todas as informa√ß√µes para distinguir de forma clara quando uma entidade nomeada come√ßa e quando termina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando modelos pr√©-treinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLTK\n",
    "Modelo pr√©-treinado no idioma ingl√™s.\n",
    "<br>Podemos ver que ele se perde bastante no exemplo usado, classificando o \"Bem\" como GPE (localiza√ß√£o), Reconhecimento como organiza√ß√£o, mas tamb√©m acertar em outras, como FIAP como Organiza√ß√£o e Renata Gotler como pessoa.\n",
    "\n",
    "<br>Ainda conseguimos usar mesmo que com um erro maior alguns modelos pr√©-treinados em outros idiomas, desde que eles possuam padr√µes em comum. Por exemplo, as l√≠nguas da fam√≠lia Indo-Europ√©ia como espanhol, ingl√™s, portugu√™s, russo, alem√£o, franc√™s e outros, possuem padr√µes que podem fazer com que um modelo pr√©-treinado em uma, possa ser usado em outra. J√° se fossemos testar em textos japoneses, esses modelos teriam uma performance bem mais baixa, visto que s√£o idiomas bem diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE Bem/NNP)\n",
      "  vindos/VBZ\n",
      "  a/DT\n",
      "  aula/NN\n",
      "  de/FW\n",
      "  (ORGANIZATION Reconhecimento/NNP)\n",
      "  de/FW\n",
      "  (PERSON Entidades/NNP Nomeadas/NNP)\n",
      "  da/NN\n",
      "  (ORGANIZATION FIAP/NNP)\n",
      "  ministrada/NN\n",
      "  pela/NN\n",
      "  professora/NN\n",
      "  (PERSON Renata/NNP Gotler/NNP))\n"
     ]
    }
   ],
   "source": [
    "texto = \"Bem vindos a aula de Reconhecimento de Entidades Nomeadas da FIAP ministrada pela professora Renata Gotler\"\n",
    "tokens = word_tokenize(texto)\n",
    "taggeado = pos_tag(tokens)\n",
    "entidades = ne_chunk(taggeado)\n",
    "print(entidades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se testaremos o mesmo texto em ingl√™s, vemos que o resultado melhora bastante, mesmo que ainda fazendo um pequeno erro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Welcome/VB\n",
      "  to/TO\n",
      "  the/DT\n",
      "  (ORGANIZATION Named/NNP Entity/NNP)\n",
      "  Recognition/NNP\n",
      "  class/NN\n",
      "  from/IN\n",
      "  (ORGANIZATION FIAP/NNP)\n",
      "  lectured/VBN\n",
      "  by/IN\n",
      "  teacher/NN\n",
      "  (PERSON Renata/NNP Gotler/NNP))\n"
     ]
    }
   ],
   "source": [
    "text = \"Welcome to the Named Entity Recognition class from FIAP lectured by teacher Renata Gotler\"\n",
    "tokens = word_tokenize(text)\n",
    "taggeado = pos_tag(tokens)\n",
    "entidades = ne_chunk(taggeado)\n",
    "print(entidades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spacy\n",
    "A biblioteca spacy possui um modelo NER pr√©-treinado no idioma portugu√™s, vamos test√°-lo? Olha que legal, tudo bem certinho, identificou a organiza√ß√£o FIAP e a pessoa Renata Gotler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIAP ORG\n",
      "Renata Gotler PER\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "doc = nlp(texto)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fine-tuned BERT\n",
    "O modelo abaixo foi pr√©-treinado na tarefa de reconhecimento de entidades nomeadas usando como corpo o BERTimbau, que √© pr√©-treinado na l√≠ngua portuguesa. Dessa forma, uma cabe√ßa de classifica√ß√£o de entidades foi adicionada usando artigos da Globo News. Mais informa√ß√µes sobre o modelo est√£o dispon√≠veis na [documenta√ß√£o](https://huggingface.co/monilouise/ner_news_portuguese).\n",
    "\n",
    "<br> Abaixo podemos ver que FIAP n√£o foi identificada como uma entidade nomeada, mas Renata Gotler foi classificada corretamente como pessoa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RenataGotler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\RenataGotler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\RenataGotler\\Reposit√≥rios\\Pos_Tech_MLET\\nlp\\models\\models--monilouise--ner_pt_br. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at monilouise/ner_pt_br were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\RenataGotler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\RenataGotler\\Reposit√≥rios\\Pos_Tech_MLET\\nlp\\models\\models--neuralmind--bert-base-portuguese-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\RenataGotler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'DistilBertTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'DistilBertTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rena: PESSOA (0.96)\n",
      "##ta: PESSOA (0.59)\n",
      "Got: PESSOA (0.97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RenataGotler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForTokenClassification, DistilBertTokenizerFast, pipeline\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    'monilouise/ner_pt_br', cache_dir=\"../models/\"\n",
    ")\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\n",
    "    'neuralmind/bert-base-portuguese-cased',\n",
    "    model_max_length=512,\n",
    "    do_lower_case=False,\n",
    "    cache_dir=\"../models/\"\n",
    ")\n",
    "ner = pipeline('ner', model=model, tokenizer=tokenizer, grouped_entities=True)\n",
    "entidades = ner(texto)\n",
    "for ent in entidades:\n",
    "    print(f\"{ent['word']}: {ent['entity_group']} ({ent['score']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que j√° usamos modelos prontos, vamos ver como treinar o nosso pr√≥prio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando um modelo multi linguagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prontos para treinar um modelo multi linguagem para Reconhecimento de Entidade Nomeada (NER)? Para isso, vamos usar um peda√ßo do dataset ‚ÄúXTREME‚Äù (Cross-lingual TRansfer Evaluation of Multilingual Encoders), chamado de WikiANN ou PAN-X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import DatasetDict, load_dataset, get_dataset_config_names\n",
    "from transformers import (\n",
    "    XLMRobertaForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from seqeval.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse dataset possui 183 subsets (idiomas), com um padr√£o de PAN-x. e a sigla do idioma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTREME possui 183 configura√ß√µes.\n",
      "['PAN-X.af', 'PAN-X.ar', 'PAN-X.bg']\n"
     ]
    }
   ],
   "source": [
    "xtreme_subsets = get_dataset_config_names(\"xtreme\") \n",
    "print(f\"XTREME possui {len(xtreme_subsets)} configura√ß√µes.\") \n",
    "panx_subsets = [s for s in xtreme_subsets if s.startswith(\"PAN\")]\n",
    "print(panx_subsets[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos pegar os seguintes idiomas: ingl√™s, portugu√™s e franc√™s. Al√©m disso, vamos fazer uma redu√ß√£o do dataset por propor√ß√µes para termos uma vis√£o mais realista. Datasets desbalanceados s√£o muito comuns em problemas na vida real, pense na propor√ß√£o de pessoas que falam um determinado idioma, √© muito mais f√°cil conseguir dados em ingl√™s do que nos demais idiomas, certo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pt</th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N√∫mero de observa√ß√µes de treino</th>\n",
       "      <td>2600</td>\n",
       "      <td>14400</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   pt     en    fr\n",
       "N√∫mero de observa√ß√µes de treino  2600  14400  3000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs = ['pt', 'en', 'fr']\n",
    "prop = [0.13, 0.72, 0.15]\n",
    "panx_ch = defaultdict(DatasetDict)\n",
    "for lang, prop in zip(langs, prop):\n",
    "\tds = load_dataset('xtreme', name=f'PAN-X.{lang}')\n",
    "\tfor split in ds:\n",
    "\t\tpanx_ch[lang][split] = ds[split].shuffle(seed=0).select(\n",
    "            range(int(prop * ds[split].num_rows))\n",
    "        )\n",
    "pd.DataFrame(\n",
    "\t{\n",
    "\t\tlang: [panx_ch[lang]['train'].num_rows]\n",
    "\t\tfor lang in langs\n",
    "\t}, index=['N√∫mero de observa√ß√µes de treino']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente vamos treinar nosso modelo na l√≠ngua inglesa e testarmos ele na l√≠ngua inglesa, portuguesa e francesa.\n",
    "<br>Dessa forma, vamos inspecionar um exemplo no dataset ingl√™s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: [\"'\", \"''\", 'Toronto', 'Lynx', \"''\", \"'\"]\n",
      "ner_tags: [0, 0, 3, 4, 0, 0]\n",
      "langs: ['en', 'en', 'en', 'en', 'en', 'en']\n"
     ]
    }
   ],
   "source": [
    "exemplo = panx_ch['en']['train'][0]\n",
    "for key, value in exemplo.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que a coluna ner_tags corresponde a um c√≥digo mapeado, ent√£o vamos transform√°-lo em uma nova coluna mais familiar, com as tags LOC, PER e ORG. Podemos fazer isso atrav√©s do atributo features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n",
      "ner_tags: Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)\n",
      "langs: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n"
     ]
    }
   ],
   "source": [
    "for key, value in panx_ch['en']['train'].features.items():\n",
    "\tprint(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos criar uma fun√ß√£o que cria a coluna ner_tags_str usando a feature ner_tags que possui uma classe ClassLabel que mapeia o id com a tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>'</td>\n",
       "      <td>''</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Lynx</td>\n",
       "      <td>''</td>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1        2      3   4  5\n",
       "tokens  '  ''  Toronto   Lynx  ''  '\n",
       "tags    O   O    B-ORG  I-ORG   O  O"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = panx_ch['en']['train'].features['ner_tags'].feature\n",
    "def create_tag_names_column(batch):\n",
    "\treturn {'ner_tags_str': [tags.int2str(idx) for idx in batch['ner_tags']]}\n",
    "panx_en = panx_ch['en'].map(create_tag_names_column)\n",
    "exemplo = panx_en['train'][0]\n",
    "pd.DataFrame([exemplo['tokens'], exemplo['ner_tags_str']], ['tokens', 'tags'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima j√° vemos alguns desafios que enfrentamos lidando com idiomas: Toronto √© uma cidade, que seria classificado como local, mas Toronto Lynx √© um time de futebol, ent√£o √© classificado como organiza√ß√£o. Outro desafio importante √© a cria√ß√£o das tags, podemos ver que √© bem trabalhoso e complexo de taggear todas as senten√ßas de um dataset inteiro para treinarmos o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora faremos uma An√°lise Explorat√≥ria, para entender a quantidade de tags que temos em cada dataset e ver se est√£o homog√™nias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "      <th>LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>6715</td>\n",
       "      <td>6542</td>\n",
       "      <td>6767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>3364</td>\n",
       "      <td>3276</td>\n",
       "      <td>3458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3385</td>\n",
       "      <td>3339</td>\n",
       "      <td>3357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ORG   PER   LOC\n",
       "train       6715  6542  6767\n",
       "validation  3364  3276  3458\n",
       "test        3385  3339  3357"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split2freqs = defaultdict(Counter)\n",
    "for split, dataset in panx_en.items():\n",
    "\tfor row in dataset['ner_tags_str']:\n",
    "\t\tfor tag in row:\n",
    "\t\t\tif tag.startswith('B'):\n",
    "\t\t\t\ttag_type = tag.split('-')[1]\n",
    "\t\t\t\tsplit2freqs[split][tag_type] += 1\n",
    "pd.DataFrame.from_dict(split2freqs, orient='index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que vimos o dataset, vamos para o modelo...\n",
    "<br>Nesse exemplo usaremos o modelo [XLM-RoBERTa](https://huggingface.co/docs/transformers/model_doc/xlm-roberta). O modelo RoBERTa modifica o pr√©-treinamento do BERT, melhorando o modelo ao treinar em mais dados por mais tempo, al√©m de n√£o realizar a tarefa de Next Sentence Prediction. O XLM-RoBERTa, por sua vez, estende o RoBERTa para um pr√©-treinamento multi-l√≠ngua. Outra diferen√ßa para o BERT √© a tokeniza√ß√£o: Enquanto o BERT tokeniza usando WordPiece, o XLM-RoBERTa utiliza o SentencePiece. Essa mudan√ßa de tokeniza√ß√£o √© especialmente importante para lidar com l√≠nguas em que a separa√ß√£o por espa√ßo n√£o faz sentido, como na l√≠ngua japonesa, sendo mais agn√≥stica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RenataGotler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"../models/\")\n",
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}\n",
    "config = AutoConfig.from_pretrained(\n",
    "\tmodel_name,\n",
    "\tnum_labels=tags.num_classes,\n",
    "\tid2label=index2tag,\n",
    "\tlabel2id=tag2index,\n",
    "    cache_dir=\"../models/\"\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = XLMRobertaForTokenClassification.from_pretrained(\n",
    "    model_name, config=config, cache_dir=\"../models/\"\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de fazer o fine-tuning do modelo, primeiro precisamos tokenizar nosso dataset e alinhar e limpar nossos labels. \n",
    "<br>N√£o queremos que tokens de car√°cter especial, como o `<s>` e o `<\\s>` que indicam in√≠cio e fim de senten√ßa sejam classificados, e tamb√©m queremos ignorar a classifica√ß√£o das subpalavras, somente a primeira deve ser classificada, as demais ser√£o tratadas posteriormente quando juntarmos os tokens em palavras. Para isso, vamos usar os word_ids. Vamos ver um exemplo abaixo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>‚ñÅ'</td>\n",
       "      <td>‚ñÅ''</td>\n",
       "      <td>‚ñÅToronto</td>\n",
       "      <td>‚ñÅLyn</td>\n",
       "      <td>x</td>\n",
       "      <td>‚ñÅ''</td>\n",
       "      <td>‚ñÅ'</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word Ids</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0   1    2         3     4  5    6   7     8\n",
       "Tokens     <s>  ‚ñÅ'  ‚ñÅ''  ‚ñÅToronto  ‚ñÅLyn  x  ‚ñÅ''  ‚ñÅ'  </s>\n",
       "Word Ids  None   0    1         2     3  3    4   5  None"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = tokenizer(exemplo['tokens'], is_split_into_words=True) \n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"]) \n",
    "word_ids = tokenized_input.word_ids()\n",
    "pd.DataFrame([tokens, word_ids], index=[\"Tokens\", \"Word Ids\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver acima que os caracteres especiais est√£o com Ids None. Al√©m disso, as subpalavras possuem o mesmo id da anterior: A palavra Lynx foi dividida em ‚ñÅLyn e x por exemplo, ambas com o id 3. Com isso, podemos tratar os labels para quando forem None ou iguais ao anterior, alocamos o label id -100. Porque -100? Porque a classe torch.nn.CrossEntropyLoss possui um atributo chamado ignore_index com valor -100. Dessa forma, os tokens associados com label -100 ser√£o ignorados durante o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7200/7200 [00:00<00:00, 22705.34 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "\ttokenized_inputs = tokenizer(\n",
    "\t\texamples['tokens'], truncation=True, is_split_into_words=True\n",
    "\t)\n",
    "\tlabels = []\n",
    "\tfor idx, label in enumerate(examples['ner_tags']):\n",
    "\t\tword_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "\t\tprevious_word_idx = None\n",
    "\t\tlabels_ids = []\n",
    "\t\tfor word_idx in word_ids:\n",
    "\t\t\tif word_idx is None or word_idx == previous_word_idx:\n",
    "\t\t\t\tlabels_ids.append(-100)\n",
    "\t\t\telse:\n",
    "\t\t\t\tlabels_ids.append(label[word_idx])\n",
    "\t\t\tprevious_word_idx = word_idx\n",
    "\t\tlabels.append(labels_ids)\n",
    "\ttokenized_inputs['labels'] = labels\n",
    "\treturn tokenized_inputs\n",
    "def encode_panx_dataset(corpus):\n",
    "\treturn corpus.map(\n",
    "\t\ttokenize_and_align_labels,\n",
    "\t\tbatched=True,\n",
    "\t\tremove_columns=['langs', 'ner_tags', 'tokens']\n",
    "\t)\n",
    "panx_en_encoded = encode_panx_dataset(panx_ch['en'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A avalia√ß√£o de um modelo NER √© similar ao de modelos de classifica√ß√£o, usando m√©tricas como acuracidade, precision, recall, f1-score. A diferen√ßa √© que todas as palavras de uma entidade precisam ser previstas corretamente para uma previs√£o contar como correta. Para isso, usaremos a biblioteca seqeval, que faz exatamente isso. Veja um exemplo abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       0.00      0.00      0.00         1\n",
      "         PER       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.50      0.50         2\n",
      "weighted avg       0.50      0.50      0.50         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "y_true = [\n",
    "    ['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'],\n",
    "    ['B-PER', 'I-PER', 'O']\n",
    "]\n",
    "y_pred = [\n",
    "    ['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'],\n",
    "    ['B-PER', 'I-PER', 'O']\n",
    "]\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar essa biblioteca, precisaremos formatar as previs√µes e os labels para formato de lista de listas, conforme visto acima, onde cada lista corresponde a um registro do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_predictions(predictions, label_ids):\n",
    "\tpreds = np.argmax(predictions, axis=2)\n",
    "\tbatch_size, seq_len = preds.shape\n",
    "\tlabels_list, preds_list = [], []\n",
    "\tfor batch_idx in range(batch_size):\n",
    "\t\texample_label, example_preds = [], []\n",
    "\t\tfor seq_idx in range(seq_len):\n",
    "\t\t\tif label_ids[batch_idx, seq_idx] != -100:\n",
    "\t\t\t\texample_label.append(\n",
    "                    index2tag[label_ids[batch_idx][seq_idx]]\n",
    "                )\n",
    "\t\t\t\texample_preds.append(\n",
    "                    index2tag[preds[batch_idx][seq_idx]]\n",
    "                )\n",
    "\t\tlabels_list.append(example_label)\n",
    "\t\tpreds_list.append(example_preds)\n",
    "\treturn preds_list, labels_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos tudo que precisamos para fazer o fine-tuning do XLM-RoBERTa. Primeiramente, faremos somente no subset do idioma ingl√™s e testaremos o modelo nos demais idiomas, portugu√™s e franc√™s. Essa parte j√° fica bem parecida com a da aula passada de an√°lise de sentimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RenataGotler\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "batch_size = 24\n",
    "logging_steps = len(panx_en_encoded['train']) // batch_size\n",
    "finetuned_model_name = f'../models/{model_name}-finetuned-panx-en'\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=finetuned_model_name,\n",
    "    log_level='error',\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_steps=1e6,\n",
    "    weight_decay=0.01,\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\ty_pred, y_true = align_predictions(\n",
    "        eval_pred.predictions, eval_pred.label_ids\n",
    "    )\n",
    "\treturn {'f1': f1_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, precisamos aplicar o m√©todo pad para deixar todas as sequ√™ncias do mesmo tamanho em uma batch (lote). Para isso, usaremos o data collator. Precisamos aplic√°-lo tanto no texto como nos labels, porque agora temos labels de tamanhos diferentes, s√£o labels sequenciais, ao contr√°rio do que t√≠nhamos na aula passada na an√°lise de sentimento, onde t√≠nhamos somente a previs√£o de uma classe. O pad seguir√° a mesma l√≥gica implementada, transformando os tokens pad para ids de -100 para serem ignorados durante o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 252/1800 [57:22<5:52:29, 13.66s/it]\n",
      "                                                     \n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 600/1800 [58:45<1:46:01,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3146, 'grad_norm': 7.7775797843933105, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                    \n",
      "\u001b[A                                                   \n",
      "\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 600/1800 [1:03:55<1:46:01,  5.30s/it]\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2852923572063446, 'eval_f1': 0.7795589235402701, 'eval_runtime': 310.3612, 'eval_samples_per_second': 23.199, 'eval_steps_per_second': 0.967, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1200/1800 [1:51:41<49:57,  5.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2291, 'grad_norm': 5.066575050354004, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                     \n",
      "\u001b[A                                                   \n",
      "\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1200/1800 [1:56:23<49:57,  5.00s/it]\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2691309452056885, 'eval_f1': 0.797154072620216, 'eval_runtime': 282.8361, 'eval_samples_per_second': 25.456, 'eval_steps_per_second': 1.061, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1800/1800 [2:45:21<00:00,  3.93s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1606, 'grad_norm': 1.9625195264816284, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                     \n",
      "\u001b[A                                                   \n",
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1800/1800 [2:50:08<00:00,  3.93s/it]\n",
      "\u001b[A\n",
      "                                                     \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1800/1800 [2:50:08<00:00,  5.67s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.27013665437698364, 'eval_f1': 0.8118384947079577, 'eval_runtime': 286.7881, 'eval_samples_per_second': 25.106, 'eval_steps_per_second': 1.046, 'epoch': 3.0}\n",
      "{'train_runtime': 10208.4417, 'train_samples_per_second': 4.232, 'train_steps_per_second': 0.176, 'train_loss': 0.23476712544759115, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1800, training_loss=0.23476712544759115, metrics={'train_runtime': 10208.4417, 'train_samples_per_second': 4.232, 'train_steps_per_second': 0.176, 'total_flos': 840013140205008.0, 'train_loss': 0.23476712544759115, 'epoch': 3.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=panx_en_encoded['train'],\n",
    "    eval_dataset=panx_en_encoded['validation'],\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O treinamento pode demorar bastante, tenha paci√™ncia. Acima podemos ver que os resultados foram muito bons! Com F1 de cerca de 81%! Ap√≥s, j√° teremos nosso modelo treinado, agora √© s√≥ formatar o resultado final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text, tags, model, tokenizer):\n",
    "\ttokens = tokenizer(text).tokens()\n",
    "\tinput_ids = tokenizer(text, return_tensors='pt').input_ids.to(device)\n",
    "\toutputs = model(input_ids)[0]\n",
    "\tpredictions = torch.argmax(outputs, dim=2)\n",
    "\tpreds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "\treturn pd.Dataframe([tokens, preds], index=['Tokens', 'Tags'])\n",
    "\n",
    "def get_f1_score(trainer, dataset):\n",
    "    return trainer.predict(dataset).metrics['test_f1']\n",
    "\n",
    "def evaluate_lang_performance(lang, trainer):\n",
    "\tpanx_ds = encode_panx_dataset(panx_ch[lang])\n",
    "\treturn get_f1_score(trainer, panx_ds['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nosso modelo at√© ent√£o foi treinado somente em texto do idioma ingl√™s, ser√° que ele j√° performa bem nos idiomas portugu√™s e franc√™s?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55/55 [00:23<00:00,  2.38it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [03:21<00:00,  1.49it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:47<00:00,  1.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'en': {'pt': 0.755090168702734,\n",
       "              'en': 0.819514586908556,\n",
       "              'fr': 0.7384541756401053}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores = defaultdict(dict)\n",
    "for lang in langs:\n",
    "\tf1_scores['en'][lang] = evaluate_lang_performance(lang, trainer)\n",
    "f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incr√≠vel! Mesmo o treinamento sendo no idioma ingl√™s, j√° conseguimos usar esse modelo nos outros idiomas com uma boa performance, com F1 de cerca de 75%.\n",
    "<br>Mas ainda podemos melhorar, podemos treinar um modelo em todos os idiomas de uma vez.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 833/2502 [1:06:40<2:04:56,  4.49s/it] \n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 833/2502 [1:06:41<2:04:56,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2325, 'grad_norm': 4.244439601898193, 'learning_rate': 3.3353317346123105e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 834/2502 [1:06:43<1:49:40,  3.95s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                           \n",
      "                                                      \n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 834/2502 [1:13:41<1:49:40,  3.95s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.26804468035697937, 'eval_f1': 0.8145848375451263, 'eval_runtime': 417.4688, 'eval_samples_per_second': 23.954, 'eval_steps_per_second': 0.999, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1666/2502 [2:22:01<1:02:52,  4.51s/it] \n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1666/2502 [2:22:01<1:02:52,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1618, 'grad_norm': 8.026433944702148, 'learning_rate': 1.6706634692246204e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1668/2502 [2:22:09<58:12,  4.19s/it]  \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                           \n",
      "                                                      \n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1668/2502 [2:29:37<58:12,  4.19s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28700748085975647, 'eval_f1': 0.8219504275354476, 'eval_runtime': 447.2561, 'eval_samples_per_second': 22.359, 'eval_steps_per_second': 0.932, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2499/2502 [3:37:56<00:13,  4.57s/it]    \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2499/2502 [3:37:56<00:13,  4.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1, 'grad_norm': 17.973731994628906, 'learning_rate': 5.995203836930455e-08, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2502/2502 [3:38:10<00:00,  4.34s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                           \n",
      "                                                      \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2502/2502 [3:44:55<00:00,  4.34s/it]\n",
      "\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2502/2502 [3:44:55<00:00,  5.39s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3139559030532837, 'eval_f1': 0.8286924720280987, 'eval_runtime': 404.9415, 'eval_samples_per_second': 24.695, 'eval_steps_per_second': 1.03, 'epoch': 3.0}\n",
      "{'train_runtime': 13495.3183, 'train_samples_per_second': 4.446, 'train_steps_per_second': 0.185, 'train_loss': 0.16469408920724138, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2502, training_loss=0.16469408920724138, metrics={'train_runtime': 13495.3183, 'train_samples_per_second': 4.446, 'train_steps_per_second': 0.185, 'total_flos': 1143126996806784.0, 'train_loss': 0.16469408920724138, 'epoch': 3.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "def concatenate_splits(corpus):\n",
    "\tmulti_corpus = DatasetDict()\n",
    "\tfor split in corpus[0].keys():\n",
    "\t\tmulti_corpus[split] = concatenate_datasets(\n",
    "\t\t\t[data[split] for data in corpus]\n",
    "\t\t).shuffle(seed=42)\n",
    "\treturn multi_corpus\n",
    "\n",
    "panx_all_encoded = [panx_en_encoded]\n",
    "for lang in ['pt', 'fr']:\n",
    "\tpanx_encoded = encode_panx_dataset(panx_ch[lang])\n",
    "\tpanx_all_encoded.append(panx_encoded)\n",
    "corpus = concatenate_splits(panx_all_encoded)\n",
    "training_args.output_dir = f'../models/{model_name}-finetuned-panx-all'\n",
    "training_args.logging_steps = len(corpus['train']) // batch_size\n",
    "trainer = Trainer(model,args=training_args, data_collator=data_collator, compute_metrics=compute_metrics, train_dataset=corpus['train'], eval_dataset=corpus['validation'], tokenizer=tokenizer)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que resultado! 83% de F1 score no total! Agora vamos testar o modelo multi linguagem nos nossos datasets e ver como ficou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [05:06<00:00,  1.02s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55/55 [00:44<00:00,  1.24it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [01:00<00:00,  1.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Evaluated on</th>\n",
       "      <th>pt</th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fine-tuned on</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>0.7551</td>\n",
       "      <td>0.8195</td>\n",
       "      <td>0.7385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.8243</td>\n",
       "      <td>0.8746</td>\n",
       "      <td>0.8615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Evaluated on       pt      en      fr\n",
       "Fine-tuned on                        \n",
       "en             0.7551  0.8195  0.7385\n",
       "all            0.8243  0.8746  0.8615"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, lang in enumerate(langs):\n",
    "\tf1_scores['all'][lang] = get_f1_score(\n",
    "\t\ttrainer, panx_all_encoded[idx]['test']\n",
    "\t)\n",
    "scores_data = {\n",
    "\t'en': f1_scores['en'],\n",
    "\t'all': f1_scores['all'],\n",
    "}\n",
    "f1_scores_df = pd.DataFrame(scores_data).T.round(4).rename_axis(\n",
    "\tindex='Fine-tuned on', columns= 'Evaluated on'\n",
    ")\n",
    "f1_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que usar outros idiomas no treinamento aumentou o resultado testando somente no dataset em ingl√™s tamb√©m, indo de 82% para 87% em F1! Isso porque ele aprendeu outros padr√µes com os outros idiomas que puderam ser aproveitados. No entanto, isso √© verdade para aqueles idiomas que s√£o similares, conforme comentamos anteriormente, todos os idiomas testados pertencem √† fam√≠lia Indo-Europ√©ia, que compartilham padr√µes entre si. Esses padr√µes fazem com que o modelo performe de forma quase equivalente nesses idiomas, podemos ver que o F1 em todos os tr√™s idiomas ficou bem parecido, em torno de 85%, o que √© muito bom para um modelo de Reconhecimento de Entidade Nomeada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lise de Erro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, √© sempre importante fazer uma an√°lise de erro para entender as fraquezas e for√ßas do seu modelo, entendendo potenciais melhorias ou at√© vendo poss√≠veis vi√©ses.\n",
    "<br>Podemos fazer isso extraindo a loss e a classe prevista para cada token de cada registro, comparando com a classe verdadeira do token do registro. Na an√°lise de erro, podemos olhar para os registros com as maiores loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def forward_pass_with_label(batch):\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        output = trainer.model(input_ids, attention_mask)\n",
    "        predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "    loss = cross_entropy(output.logits.view(-1,7), labels.view(-1), reduction=\"none\")\n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
    "    return {\"loss\": loss, \"predicted_label\": predicted_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7200/7200 [05:28<00:00, 21.94 examples/s]\n"
     ]
    }
   ],
   "source": [
    "valid_set = panx_en_encoded[\"validation\"]\n",
    "valid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)\n",
    "df = valid_set.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos extrair is tokens, at√© ent√£o s√≥ temos os ids para melhorar nossa leitura. Al√©m disso, vamos retirar o padding adicionado anteriormente limitando pelo tamanho do dado de entrada (input_ids)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 111767, 87, 1529, 5861, 1650, 194397, 70, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, O, B-ORG, I-ORG, IGN, I-ORG, I-ORG, I-OR...</td>\n",
       "      <td>[0.0, 0.00023600654, 0.0011836435, 0.001912075...</td>\n",
       "      <td>[I-ORG, O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, ...</td>\n",
       "      <td>[&lt;s&gt;, ‚ñÅ``, ‚ñÅI, ‚ñÅHe, ard, ‚ñÅIt, ‚ñÅThrough, ‚ñÅthe, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids  \\\n",
       "0  [0, 111767, 87, 1529, 5861, 1650, 194397, 70, ...   \n",
       "\n",
       "                            attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [IGN, O, B-ORG, I-ORG, IGN, I-ORG, I-ORG, I-OR...   \n",
       "\n",
       "                                                loss  \\\n",
       "0  [0.0, 0.00023600654, 0.0011836435, 0.001912075...   \n",
       "\n",
       "                                     predicted_label  \\\n",
       "0  [I-ORG, O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, ...   \n",
       "\n",
       "                                        input_tokens  \n",
       "0  [<s>, ‚ñÅ``, ‚ñÅI, ‚ñÅHe, ard, ‚ñÅIt, ‚ñÅThrough, ‚ñÅthe, ...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2tag[-100] = \"IGN\"\n",
    "df[\"input_tokens\"] = df[\"input_ids\"].apply(lambda x: tokenizer.convert_ids_to_tokens(x))\n",
    "for label in [\"predicted_label\", \"labels\"]:\n",
    "    df[label] = df[label].apply(lambda x: [index2tag[i] for i in x])\n",
    "for col in [\"loss\", \"predicted_label\"]:\n",
    "    df[col] = df.apply(lambda x: x[col][:len(x[\"input_ids\"])], axis=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos olhar para os tokens de forma individual, explodindo as listas, criando uma linha por token. Tamb√©m vamos retirar os labels IGN que possuem loss zero de qualquer forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111767</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>‚ñÅ``</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>‚ñÅI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1529</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>‚ñÅHe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1650</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>‚ñÅIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194397</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>‚ñÅThrough</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input_ids attention_mask labels  loss predicted_label input_tokens\n",
       "0    111767              1      O   0.0               O          ‚ñÅ``\n",
       "0        87              1  B-ORG   0.0           B-ORG           ‚ñÅI\n",
       "0      1529              1  I-ORG   0.0           I-ORG          ‚ñÅHe\n",
       "0      1650              1  I-ORG   0.0           I-ORG          ‚ñÅIt\n",
       "0    194397              1  I-ORG   0.0           I-ORG     ‚ñÅThrough"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = df.apply(pd.Series.explode)\n",
    "df_tokens = df_tokens[df_tokens[\"labels\"] != \"IGN\"]\n",
    "df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
    "df_tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos agrupar os dados por token e agregar a loss, extraindo contagem, m√©dia e soma. Podemos ver que o token que acumulou a maior loss no dataset de valida√ß√£o √© o _, seguido por _of e assim por diante...\n",
    "<br>Isso nos d√° alguns insights importantes:\n",
    "- o token `_` representa espa√ßo, ele ter obtido a maior loss acumulada n√£o √© surpresa, visto que ele √© o token mais frequente tamb√©m. Al√©m disso, a m√©dia da loss desse token indica que o modelo n√£o tem problemas em classificar ele.\n",
    "- os tokens `_of`, `_the`, `_and` e outros na lista aparencem com bastante frequ√™ncia. Esses tokens aparecem bastante juntos com entidade nomeadas e as vezes fazem parte delas, o que explica o porque o modelo fica confuso com eles.\n",
    "- Par√™nteses no in√≠cio das palavras apareceram com uma frequencia relativamente alta e uma m√©dia de loss bem alta tamb√©m, precisando de investiga√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_tokens</th>\n",
       "      <td>‚ñÅ</td>\n",
       "      <td>‚ñÅof</td>\n",
       "      <td>‚ñÅ)</td>\n",
       "      <td>‚ñÅ(</td>\n",
       "      <td>‚ñÅthe</td>\n",
       "      <td>‚ñÅand</td>\n",
       "      <td>‚ñÅ''</td>\n",
       "      <td>‚ñÅThe</td>\n",
       "      <td>‚ñÅ'</td>\n",
       "      <td>‚ñÅin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5550</td>\n",
       "      <td>1356</td>\n",
       "      <td>1927</td>\n",
       "      <td>1931</td>\n",
       "      <td>1142</td>\n",
       "      <td>726</td>\n",
       "      <td>2775</td>\n",
       "      <td>336</td>\n",
       "      <td>1317</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>927.96</td>\n",
       "      <td>669.83</td>\n",
       "      <td>490.93</td>\n",
       "      <td>488.31</td>\n",
       "      <td>353.17</td>\n",
       "      <td>241.58</td>\n",
       "      <td>165.59</td>\n",
       "      <td>162.77</td>\n",
       "      <td>150.59</td>\n",
       "      <td>149.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0       1       2       3       4       5       6       7  \\\n",
       "input_tokens       ‚ñÅ     ‚ñÅof      ‚ñÅ)      ‚ñÅ(    ‚ñÅthe    ‚ñÅand     ‚ñÅ''    ‚ñÅThe   \n",
       "count           5550    1356    1927    1931    1142     726    2775     336   \n",
       "mean            0.17    0.49    0.25    0.25    0.31    0.33    0.06    0.48   \n",
       "sum           927.96  669.83  490.93  488.31  353.17  241.58  165.59  162.77   \n",
       "\n",
       "                   8       9  \n",
       "input_tokens      ‚ñÅ'     ‚ñÅin  \n",
       "count           1317     910  \n",
       "mean            0.11    0.16  \n",
       "sum           150.59  149.86  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens.groupby(\"input_tokens\")[[\"loss\"]].agg(\n",
    "    [\"count\", \"mean\", \"sum\"]\n",
    ").droplevel(level=0, axis=1).sort_values(\n",
    "    by=\"sum\", ascending=False\n",
    ").reset_index().round(2).head(10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando pelos labels, podemos ver que a maior loss acumulada √© da classe I-ORG, sendo onde nosso modelo tem maior dificuldade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8384</td>\n",
       "      <td>4564</td>\n",
       "      <td>5337</td>\n",
       "      <td>3364</td>\n",
       "      <td>29398</td>\n",
       "      <td>3458</td>\n",
       "      <td>3276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>4391.25</td>\n",
       "      <td>3261.51</td>\n",
       "      <td>2949.29</td>\n",
       "      <td>2384.79</td>\n",
       "      <td>2201.95</td>\n",
       "      <td>1617.1</td>\n",
       "      <td>1361.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1        2        3        4       5        6\n",
       "labels    I-ORG    I-LOC    I-PER    B-ORG        O   B-LOC    B-PER\n",
       "count      8384     4564     5337     3364    29398    3458     3276\n",
       "mean       0.52     0.71     0.55     0.71     0.07    0.47     0.42\n",
       "sum     4391.25  3261.51  2949.29  2384.79  2201.95  1617.1  1361.11"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens.groupby(\"labels\")[[\"loss\"]].agg(\n",
    "    [\"count\", \"mean\", \"sum\"]\n",
    ").droplevel(level=0, axis=1).sort_values(\n",
    "    by=\"sum\", ascending=False\n",
    ").reset_index().round(2).head(10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos quebrar ainda mais e ver a matriz de confus√£o. Abaixo vemos que:\n",
    "- Nosso modelo se confunde entre o B-ORG (in√≠cio de organiza√ß√£o) e o I-ORG (token subsequente).\n",
    "- O modelo tamb√©m se confunde bastante entre a classe B-PER com O e I-PER.\n",
    "- Em geral nosso modelo √© um bom modelo, podemos ver isso claremente pela diagonal da matriz de confus√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAIjCAYAAADP4ysCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAACjRUlEQVR4nOzdd1gUVxcG8HeXrhQBQRCRIlWajaJGwS4EiSb2HsXYYos99p5izWfvvXexxAKiiVGwYO+KokFAOoogsN8fC4sLC4LSJr6/59lHmT0ze+/ZO7Nn78yASCKRSEBERERUwYnLuwFERERERcGihYiIiASBRQsREREJAosWIiIiEgQWLURERCQILFqIiIhIEFi0EBERkSCwaCEiIiJBYNFCREREgsCihaicTJ8+HSKRqFRfQyQSYfr06aX6GmUhKioKHTt2hL6+PkQiERYvXlzir/H69Wu4uLigWrVq2LRpE/7++2/UqVOnxF/nv8jc3Bx9+/aV/Xz27FmIRCKcPXu2XNtB/z0sWug/b+PGjRCJRBCJRPjrr7/yPS+RSGBqagqRSARfX99Peo25c+fi4MGDn9lSKsioUaPw559/YuLEidiyZQvatm1b4q+xe/duVK5cGYMHD8bIkSPRpEkT9O/fv8Rfh4g+nXJ5N4CorKirq2P79u346quv5JYHBwfjxYsXUFNT++Rtz507Fx07dkT79u2LvM7kyZMxYcKET37NL0lgYCC++eYbjBkzptReo1u3bujatSv09PQwfvx4pKSkwMDAoNRe77+sadOmSE1Nhaqqank3hf5jONNCXwwfHx/s2bMHGRkZcsu3b9+O+vXrw8jIqEza8ebNGwCAsrIy1NXVy+Q1hS46OhpVqlQp1dfQ1dWFnp4eAEBDQ0OwBUtWVhbevXtXrm0Qi8VQV1eHWMyPGCpZHFH0xejWrRtiY2Nx6tQp2bL09HTs3bsX3bt3V7jO/Pnz0ahRI+jr60NDQwP169fH3r175WJEIhHevHmDTZs2yU5D5ZxXz7lu5c6dO+jevTt0dXVlMz15r2np27evbP28j49dl5KWloZRo0bBwMAAWlpa8PPzw4sXLxTGvnz5Ev369UO1atWgpqYGBwcHrF+//mPpk9m6dSvc3NxQqVIl6OrqomnTpjh58qRczPLly+Hg4AA1NTVUr14dQ4cORUJCglyMl5cXHB0dcefOHTRr1gyVKlWCiYkJfvvtN1lMzqk9iUSCZcuWyfKhKH951wkPD5ctu3z5Mtq0aYOqVatCQ0MDFhYW6Nevn9x6v/7660ffawDIyMjArFmzUKtWLaipqcHc3Bw///wz0tLSPpq7vn37QlNTEy9fvkT79u2hqakJAwMDjBkzBpmZmXKxb968wejRo2Fqago1NTXY2tpi/vz5kEgkcnEikQg//vgjtm3bJsv5iRMnZHn466+/MHz4cBgYGKBKlSoYOHAg0tPTkZCQgN69e0NXVxe6uroYN25cvm0XZfwrkvealg9P0eZ9eHl5ydbbsGEDmjdvDkNDQ6ipqaF27dpYsWJFvu1LJBLMnj0bNWrUQKVKldCsWTPcvn07X1xcXBzGjBkDJycnaGpqQltbG97e3rh+/fpH+0AVE08P0RfD3NwcDRs2xI4dO+Dt7Q0AOH78OBITE9G1a1f88ccf+dZZsmQJ/Pz80KNHD6Snp2Pnzp3o1KkTAgIC8PXXXwMAtmzZAn9/f7i5ueGHH34AANSqVUtuO506dYK1tTXmzp2b74Mhx8CBA9GyZUu5ZSdOnMC2bdtgaGhYaN/8/f2xdetWdO/eHY0aNUJgYKCsfR+KioqCh4eH7IPOwMAAx48fR//+/ZGUlISRI0cW+jozZszA9OnT0ahRI8ycOROqqqq4dOkSAgMD0bp1awDSYmLGjBlo2bIlBg8ejPv372PFihUIDQ3F33//DRUVFdn24uPj0bZtW3z77bfo3Lkz9u7di/Hjx8PJyQne3t5o2rQptmzZgl69eqFVq1bo3bt3oe1TJDo6Gq1bt4aBgQEmTJiAKlWqIDw8HPv375eLW7x4Mb799ttC3+ucXG/atAkdO3bE6NGjcenSJcybNw93797FgQMHPtqezMxMtGnTBu7u7pg/fz5Onz6NBQsWoFatWhg8eDAA6Yeyn58fgoKC0L9/f9SpUwd//vknxo4di5cvX2LRokVy2wwMDMTu3bvx448/omrVqjA3N0dYWBgAYNiwYTAyMsKMGTNw8eJFrF69GlWqVMGFCxdQs2ZNzJ07F8eOHcPvv/8OR0dHuRwXZfwXRc77+KFnz55h8uTJcmN7xYoVcHBwgJ+fH5SVlXHkyBEMGTIEWVlZGDp0qCxu6tSpmD17Nnx8fODj44OrV6+idevWSE9Pl3uNJ0+e4ODBg+jUqRMsLCwQFRWFVatWwdPTE3fu3EH16tWL3AeqICRE/3EbNmyQAJCEhoZKli5dKtHS0pK8fftWIpFIJJ06dZI0a9ZMIpFIJGZmZpKvv/5abt2cuBzp6ekSR0dHSfPmzeWWV65cWdKnT598rz1t2jQJAEm3bt0KfK4gDx8+lOjo6EhatWolycjIKDAuLCxMAkAyZMgQueXdu3eXAJBMmzZNtqx///4SY2NjyevXr+Viu3btKtHR0cnX37ztEYvFkg4dOkgyMzPlnsvKypJIJBJJdHS0RFVVVdK6dWu5mKVLl0oASNavXy9b5unpKQEg2bx5s2xZWlqaxMjISPLdd9/JbR+AZOjQoXLLCspfzvv99OlTiUQikRw4cED2/hfmzZs3cj8req9zcu3v7y8XO2bMGAkASWBgYKGv0adPHwkAycyZM+WW161bV1K/fn3ZzwcPHpQAkMyePVsurmPHjhKRSCR59OiRbBkAiVgslty+fVsuNicPbdq0kb0/EolE0rBhQ4lIJJIMGjRItiwjI0NSo0YNiaenp9w2ijr+zczM5MZ/UFCQBIAkKChIYR5SU1Ml9evXl1SvXl0SGRlZ4OtJJBJJmzZtJJaWlrKfc8bY119/Ldevn3/+WQJArh3v3r3LN1afPn0qUVNTy/cekDDw9BB9UTp37ozU1FQEBAQgOTkZAQEBBZ4aAqTXNuSIj49HYmIimjRpgqtXrxbrdQcNGlSs+Ddv3qBDhw7Q1dXFjh07oKSkVGDssWPHAADDhw+XW5531kQikWDfvn1o164dJBIJXr9+LXu0adMGiYmJhfbr4MGDyMrKwtSpU/Ndq5Bzmub06dNIT0/HyJEj5WIGDBgAbW1tHD16VG49TU1N9OzZU/azqqoq3Nzc8OTJkwLbUVw518IEBATg/fv3BcZVqlRJ9v+C3uucXP/0009y644ePRoA8vWvIHnHQ5MmTeT6fOzYMSgpKeV7T0ePHg2JRILjx4/LLff09ETt2rUVvlb//v3lTqO5u7tDIpHI3RmlpKSEBg0a5Mt7SY3/vIYMGYKbN29i3759cteSffh6iYmJeP36NTw9PfHkyRMkJiYCyB1jw4YNk+uXollCNTU12TjMzMxEbGwsNDU1YWtr+9l9oPLB00P0RTEwMEDLli2xfft2vH37FpmZmejYsWOB8QEBAZg9ezbCwsLkrlko7u9XsbCwKFb8gAED8PjxY1y4cAH6+vqFxj579gxisTjfKSlbW1u5n2NiYpCQkIDVq1dj9erVCrcVHR1d4Os8fvwYYrG4wA/HnLYoem1VVVVYWlrKns9Ro0aNfLnU1dXFjRs3CnyN4vL09MR3332HGTNmYNGiRfDy8kL79u3RvXt3uTvGivJe5+TayspK7jWMjIxQpUqVfP1TRF1dPd9Fvrq6uoiPj5d7nerVq0NLS0suzt7eXvb8hwobXzVr1pT7WUdHBwBgamqab/mHbQBKbvx/aNWqVdiwYQNWrVoFDw8Puef+/vtvTJs2Df/88w/evn0r91xiYiJ0dHRkfbe2tpZ73sDAALq6unLLsrKysGTJEixfvhxPnz6Vu27oY/sVVUwsWuiL0717dwwYMACvXr2Ct7d3gXelnD9/Hn5+fmjatCmWL18OY2NjqKioYMOGDdi+fXuxXvPDb5Afs2TJEuzYsQNbt24t0V9ulpWVBQDo2bMn+vTpozDG2dm5xF6vKAqaQZIUcN3Phwr64Mx7QatIJMLevXtx8eJFHDlyBH/++Sf69euHBQsW4OLFi9DU1Cz2e/05H9qFzZp9qsLGV0Gvp2j5h3kvyfGfIyQkBCNGjIC/v7/s+q8cjx8/RosWLWBnZ4eFCxfC1NQUqqqqOHbsGBYtWiQbv8Uxd+5cTJkyBf369cOsWbOgp6cHsViMkSNHftL2qPyxaKEvTocOHTBw4EBcvHgRu3btKjBu3759UFdXx59//in3jXzDhg35YkvqN9ueP38eY8aMwciRI9GjR48irWNmZoasrCw8fvxYbobj/v37cnE5dxZlZmbmu+C3KGrVqoWsrCzcuXOnwGLKzMxM9tqWlpay5enp6Xj69OknvW5Bcr5VJyQkyBWeBc12eHh4wMPDA3PmzMH27dvRo0cP7Ny5E/7+/kV+r3Ny/fDhQ9msByC9wDkhIUHW/89lZmaG06dPIzk5WW625d69e7LnS1txxn9RxMTEoGPHjqhTpw6WLVuW7/kjR44gLS0Nhw8flpsdCgoKkovL6fvDhw/lxlhMTEy+maK9e/eiWbNmWLdundzyhIQEVK1a9ZP6QeWL17TQF0dTUxMrVqzA9OnT0a5duwLjlJSUIBKJ5L65h4eHK/zNt5UrV853S29xRUZGonPnzvjqq6/w+++/F3m9nDuh8t79lPdX3SspKeG7777Dvn37cOvWrXzbiYmJKfR12rdvD7FYjJkzZ+b7lprzDb1ly5ZQVVXFH3/8Ifetfd26dUhMTCzWHScfk3M67Ny5c7JlObeefyg+Pj7fzE1O0ZVzyqOo77WPjw+A/LlduHAhAJRY/3x8fJCZmYmlS5fKLV+0aBFEIpHsPS9NxRn/H5OZmYmuXbsiPT0d+/btU/hL53Jmfj58rxITE/MVSS1btoSKigr+97//ycUq+tMOSkpK+d77PXv24OXLl8XuA1UMnGmhL1JBp0c+9PXXX2PhwoVo27YtunfvjujoaCxbtgxWVlb5rrmoX78+Tp8+jYULF6J69eqwsLCAu7t7sdo0fPhwxMTEYNy4cdi5c6fcc87OzgWeuqlTpw66deuG5cuXIzExEY0aNcKZM2fw6NGjfLG//PILgoKC4O7ujgEDBqB27dqIi4vD1atXcfr0acTFxRXYPisrK0yaNAmzZs1CkyZN8O2330JNTQ2hoaGoXr065s2bBwMDA0ycOBEzZsxA27Zt4efnh/v372P58uVwdXWVu+j2c7Vu3Ro1a9ZE//79MXbsWCgpKWH9+vUwMDDA8+fPZXGbNm3C8uXL0aFDB9SqVQvJyclYs2YNtLW1ZUVIUd9rFxcX9OnTB6tXr0ZCQgI8PT0REhKCTZs2oX379mjWrFmJ9K1du3Zo1qwZJk2ahPDwcLi4uODkyZM4dOgQRo4cme/6pdJQnPH/MStXrkRgYCAGDRqUb+akWrVqaNWqFVq3bg1VVVW0a9cOAwcOREpKCtasWQNDQ0NERkbK4nN+r828efPg6+sLHx8fXLt2DcePH883e+Lr64uZM2fi+++/R6NGjXDz5k1s27ZNboaGBKZ8bloiKjsf3vJcGEW3PK9bt05ibW0tUVNTk9jZ2Uk2bNig8Fbbe/fuSZo2bSrR0NCQu+0yJzYmJibf6+XdTs4twIoeH962rEhqaqpk+PDhEn19fUnlypUl7dq1k0RERChcNyoqSjJ06FCJqampREVFRWJkZCRp0aKFZPXq1YW+Ro7169dL6tatK1FTU5Po6upKPD09JadOnZKLWbp0qcTOzk6ioqIiqVatmmTw4MGS+Ph4uRhPT0+Jg4NDvu336dNHYmZmJrcMCm55lkgkkitXrkjc3d0lqqqqkpo1a0oWLlyY75bnq1evSrp16yapWbOmRE1NTWJoaCjx9fWVXL58WW5bRX2v379/L5kxY4bEwsJCoqKiIjE1NZVMnDhR8u7du4/mrk+fPpLKlSvnW67odZKTkyWjRo2SVK9eXaKioiKxtraW/P7773K3+RaWm4LGfUFjUlHbipqTj93ynLOOoseHt1kfPnxY4uzsLFFXV5eYm5tLfv31V8n69evl3k+JRCLJzMyUzJgxQ2JsbCzR0NCQeHl5SW7dupWvHe/evZOMHj1aFte4cWPJP//8I/H09Mx3ezcJg0giKcIVb0RERETljNe0EBERkSCwaCEiIiJBYNFCREREgsCihYiIiASBRQsREREJAosWIiIiEgT+crkSlpWVhX///RdaWlol9qvdiYiI/qskEgmSk5NRvXr1fH9BPi8WLSXs33//zffXU4mIiKhwERERqFGjRqExLFpKWM4fN1P1mgaRsno5t6Z83dowoLybUCFoqnM3A6S//pQAzr9KicXMRI6srC9770hOToKNZU25Pw5aEB5NS1jOKSGRsvoXX7RoaWuXdxMqBC0WLQBYtOTgR7UUi5ZcX3rRkqMol1TwQlwiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQmCcnk3gIrG38cZw75tAEPdSrj19DXGrwrC1YdRBcYP8quLft5OqGGgjbikVBy68BAzN/2NtPeZAABNDRX83KMRfBvWQlWdSrj5JBoT1gTjWiHbrAg2H/gLq3YGIiYuGfa1qmPGiG9Rx96swPijQWFYsP44XryKg4WJASYM8kUzj9qy5809Rylcb+KgdhjYrXmJt7+krN1zDku3nUF0bBIcrE3wy+iOqO9gXmD8oTPXMHdVACIi42BpaoBpQ79Bq8YOsuePBIVh4/6/cf3ec8QnvcXZLePhZFOjDHryedYpyEO9j+Rh3gd5mJonDwF58hAkkDxwPEit2R2M/22V5sHR2gS/ju1UaB4Onr6KuSuP4nlkLCxNDTB9WHu0/iAPEokE81YdxeaDF5CYkgp3Z0ssmNAFtWoalkFvPt1/eTxwpkUAOnxlg9n+TfHrjovwGrkdt57GYN/MDqiqo6EwvqOnLab1aYzfdl6C+5DNGPa/U+jwlQ2m9G4si1kyrBW86tbEoIV/ovGwLQi89hwHZ30LY73KZdWtYjsSeA2zlx3EiD5tcHTNaNSuVR29x6zC6/hkhfFXbj3F8Flb0MXHHcfWjEHrJo74YdJ63H8SKYsJ2T9D7vHb+K4QiUTw9nQuq24V24FTVzBlyQGM7e+NwE3j4Ghlgk4jliMmTnEeQm48wYApG9GzXUMEbR4Pn6bO6DVuDe4+/lcW8zY1HR4ulpj24zdl1Y3PljcPDkXIww9TNqLHB3norSAP7i6WmCrgPHyp42H/ySuYvPgAxvt74+yW8XC0NsF3w5YVmIdL15/Af/JG9PymIYK3TsDXni7oOWY17jzKzcOSzaexalcwFk7silMbxqCShiq+G7YM79Lel1W3iu2/Ph5YtOQRERGBfv36oXr16lBVVYWZmRlGjBiB2NjYcmvTkPb1sPnPW9h+5g7uR8Thp+Vn8DYtAz1bOSiMd7MzxqW7/2Jv8H1ERCch6Npz7Dt3H/VtqgEA1FWV4NfICtM3nMeF2y/xNDIRv+64iCeRCejnU3E/rNfuPouuvg3R2ccd1uZGmDO6EzTUVbH72CWF8ev3noOnmx0GdmsOK/NqGN3fBw42NbDpwHlZjKG+ttzj1N+30LCuFWpWr1pW3Sq25TuC0OubhujRzgN2lsZYMKELNNRVse3IPwrjV+06ixYe9hjWqyVsLYzw8yBfONuaYu2ec7KYLj5uGOvvDU9X27LqxmdbkZ2H7u08YPtBHrYXkofm2XmwsTDCRAV56CzAPHA8SC3fHoje7Ruhh19D2FkaY+HErqikroqthwvIw86zaNHQHsOz8zBpsC9c7EyxZk8wAOksy8odQRjTrw18PJ3haG2CFTN649XrRBwNvl6WXSuW//p4YNHygSdPnqBBgwZ4+PAhduzYgUePHmHlypU4c+YMGjZsiLi4uDJvk4qyGHWsDHH2eoRsmUQCBIc9h6utscJ1Qu5Fok6taqhnLS1SzKppo1UDC5y6HA4AUFYSQ1lJjHfpmXLrvUvPgEdtk9LpyGdKf5+BWw9eoHF9G9kysViMxvWtcfX2M4XrXLsdLhcPAE1dbQuMj4lLRtA/d9DFx73kGl7C0t9n4Pq9CHi65R48xGIxPF1tEXozXOE6oTfD8x1smnvYIfTm09Jsaqn6lDxcVpCHZh52uPyF5eG/Oh7C7kXAK28e3GwL7FfIzafwcrWTW9bcw16Wt2cvYxEVmwQvt9wYHU0N1HcwR+iN8BLvQ0n4EsYDr2n5wNChQ6GqqoqTJ09CQ0N66qVmzZqoW7cuatWqhUmTJmHFihVl2iZ9bQ0oK4kRE/9WbnlMwltY19BTuM7e4PvQ09bA8V87QyQCVJSVsP7YDSzcEwoASEl9j5C7/2JsV3c8eBGH6IS36NjUFq62xngSmVDaXfok8YlvkJmZhaq6WnLLDXS18Ph5tMJ1YuKSFca/jktSGL/vRAgqV1JHm6YVd7YpNkGaB0M9bbnlhnpaePhM8fVI0bFJMNDLkwc9LUTHKp4uFoKcPBjkyYNBMfNg+B/JA8dDSvZ4yNsvbTwMLyQP+oryID0+RGX/mzfGUD83pqL5EsYDZ1qyxcXF4c8//8SQIUNkBUsOIyMj9OjRA7t27YJEIpF7Li0tDUlJSXKP8tbYsQZ+6uSKMSsD4TVyO3rOOYLWruYY08VNFjNw4Z8QiYC7mwYgav8w/NCuDvadu48sSSEb/o/bfTwE7VvWg7qaSnk3hYiIFOBMS7aHDx9CIpHA3t5e4fP29vaIj49HTEwMDA1zrxyfN28eZsyYUWrtik1KRUZmFgx0K8ktN6hSCdHxbxSuM6lnQ+wOuostJ28DAO48i0VldRUs+rEFFuwOgUQChL9KhO/EvaikpgytSqqIin+LdeN88OxVYqn15XPo6lSGkpI430W3MfHJ+b5t5zDQ01IYX1VBfMj1x3jyPBpLp/UuuUaXAv0q0jxE55ktio5LzvftKoehvna+i/Bi4pJhmOcbpJDk5CEmTx5iipmH6P9IHjgeNLPHQ95+JcFQv5A8xCrKgzS+Wva/MbHJMKqqI4uJjk2usHdSfQnjgTMteeSdSfmYiRMnIjExUfaIiIj4+ErF8D4jC2GPouHpbCpbJhIBTV1MEXo/UuE6GmrKyMqSX5aZPYUiEonklr9Ny0BU/FvoVFZDi7pmOHbpcYm2v6SoqijD0aYGLlx5IFuWlZWFC1cfop6D4lue6zqYy8UDwF+XHyiM33XsEpxsa6C2VcW8pieHqooyXOxMcS5UPg/nQh/A1clc4TquTuY4d1k+D2dD7sPVyaI0m1qqPiUPDRTkITjkPhp8YXn4r46HOnamCA69L1uWmwfF/XJzspCLB4CgS/dkeTMz0Uc1fW25mKSUVFy5HQ5XZ/MS70NJ+BLGA4uWbFZWVhCJRLh7967C5+/evQtdXV0YGBjILVdTU4O2trbco6QtP3gVvds4omtze9jU0MXCIS1QWV0F207fAQCsGNUaUz+4nflEyFN87+OEb5vYoGY1bXjVqYmfezTEiZCnyMouXprXNUOLemay54/M7YgHL+Jk26yI/Dt7YcfRi9h7IgSPwqMwaeFevE1NRydv6YWzP83Zhl9XB8ji+3VsiuCQe1izKwiPnkVh0YYTuHk/An06NJHbbvKbdzh29jq6fO1Rpv35VEO6NcOWQxew4+gl3H/6CmN+3Y2379LQ3Vfa/sHTN2PmssOy+IFdvHDmnztYtu0MHoS/wq9rjiHs7nP4d2oqi4lPfIObD17g/tNXAIBHz6Jw88EL2Xn9imhwdh52Hr2EBx/koVt2HoZM34xZefIQmJ2Hh/+hPHA8SA3p3hybD17AjoCLuP/0FX76ZRfepKahRztpHgZN24wZSw/J4gd2leZh6VZpHn5ZfRRhd59jQCdPANIveIO6NcP89SdwLPgGbj96icHTt8Coqg6+9nQplz4WxX99PPD0UDZ9fX20atUKy5cvx6hRo+Sua3n16hW2bduG3r1755upKAsH/nqAqjoa+LlHQxjqVsLNJ6/RcdpBxCRIL86tYaAtdy3K/F2XIJFIMKlnIxjrayI26S1OhDzFrC0XZDHalVUxtXdjVK+qifjkNBy58BCzt1xARmZW3pevMNo1r4u4hBQsWn8CMXFJsLcywabfB8ouInsZHQ+ROPf9qe9ogSVTemHBumP4fc1RmNcwwOo5/WBrKX/X1ZEzVyGRSODXol6Z9udTdWhVH68TUvDL6qOIjk2Go40Jdi8eIpvWfhkVD/EHeXBztsTqWX0xZ2UAZq8IgKWpAbb8NgD2tarLYo6fv4lhs7bJfvafvBEAMM7fG+MH+JRNx4qpQ6v6iC0kDy8U5GHVrL6YuzIAc7LzsDlPHk7kycOA7DyMreB54HgAvm0tzcPcVUezT+GYYO8fQ3PHw6s4iD84fru7WGLN7L6YsyIAs5YfgaWpAbbO/wG1rXLzMKJ3S7xNTcOouTuQmJIKD5da2PvHkAp93dt/fTyIJMU9H/If9vDhQzRq1Aj29vaYPXs2LCwscPv2bYwdOxZpaWm4ePEi9PQU37GTIykpCTo6OlBrOQ8iZfUyannFFL5raHk3oULQUud3AwDggUaq7L/2VEwffnB+6bK+5DsgIP3cNDaogsTExI+ereDpoQ9YW1vj8uXLsLS0ROfOnVGrVi388MMPaNasGf7555+PFixERERUevgVMA8zMzNs3LixvJtBREREeXCmhYiIiASBRQsREREJAosWIiIiEgQWLURERCQILFqIiIhIEFi0EBERkSCwaCEiIiJBYNFCREREgsCihYiIiASBRQsREREJAosWIiIiEgQWLURERCQILFqIiIhIEFi0EBERkSCwaCEiIiJBYNFCREREgsCihYiIiASBRQsREREJAosWIiIiEgQWLURERCQILFqIiIhIEFi0EBERkSCwaCEiIiJBYNFCREREgsCihYiIiARBubwb8F91a8MAaGlrl3czypXt4F3l3YQK4eHKLuXdhApBS0OlvJtQIWRlScq7CVTBZHzhY6I4/edMCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAjK5d0AKprNB/7Cqp2BiIlLhn2t6pgx4lvUsTcrMP5oUBgWrD+OF6/iYGFigAmDfNHMo7bseXPPUQrXmzioHQZ2a17i7S8p37ewwRDv2jDQ0cCdiHhM2hqKa09iC4wf0NoOfZrbwES/EuKS0xBw+Tnm7rmGtPdZAIBhvg74un5NWBlr4937TIQ+jMHs3dfw+FVSWXXpk2zaLz8eZo74FnVqFzweAoLCsGCddDyYmxhg4iBfNG9YWy7mYXgU5q08gkvXHyMjMwvW5tWwatb3MKmmW9rd+WRrdgfjf1vPIDo2CY7WJvh1bCfUdzAvMP7g6auYu/IonkfGwtLUANOHtUfrxg6y5yUSCeatOorNBy8gMSUV7s6WWDChC2rVNCyD3ny6tXvOYek2aR4crE3wy+iOhebh0JlrmLsqABGRcbA0NcC0od+g1Qd5OBIUho37/8b1e88Rn/QWZ7eMh5NNjTLoyefheJBav/cclm8LRHRcEmpbmWDuTx1Rz6Hg48PhM9fw6+qjiHgVB4saBpgy1A8tG+Xm4fe1x3Dw1FW8jE6AqooSnG1NMXGQb6G5LS2caRGAI4HXMHvZQYzo0wZH14xG7VrV0XvMKryOT1YYf+XWUwyftQVdfNxxbM0YtG7iiB8mrcf9J5GymJD9M+Qev43vCpFIBG9P57LqVrF942aG6d3qY8GhG2g97RhuR8Rjx5jmqKqlpjC+g4c5JnWqiwUHb6DpxCP4af1FfONmhokd68piGtpWw4Yz9/H1rBPo/NtpqCiJsWtsc1RSVSqrbhXb4TPXMGvZQYzs2wZH146GvVV19CxkPFy++RTDZm5Bl6/dcWztGLRp4ogBecZD+MvX+O7HP1DLzBC7lgzFnxvGYnjv1lBTrbjfa/afvILJiw9gvL83zm4ZD0drE3w3bBli4hTn4dL1J/CfvBE9v2mI4K0T8LWnC3qOWY07j/6VxSzZfBqrdgVj4cSuOLVhDCppqOK7YcvwLu19WXWr2A6cuoIpSw5gbH9vBG4aB0crE3QasbzAPITceIIBUzaiZ7uGCNo8Hj5NndFr3BrcfZybh7ep6fBwscS0H78pq258No4HqYOnr2LaHwcwun9bnNo4Fg7WJug6quDxEHrjCQZN24Tu7Rri9KZx8G7qjL7j18qNB0tTQ8wd3Qlnt07A4ZUjYWqshy4jlhd4zClNFa5o6du3L0Qikeyhr6+Ptm3b4saNGwWuEx4enm+d1q1b49q1a7IYLy8vuZicx6BBg2QxHy7X1taGq6srDh06VKr9LYq1u8+iq29DdPZxh7W5EeaM7gQNdVXsPnZJYfz6vefg6WaHgd2aw8q8Gkb394GDTQ1sOnBeFmOory33OPX3LTSsa4Wa1auWVbeKbWBbe2wLfoSd55/gwb+JGLfxElLTM9G1qZXCeFdrA4Q+jMaBi+GIeP0GwbcicfBiOOpa6stiui8IxK6/nuD+y0TciUjAiLUXUKOqJpwt9BVusyJYu/ssumWPBxtzI8zLHg+7jhY+HgZ1aw5r82oY4+8DR5sa2Lg/dzz8vuYYmnnYY9JgPzja1IC5SVW0/soRVXW1yqpbxbZ8eyB6t2+EHn4NYWdpjIUTu6KSuiq2Hv5HYfyqnWfRoqE9hvdqCVsLI0wa7AsXO1Os2RMMQPqteuWOIIzp1wY+ns5wtDbBihm98ep1Io4GXy/LrhXL8h1B6PVNQ/Ro5wE7S2MsmNAFGuqq2HakgDzsOosWHvYYlp2Hnwf5wtnWFGv3nJPFdPFxw1h/b3i62pZVNz4bx4PUyh1B6OnXCN18PWBrYYzfx3WGhpoqdgRcVBi/encwmrnbY2jPFrAxN8KEgV/DybYG1u/NPT5816YBPN1sYW5SFXaWxpg5ogOS37yTK/DKSoUrWgCgbdu2iIyMRGRkJM6cOQNlZWX4+vp+dL3Tp08jMjISf/75J1JSUuDt7Y2EhATZ8wMGDJBtN+fx22+/yW1jw4YNiIyMxOXLl9G4cWN07NgRN2/eLOkuFln6+wzcevACjevbyJaJxWI0rm+Nq7efKVzn2u1wuXgAaOpqW2B8TFwygv65gy4+7iXX8BKmoiSGs7kezt3OnR2QSIDztyPRwEpxoRX6MAbO5vqyIqWmgSaau5jgzPWXBb6OloYKACAhJa0EW19y0t9n4OaDF/iqgfx4+KqQ8XD1dji+yjse3HLHQ1ZWFgL/uQNLU0P0HL0Sdf2mwG/gIvx5vvzG/cekv89A2L0IeLnlfqiKxWJ4utki9OZTheuE3HwKL1c7uWXNPewRejMcAPDsZSyiYpPg5ZYbo6OpgfoO5gi9EV7ifSgJ6e8zcP1eBDzz5sHVVtavvEJvhucrRpp72BWYNyHgeJBKf5+BG/cj0MRVPg9NXW1x+ZbiPFy5FY6mrvLHh2bu9gXGp7/PwJaDF6CtqQEHa5OSa3wRVciiRU1NDUZGRjAyMkKdOnUwYcIEREREICYmptD19PX1YWRkhAYNGmD+/PmIiorCpUu53z4rVaok227OQ1tbW24bVapUgZGREWxsbDBr1ixkZGQgKCioVPpZFPGJb5CZmZXvG6+BrhZi4hRfdxETl6ww/nUB8ftOhKByJXW0aVpxTw3paalBWUmMmMR3cstjEt/BUEdD4ToHLobjtwPXcWhSa0Ss646Q+e3xz70o/BFwW2G8SATM6tEAlx5E497LxBLvQ0mIK2A8VNUrfDwY6BU8fl7Hp+BNahqWbzsDL3c7bF0wCG2aOOGHyRtwMexR6XTkM8UmpCAzMyt/v/S0ER2rOA/RsUkw0M8bryWLj8r+N2+Mob5Wgdssb7EJ0vFgqCd/HDPU00J0AeMhOjZJQd60EB1b9lP9JYXjQSouezwU5/2Vjgftj8af/OsWLJqPQU3P0Vi18yx2LxkC/SqaJduBIqi4J6yzpaSkYOvWrbCysoK+ftGn7DU0pB9k6enpn/S6GRkZWLduHQBAVVW1wLi0tDSkpeV+K09KqpiDuTC7j4egfct6UFdTKe+mlKhGdtUwwtcREzaH4urj17CopoVZPRpglJ8TFh3OP4vwS2832JlUgd+ck+XQ2vKTJZEAAFp/5Qj/zl4AAAdrE1y5FY6thy7Ao47i029E9OVoXN8agZvGIzYxBVsP/YMBkzfg+NrR+Qqk0lYhZ1oCAgKgqakJTU1NaGlp4fDhw9i1axfE4qI1NyEhAbNmzYKmpibc3Nxky5cvXy7bbs5j27Ztcut269YNmpqaUFNTw6hRo2Bubo7OnTsX+Frz5s2Djo6O7GFqavppnS6Ark5lKCmJ813wFBOfnK86zmGgp6UwvqqC+JDrj/HkeTS6+HqUXKNLQVxyGjIys2Cgoy633EBHHdGJqQrXGfetC/ZeeIrtwY9w70UCjl+JwLy9YRjm6wCRSD52bi9XtHQxwXe/nEJk/NvS6sZn0ytgPLyOK3w85L0I78Pxo6dTGcpKYlibVZOLsTKrhpdR8SXY+pKjX0UTSkri/P2KS4KhvuI8GOprIyY2b3yyLL5a9r95Y6JjkwvcZnnTryIdD3lnVaLjkvPNvuQw1NdWkLdkGOpX3OuXPobjQUovezwU5/2Vjoekj8ZX1lCDhakBGjhaYPGk7lBWUsL2Aq6bKk0Vsmhp1qwZwsLCEBYWhpCQELRp0wbe3t549uwZvL29ZQWHg4OD3HqNGjWCpqYmdHV1cf36dezatQvVquUeiHv06CHbbs7Dz89PbhuLFi1CWFgYjh8/jtq1a2Pt2rXQ09MrsK0TJ05EYmKi7BEREVGiuVBVUYajTQ1cuPJAtiwrKwsXrj4s8Ba2ug7mcvEA8NflBwrjdx27BCfbGqhtVfbnJovjfWYWboTHoUltI9kykQj4qrYRLj96rXAdDTUl2SxCjsws6c8i5FYtc3u5wru+KTr+ehrPX78phdaXHFUVZTjZ1MDfecbD34WMh3oO5vj7ap7xEJo7HlRVlOFiVxOPI6LlYp6+iEENo4LHfnlSVVFGHTtTBIfely3LysrCudAHcHWyULiOm5OFXDwABF26B1cncwCAmYk+qulry8UkpaTiyu1wuDqbl3gfSoL0vTPFuVD58SDNg7nCdVydzHHusvx4OBtyv8C8CQHHg5SqijKcbU1x/rL8eDh/+T4aOCrOQ31Hc7l4AAgOuVdgvGy7kiykv8/4/EYXU4U8PVS5cmVYWeVOSa9duxY6OjpYs2YN1q5di9RU6TdrFRX50xm7du1C7dq1oa+vjypVquTbro6Ojtx2FTEyMoKVlRWsrKywYcMG+Pj44M6dOzA0VHxfvpqaGtTUFN9yW1L8O3th9LztcLIzRR07M6zbG4y3qeno5C29cPanOdtQzUAH43+QXqzcr2NTdBm+FGt2BaGZR20cCbyGm/cjMG+M/IxR8pt3OHb2OiYN8cv3mhXRqhN3sWRAI1x/GodrT15jQBt7VFJTxs7zjwEA//uhESLj32LunjAAwKlrLzGwrR1uPovDtcevYV5NC+O/dcGpsBeyYuaX3q7o4GGBvkvOIuXde9lMTvLb93j3PrNc+vkxsvFga4o69mZYt0c6HjpnX0g9cs42GFXVwYSBueOh8/ClWL0zCM0b1sbhM9dw434EfhmbOx4GdmuGodM3w92lFhrVtcLZS/dw+sJt7FoytFz6WBRDujfHkBlbUNe+Juo5mGPFjiC8SU1Dj3bSWcNB0zbD2EBHdtvuwK5e8B24GEu3nkHrrxyw/+QVhN19jsU/dwMgvXtwULdmmL/+BCxNDWBmoo+5K4/CqKoOvvZ0Kbd+fsyQbs0wdOZW1LGviXq1zbBq51m8fZeG7tmzp4Onb4axQRVMHSrdzwd28UK7QUuwbNsZtGrsgAOnriLs7nMsmthVts34xDd4ERWPVzHSa7sePYsCIP1WXq2CzjJwPEgN6tYMw2dtRR07U9R1MMPqnWfx9l06uvpKjw8/ztgCIwMdTM4+7v/Q2RPth/yBFdsD0bKRAw6evoLr9yIwf4J0PLxJTcPijSfRpokjqunrIC4xBev3nsermES0a163wHaUlgpZtOQlEokgFouRmpoKE5OCZwRMTU1Rq1atEntdNzc31K9fH3PmzMGSJUtKbLvF1a55XcQlpGDR+hOIiUuCvZUJNv0+UHYu8WV0PETi3JmD+o4WWDKlFxasO4bf1xyFeQ0DrJ7TD7aWxnLbPXLmKiQSCfxa1CvT/nyqQyHPoK+thnHfOsNARwO3n8ej2/xAvE6SXpxrolcZWVm5MyuLDt+EBBJM+K4OjHQ1EJuchlPXXmDevjBZTN8W0qvsD/zcWu61Rqy5gF1/PSn9Tn0CvxbS8bAwezzUtjLBlvm54+HfqHiIPzj/1cDJAn9M7YX5a4/ht+zxsCbPeGjb1BlzR3fCsq2nMW3JAdSqaYBVM/vCzdmyzPtXVN+2ro/XCSmYu+ooomOT4WRjgr1/DJVN3b94FSeXB3cXS6yZ3RdzVgRg1vIjsDQ1wNb5P6C2VXVZzIjeLfE2NQ2j5u5AYkoqPFxqYe8fQyr09V4dWknz8MtqaR4cbUywe/EQWR5eRsVD/MHxwc3ZEqtn9cWclQGYvSIAlqYG2PLbANjXys3D8fM3MWxW7qlz/8kbAQDj/L0xfoBP2XSsmDgepNq3rIfY+BT8tvZY9i8brIEdiwbLThfmHQ+uzpZYMaMPfll9FHNXHoGFqSE2/uovGw9KYjEePYvC7mMhiEtMga5OZdSxr4lDK0bALs9nSlkQSSR55s/LWd++fREVFYUNGzYAAOLj47F06VKsWLECgYGB8PLyyrdOeHg4LCwscO3aNdSpU0fhdr28vGBjY4OZM2fKLVdTU4OurvQ3fopEIhw4cADt27eXPX/8+HF06NABjx8/LrRgypGUlAQdHR08jHgNLe2K+Y2krNgO3lXeTagQHq7sUt5NqBBybif/0n1YWH/JPvzg/NKlZ2SVdxPKVVJSEkyr6SIxMTHfHb15VchrWk6cOAFjY2MYGxvD3d0doaGh2LNnj8KCpTjWrFkj227Oo1u3boWu07ZtW1hYWGDOnDmf9dpERET0eSrcTIvQcaYlF2dapDjTIsWZFinOtEhxpiUXZ1oEPtNCRERElBeLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCYJyeTfgv6qyujI01b/s9D5c2aW8m1Ah1Pzm9/JuQoUQf/Ln8m5ChSAWi8q7CRWCRCIp7yZUGCpKX/aYKE7/OdNCREREgsCihYiIiASBRQsREREJAosWIiIiEgQWLURERCQILFqIiIhIEFi0EBERkSCwaCEiIiJBYNFCREREgsCihYiIiASBRQsREREJAosWIiIiEgQWLURERCQILFqIiIhIEFi0EBERkSCwaCEiIiJBYNFCREREgsCihYiIiASBRQsREREJAosWIiIiEgQWLURERCQILFqIiIhIEFi0EBERkSCwaCEiIiJBYNFCREREgsCihYiIiASBRQsREREJgnJ5N4CKZt2ec1i67QyiY5PgYG2CX0Z3RD0H8wLjD525hnmrAhARGQdLUwNMHfoNWjV2kD0fEBSGjfv/xvV7zxGf9BZBW8bDyaZGGfTk82za/xdW7QxETFwy7GtVx8wR36JObbMC4wOCwrBg3XG8eBUHcxMDTBzki+YNa8vFPAyPwryVR3Dp+mNkZGbB2rwaVs36HibVdEu7O5/Mv119DOvkDkM9Tdx6EoXxy07i6v1IhbHKSmKM6toI3Vo5wbiqFh5FxGL6uiCcufxEFtPIyRTDOnnAxdoIxvpa6DF9L45deFBW3flka3YH439bpfuFo7UJfh3bCfUL2S8Onr6KuSuP4nlkLCxNDTB9WHu0/mC/kEgkmLfqKDYfvIDElFS4O1tiwYQuqFXTsAx68+mYB6m1e87J8uBgbYJfx3T8SB6kx8nn2cfJ6T/KHyclEgnmrT6GLbI8WGD++C8vD0eCwrBh/9+4flf6eRG8tfw+LzjTIgAHTl3BlCUHMLa/NwI3jYODlQk6jViOmLhkhfEhN57ghykb0aNdQwRtHg+fps7oPW4N7j7+VxbzNjUd7i6WmPrjN2XVjc92+Mw1zFp2ECP7tsHRtaNhb1UdPceswut4xXm4fPMphs3cgi5fu+PY2jFo08QRAyatx/0nuR/u4S9f47sf/0AtM0PsWjIUf24Yi+G9W0NNteLW8x087TF7YAv8uvUveA1Zj1tPorFvbldUrVJJYfzkvp7o+3VdjF92Eh7+q7Hh6DVsmfYdnGpVk8VUUlfBrSfRGLv0z7Lqxmfbf/IKJi8+gPH+3ji7ZTwcrU3w3bBlBe4Xl64/gf/kjej5TUMEb52Arz1d0HPMatx5lLtfLNl8Gqt2BWPhxK44tWEMKmmo4rthy/Au7X1ZdavYmAep/aekeRjn742gzePgaG2CjsMLPk5euvEEA6ZsRA+/hji7ZTx8PJ3Rc+wa3PngOPnH5tNYvSsYCyZ0wan1o1FJQw0dhy//4vLwNjUdHi6WmFYBPi8EUbT07dsX7du3L/B5Ly8viEQiiEQiqKuro3bt2li+fLns+Y0bN8qe//Chrq4u9xo5y1VUVGBhYYFx48bh3bt3pdm1IlmxIwi9vmmI7u08YGtpjAUTukBDXRXbj/yjMH7VrrNo7mGPYb1awsbCCBMH+cLZ1hRr95yTxXT2ccNYf294utqWVTc+29rdZ9HNtyE6+7jDxtwI80Z3goa6KnYdvaQwfv3ec/B0s8Ogbs1hbV4NY/x94GhTAxv3n5fF/L7mGJp52GPSYD842tSAuUlVtP7KEVV1tcqqW8U25Ds3bD4ehu0nb+D+89f4aclxvE3LQM82LgrjO7d0xKIdF3Aq9DGevUrA+oCrOBXyGD92dJfFnA59gjkbg3H074o/u5Jj+fZA9G7fCD38GsLO0hgLJ3ZFJXVVbD1cwH6x8yxaNLTH8F4tYWthhEmDfeFiZ4o1e4IBSL9Vr9wRhDH92sDH0xmO1iZYMaM3Xr1OxNHg62XZtWJhHqSWbw9C7/YN0aOdhzQPE7qgkroqthV0nNx5Fi08PsjDIF8425li7W7pcVIikWDlzrMYnZ0HB2sTrJjeKzsPN8qya8VS0nkAgC4+bhjn7w0vt/L/vBBE0VIUAwYMQGRkJO7cuYPOnTtj6NCh2LFjh+x5bW1tREZGyj2ePXsmt422bdsiMjIST548waJFi7Bq1SpMmzatrLsiJ/19Bq7fi4DnB4NFLBbD09UWoTfDFa5z+WZ4vmKkmYcdLt98WppNLVXp7zNw88ELfNXARrZMLBbjq/rWuHr7mcJ1rt4Ox1f1beSWNXWzlcVnZWUh8J87sDQ1RM/RK1HXbwr8Bi7Cn+dvll5HPpOKshh1rI1x9lq4bJlEAgRfewpXexOF66ipKOHd+wy5Ze/SM+DhUPFPBxYk/X0Gwu5FyB1ExWIxPN1sEVrAOA+5+RRernZyy5p72Mv2o2cvYxEVmwQvt9wYHU0N1HcwR+iN8BLvQ0lgHqRkx0nXoh8nQ2+Gyx1XAaC5h50sb8/+zclDbox2Th4q6LG0NPJQ0fxnipZKlSrByMgIlpaWmD59OqytrXH48GHZ8yKRCEZGRnKPatWqyW1DTU0NRkZGMDU1Rfv27dGyZUucOnWqrLsiJzbhDTIzs2Cgpy233EBPC9FxSQrXiY5NgoGe/EyBoZ4WomMVTw8KQVyiNA95Z0Cq6mkhpoA8xMQl58uDgW5u/Ov4FLxJTcPybWfg5W6HrQsGoU0TJ/wweQMuhj0qnY58Jn3tSlBWEiMm/o3c8pj4NzDUq6xwncDLTzHkWzdYVteFSAR41TOHb2NbVNPTLIsml4rYhJTs/SLP+6unjejYQvYL/bzxWrL4qOx/88YY6msVuM3yxjxIFXacjCokD4aKjpPZp1FkeciX2y8rDxVNxT1x/5k0NDSQnp7+yevfunULFy5cgJlZwRd5AkBaWhrS0tJkPyclVczBTPllSSQAgNZfOcK/sxcAwMHaBFduhWProQvwqGNVjq0rORNWnMKSUd4IWTcQEgBP/43H9pM30KONc3k3jYioWP4zMy05MjMzsXXrVty4cQPNmzeXLU9MTISmpqbcw9vbW27dgIAAaGpqQl1dHU5OToiOjsbYsWMLfb158+ZBR0dH9jA1NS3R/uhXqQwlJXG+2YSYuGQY5qmmcxjqa+e76Co6LhmG+hX3Oo2P0dOR5iHvRbev45LzfavIYaCnlS8PMfG58Xo6laGsJIa1mfyMm5VZNbyMii/B1pec2KS3yMjMgoGu/KyKgW5lRMe9UbxO4lv0nL4PJn6/w7nnUrj1X4U3qekIj0wogxaXDv0qmtn7RZ73Ny4JhvqF7BexeeOTZfHVsv/NGxMdm1zgNssb8yBV2HGyWiF5yDubEB2XLJt1kOUhX26/rDxUNIIqWrZt2yZXdJw/n3tB5fLly6GpqQkNDQ0MGDAAo0aNwuDBg2XPa2lpISwsTO6xdu1aue03a9YMYWFhuHTpEvr06YPvv/8e3333XaFtmjhxIhITE2WPiIiIEu2zqooyXOxMcS409wLJrKwsnAt9AFcnc4XrNHAyx7nL8hdUBofcRwMnixJtW1lSVVGGk00N/H1FPg9/X32Ieg6KZ8PqOZjj76vyefgr9IEsXprbmngcES0X8/RFDGoY6ZVwD0rG+4wshD2MhGcdc9kykQhoWsccoXdfFrpu2vtMRMamQFlJjHZf2eL4P8K56DYvVRVl1LEzRXDofdmy3P1C8Th3c7KQiweAoEv3ZPuRmYk+qulry8UkpaTiyu1wuDqbl3gfSgLzIFXQcTL4csHHSVcnc7l4ADh76b4sb2bVC8lDBT2WlkYeKhpBnR7y8/ODu3vuHQ8mJrkXHvbo0QOTJk2ChoYGjI2NIRbL12NisRhWVoVP91euXFkWs379eri4uGDdunXo379/geuoqalBTU3tU7pTZIO7NcOPM7eijn1N1KtthpU7z+LtuzR08/UAAAyZvhnGBlUwZagfAGBgFy/4DVqCZdvOoHVjB+w/dRVhd59j4cSusm3GJ77Bi6h4vIpJBAA8ehYFQFp1F1SRlzf/zl4YPW87nGxNUcfeDOv2BONtajo6+0jHxMg522BUVQcTBvoCAPp1bIrOw5di9c4gNG9YG4fPXMON+xH4ZWxn2TYHdmuGodM3w92lFhrVtcLZS/dw+sJt7FoytFz6WBTL94Vg+dh2uPYwElfv/YvB37qhsroKtv0pvaNhxdh2iIxNxsz1ZwEA9e2qw1hfCzcfR6F6VS2M79UEYrEIS3ZflG2zsroKLKrn/l4aMyMdOFoaIiH5HV7EVMxTnkO6N8eQGVtQ174m6jmYY8WOILxJTUOPdtL9YtC0zTA20JHdpjmwqxd8By7G0q1n0PorB+w/eQVhd59j8c/dAEivexvUrRnmrz8BS1MDmJnoY+7KozCqqoOvPRXfmVURMA9SQ7o3w9AZ2cdJh+zjZGoaumcfJwdP2wxjwyqYmnOc7OqFdgOXYGnOcfKk9Di56GfpcVIkEmFQVy8sWP8napkawqy6PuauDMjOQ8U9tVrSeQDyf148zPm80NNGtapl+3khqKJFS0sLWlqKp6x0dHQ+WpQUh1gsxs8//4yffvoJ3bt3h4aGRoltu7g6tKqP2IQU/LL6KKJjk+FoY4Ldi4fIpihfRMVDLBbJ4t2cLbFqVl/MXRmAOSsCYGlqgM2/DYB9reqymBPnb2LYrG2ynwdM3ggAGOvvjfEDfMqmY8Xk16Iu4hJSsHD9CcTEJaG2lQm2zB8ou1Du36h4iEW5eWjgZIE/pvbC/LXH8NuaozCvYYA1c/rB1tJYFtO2qTPmju6EZVtPY9qSA6hV0wCrZvaFm7NlmfevqA4E30VVnUr4uXdTGOpWxs0nUeg4aRdiEqSnh2oYasuu1wEANRVlTOrrCXPjKniTmo5TIY8x6NfDSHqTey1WHRtjBMzvKft57qBWAIDtJ29g6PyAMupZ8Xzbuj5eJ6Rg7irpfuFkY4K9fwzN3S9excmNB3cXS6yZ3RdzVgRg1vIjsDQ1wNb5P6C2Ve5+MaJ3S7xNTcOouTuQmJIKD5da2PvHEKirqZR5/4qKeZD6tlV9xManYN4Hx8k9Swo+Tro7W2J19nFy9nLpcXLr7wNQ+4Pj5PDeLfHmXfoHebDEniVfXh6On7+JH2fmfl74T9oIABjn740JP5Tt54VIIvng6FZB9e3bFwkJCTh48KDC5728vFCnTh0sXrxY4fMbN27EiBEjcP/+/XzPGRoaQiwWK3yNjIwMmJubY+TIkRgzZkyR2pqUlAQdHR38G5MAbe2KOWNRVt6mZXw86AtQ85vfy7sJFUL8yZ/LuwlUgQjgo4fKSFJSEoyqVkFiYuJHPzcFdU3L50hKSoKxsXG+R3R0dIHrKCsr48cff8Rvv/2GN28UX+RIREREZUMQMy1CwpmWXJxpkeJMixRnWuhD/OihHJxpISIiov8cFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIE5fJuAP13aWmolHcTKoT4kz+XdxMqBN0OK8q7CRXC4y39y7sJFUKVSjw+5MiSSMq7CeUqM6vo/edMCxEREQlCkWZaDh8+XOQN+vn5fXJjiIiIiApSpKKlffv2RdqYSCRCZmbm57SHiIiISKEiFS1ZWVml3Q4iIiKiQn3WNS3v3r0rqXYQERERFarYRUtmZiZmzZoFExMTaGpq4smTJwCAKVOmYN26dSXeQCIiIiLgE4qWOXPmYOPGjfjtt9+gqqoqW+7o6Ii1a9eWaOOIiIiIchS7aNm8eTNWr16NHj16QElJSbbcxcUF9+7dK9HGEREREeUodtHy8uVLWFlZ5VuelZWF9+/fl0ijiIiIiPIqdtFSu3ZtnD9/Pt/yvXv3om7duiXSKCIiIqK8iv1r/KdOnYo+ffrg5cuXyMrKwv79+3H//n1s3rwZAQEBpdFGIiIiouLPtHzzzTc4cuQITp8+jcqVK2Pq1Km4e/cujhw5glatWpVGG4mIiIg+7Q8mNmnSBKdOnSrpthAREREV6JP/yvPly5dx9+5dANLrXOrXr19ijSIiIiLKq9hFy4sXL9CtWzf8/fffqFKlCgAgISEBjRo1ws6dO1GjRo2SbiMRERFR8a9p8ff3x/v373H37l3ExcUhLi4Od+/eRVZWFvz9/UujjURERETFn2kJDg7GhQsXYGtrK1tma2uL//3vf2jSpEmJNo6IiIgoR7FnWkxNTRX+ErnMzExUr169RBpFRERElFexi5bff/8dw4YNw+XLl2XLLl++jBEjRmD+/Pkl2jgiIiKiHEU6PaSrqwuRSCT7+c2bN3B3d4eysnT1jIwMKCsro1+/fmjfvn2pNJSIiIi+bEUqWhYvXlzKzSAiIiIqXJGKlj59+pR2O4iIiIgK9cm/XA4A3r17h/T0dLll2tran9UgIiIiIkWKfSHumzdv8OOPP8LQ0BCVK1eGrq6u3IOIiIioNBS7aBk3bhwCAwOxYsUKqKmpYe3atZgxYwaqV6+OzZs3l0YbiYiIiIp/eujIkSPYvHkzvLy88P3336NJkyawsrKCmZkZtm3bhh49epRGO4mIiOgLV+yZlri4OFhaWgKQXr8SFxcHAPjqq69w7ty5km0dERERUbZiz7RYWlri6dOnqFmzJuzs7LB79264ubnhyJEjsj+gSCVv3Z5zWLrtDKJjk+BgbYJfRndEPQfzAuMPnbmGeasCEBEZB0tTA0wd+g1aNXaQPR8QFIaN+//G9XvPEZ/0FkFbxsPJpuL/scs1u4Pxv63SPDham+DXsZ1Qv5A8HDx9FXNXHsXzyFhYmhpg+rD2aP1BHiQSCeatOorNBy8gMSUV7s6WWDChC2rVNCyD3nw65kHK39sBw9rXgWGVSrgVHovxa//C1YfRBcYP8nVGv7YOqFFVE3HJ73DowmPM3HoJae8zAQDXV/VATcP8NxOsPX4LY1efL7V+fK4tB/7Cml1BiIlLhn2t6pg2vANc7M0KjD92NgyL1p/Ai1dxMK9RFeN+8EUzj9qy51/HJePX1QH46/J9JKWkwtXZEtOGfwuLGgZl0Z1PtlbBcbKw/eLQmWuY+8Fxclqe4+SRPMfJswI5Tq7bew7LtgYiOi4JDlYmmDe6I+o5FDweDp25hl9WH5XlYcpQP7RqJM3D+4xMzFsZgNP/3MGzl7HQ0lSHp6stpgzxg5GBTll1SabYMy3ff/89rl+/DgCYMGECli1bBnV1dYwaNQpjx44t8QYScODUFUxZcgBj+3sjcNM4OFiZoNOI5YiJS1YYH3LjCX6YshE92jVE0Obx8GnqjN7j1uDu439lMW9T0+HuYompP35TVt34bPtPXsHkxQcw3t8bZ7eMh6O1Cb4btqzAPFy6/gT+kzei5zcNEbx1Ar72dEHPMatx51FuHpZsPo1Vu4KxcGJXnNowBpU0VPHdsGV4l5b/T1VUFMyDVIfGtTD7+8b4dddleI3ei1vhsdg31RdVdTQUxndsYo1pvdzx267LcB+2E8OWBqHDV1aY0tNdFtN87D7Yfr9R9mg/7TAA4ODfj8ukT58iIPAa5q44hOF92uDw6p9gV6s6+o5bjdfxisfDlVtPMXLWVnTyccORNaPR6isnDJ6yAfefRgKQFrCDpqxHRGQsVs3uhyOrR8Okmi56j1mJt6lpZdm1Ysl7nHQswnFywJSN6PnBcbKXguOkh4slpgnoOHng1FVMXXIAY/zb4symsXCwNkHnkYXnYeDUTejRriECN42Dd1Nn9Bm3VpaH1HfpuHH/BX76vg3ObBqLjb/0x6Nn0eg5dnVZdkum2EXLqFGjMHz4cABAy5Ytce/ePWzfvh3Xrl3DiBEjirWtvn37QiQSyR76+vpo27Ytbty48dF1b9++jc6dO8PAwABqamqwsbHB1KlT8fbtW7k4c3Nz2fYrVaoEJycnrF27Nt/2JBIJ1qxZg4YNG0JbWxuamppwcHDAiBEj8OjRo2L1q6St2BGEXt80RPd2HrC1NMaCCV2goa6K7Uf+URi/atdZNPewx7BeLWFjYYSJg3zhbGuKtXtyT9919nHDWH9veLraKtxGRbR8eyB6t2+EHn4NYWdpjIUTu6KSuiq2Hi4gDzvPokVDewzv1RK2FkaYNNgXLnamWLMnGID0PV+5Iwhj+rWBj6czHK1NsGJGb7x6nYijwdfLsmvFwjxIDfFzweZTd7A98D7uv4jHTyuD8TbtPXq2sFMY72ZXDZfuvcLe8w8REZOMoOsvsO/8Q9S3zp1Nik16h+iEVNmjTQNzPIlMxN+3/1W4zYpg/Z5gdPnaAx293WBtboTZP3WEhroK9h4PURi/cd95NHWzww9dm8PKrBp+6ucNB2sTbDnwFwAg/EUMrt15hpkjO8LZriYsaxpi1qiOeJf2HkcCr5Vl14plefZxskc7D9h9cJzcVshxskX2cdLWwgg/KzhOdhHgcXLljiD0/KYRuvt6wNbCGPPHd5Z+XgRcVBi/elcwmnvY48eeLaSfFwO/hrNtDazbK51Z1NbUwN7/DUX7lvVgZVYNDRwt8MuYjrh+LwIvXsWVZdcAfELRkpeZmRm+/fZbODs7f9L6bdu2RWRkJCIjI3HmzBkoKyvD19e30HUuXrwId3d3pKen4+jRo3jw4AHmzJmDjRs3olWrVvl+d8zMmTMRGRmJW7duoWfPnhgwYACOHz8ue14ikaB79+4YPnw4fHx8cPLkSdy5cwfr1q2Duro6Zs+e/Ul9Kwnp7zNw/V4EPN1ydxqxWAxPV1uE3gxXuM7lm+H5drJmHna4fPNpaTa1VKW/z0DYvQh45c2Dmy1CC+hXyM2n8HKV/wBr7mEvy9uzl7GIik2Cl1tujI6mBuo7mCP0RniJ96EkMA9SKspi1KllgLPXX8iWSSRA8I2XcLWtpnCdkHtRqFPLAPWyixSzalpoVd8Mp648L/A1OntaY9uZeyXfgRKS/j4Dtx68QKP6NrJlYrEYjerZ4NrtcIXrXLsTjsb1reWWNXG1k8Wnv88AAKip5l49IBaLoaqiXGGPIZ9ynAxVcJxs7mFX4H4kBOnvM3D9foRcv8RiMZq62hb43l2+FY6mrjZyy5p52Bf6XielvINIJIKOluJZzdJUpGta/vjjjyJvMGcWpqjU1NRgZGQEADAyMsKECRPQpEkTxMTEwMAg//lTiUSC/v37w97eHvv374dYLK27zMzMYGNjg7p162LRokUYP368bB0tLS3Za4wfPx6//fYbTp06BW9vbwDArl27sHPnThw6dAh+fn6y9WrWrAkPDw9IJJJi9akkxSa8QWZmFgz05M+zG+hp4eGzKIXrRMcmwUBPS26ZoZ4WomMVTw8KQWxCSnYe5PtloKeNh+GF5EE/b7wWomOTAABR2f/mjTHUz42paJgHKX0tdSgriRGTmCq3PCbhLaxNqihcZ+/5h9DTVsfxOe0hEgEqykpYf+I2Fu67qjD+azcL6FRWw/bAilu0xCe+QWZWFqrqyr93VXW18OS54mt7XsclQ19BfEz26STLmtVQvZou5q85itmjO0FDXRUb9gbjVUwCYiroeMg5ThrmOU4aFvM4aSDw42Sc7PMiz76sq4VHhRwf8ubNQLfgPLxLe4+Zyw7h21b1oFW5ghYtixYtKtLGRCJRsYuWD6WkpGDr1q2wsrKCvr6+wpiwsDDcuXMH27dvlxUsOVxcXNCyZUvs2LFDrmjJkZWVhQMHDiA+Ph6qqqqy5Tt27ICtra1cwZK3XwVJS0tDWlrued6kpIq5UxN96Ro7VMdP39XDmNXnceVBFCyMdfBL/8YY06k+5u+5ki++Z0s7nL76HK/i3yrY2n+XirISls/oi4m/70I9v8lQEovRqL41PN3tUI7f36gCeJ+RCf9JGyCRAL+P71wubShS0fL0aelNlwUEBEBTUxOA9LftGhsbIyAgIF9BkuPBgwcAAHt7e4XP29vb46+//pJbNn78eEyePBlpaWnIyMiAnp4e/P395bZpays/TThy5EjZtS9VqlTBixcvoMi8efMwY8aMIvT00+hXqQwlJTFi4uSLoZi45HzVcQ5Dfe18F11FxyXDMM83aSHRr6KZnQf5fsXEJcFQv5A8xOaNT5bFV8v+NyY2GUZVc6+Cj45NrrB3CDAPUrHJ75CRmQWDPBfdGlSphOgExUXGpO5u2B38AFtO3wUA3Hkeh8rqylg02BML9l6R+0A2NdCEl3MN9Prtz1LrQ0nQ1akMJbE430W3r+OT833bzlFVTwuxiuI/mH1xsjVFwNoxSE5JRXpGJvSraOLbwYvhZGta8p0oATnHyeg8x8noYh4nYwR+nNSTfV7kOf7HF9wvQ33tfHmLURCfU7C8eBWH/cuGlcssC1AC17R8rmbNmiEsLAxhYWEICQlBmzZt4O3tjWfPnsHb2xuampqyi2I/VJxTNmPHjkVYWBgCAwPh7u6ORYsWwcrKqtB1Jk2ahLCwMEydOhUpKSkFxk2cOBGJiYmyR0RERJHbVRSqKspwsTPFudAHsmVZWVk4F/oArk7mCtdp4GSOc5cfyC0LDrmPBk4WJdq2sqSqoow6dqYIDr0vW5abB8X9cnOykIsHgKBL92R5MzPRRzV9bbmYpJRUXLkdDldn8xLvQ0lgHqTeZ2Qh7HEMPJ1ziyqRCGjqZILQ+4qnwTXUlJGVJX/cyMyUZK8rP5vavbkdYhJTcfLysxJueclSVVGGo00NXLj6ULYsKysL/1x9iLoF3Opbt7a5XDwA/HXlgcJ4LU0N6FfRxNMXMbj5IAItGzuWZPNLzKccJ10VHCfPhtwvcD8SAlUVZbjY5s/D+dCCj/8NHM1xPjTv58U9uficguVJRAz2/m8o9HQql04HiuCz/mBiSahcubJcAbF27Vro6OhgzZo1WLt2LVJTpeesVVRUAAA2NtILhu7evYu6devm297du3dlMTmqVq0KKysrWFlZYc+ePXByckKDBg1Qu7b09xJYW1vj/n35g7qBgQEMDAxgaFj476lQU1ODmppaMXtdPIO7NcOPM7eijn1N1KtthpU7z+LtuzR08/UAAAyZvhnGBlUwZaj09NbALl7wG7QEy7adQevGDth/6irC7j7HwoldZduMT3yDF1HxeBWTCAB4lH3e11BfW/bNu6IZ0r05hszYgrr2NVHPwRwrdgThTWoaerST5mHQtM0wNtCR3Z44sKsXfAcuxtKtZ9D6KwfsP3kFYXefY/HP3QBIP6gGdWuG+etPwNLUAGYm+pi78iiMqurga0+XcuvnxzAPUssPX8fy4c1x7XEMrj6MwmBfZ1RWV5FdOLtieHNExr3BzK2XAAAnQsMxxM8FN56+xuUHUbA01sHP3d1wIvSZXDEjEgE9mtth59n7yMyq+OdD+nXyxNhfdsDJxhQu9jWxYW8w3r5LR8e2bgCA0XO3w8hAG2MHSG9w6PtdE3QfuQxrd59FMw97BARew637EZgzupNsm8fOhkGviiaqG+ri/pNIzFp6AK0aO6JJBb6LZki3Zhj6wXFyVfZxsnv2cXJw9nFy6gfHyXbZx8lWjR1wIPs4uUjgx8lB3Zph2KytqGNvKs3DrrN4+y4d3b6W3to/dMYWGBnoYMoQaR5+6OKJbwb/geXbArPzcAVhdyOwYII0D+8zMtFv4jrcuP8C2xYMRGaWRHYdnK52JaiqlG0ZUe5FS14ikQhisRipqakwMTHJ93ydOnVgZ2eHRYsWoWvXrnKnka5fv47Tp09j3rx5BW7f1NQUXbp0wcSJE3Ho0CEAQLdu3dC9e3ccOnQI33xT8e7H79CqPmITUvDL6qOIjk2Go40Jdi8eIpvefxEVD7E495uim7MlVs3qi7krAzBnRQAsTQ2w+bcBsK9VXRZz4vxNDJu1TfbzgMkbAQBj/b0xfoBP2XSsmL5tXR+vE1Iwd9XR7FMXJtj7x9DcPLyKg/iDb8zuLpZYM7sv5qwIwKzlR2BpaoCt839AbavcPIzo3RJvU9Mwau4OJKakwsOlFvb+MQTqaipl3r+iYh6kDvz9GFW1NfBzV1cY6lbCzaev0XFmgOzi3BoGmsj6YEZ2/h7pKaBJ3d1grFcZsUmpOHH5GWZlFzU5vJxrwNRQC1sr8F1DH/JtXhdxiSlYvPEEXsclwb6WCTb8+gOqZp8eioyWPz7Ud7TAosk9sXD9cSxYexRmJgZYMet72FoYy2KiY5MwZ/lhxMYnw0BfGx1aN8CPvVqVed+Ko0Mr6X5R0HHypYLj5OpZfTFnZQBmZx8nt+Q5Th7Pc5z0zz5OjqvAx8kOreohNiEFv645lv3LJ2tg16LBHxwf4uVmFt2cLbFyZh/MW3UUc1YegaWpITb95i/LQ2R0Ak6cvwUAaNbrV7nXOrhsWL470UqbSFKOt8b07dsXUVFR2LBhAwAgPj4eS5cuxYoVKxAYGAgvLy+F6124cAGtWrVC69atMXHiRBgZGeHSpUsYPXo0TE1NERgYKJv9MDc3x8iRIzFy5EjZ+nfu3IGjoyNCQkLQoEEDSCQSdO7cGQEBAZg4cSLatGmDatWq4dmzZ/jll18QEhKC2NjYIvUpKSkJOjo6+DcmAdraFbMSLytK4oIvYKYvj26HFeXdhArh8Zb+5d2ECqFKpYpbEJe1rC/8CuekpCSYGOoiMTHxo5+b5X5Ny4kTJ2BsbAxjY2O4u7sjNDQUe/bsKbBgAYBGjRrh4sWLUFJSgre3N6ysrDBx4kT06dMHp06d+ujpmtq1a6N169aYOnUqAOnszq5du7B48WIcO3YMLVq0gK2tLfr16wdTU9N8F/YSERFR2fukmZbz589j1apVePz4Mfbu3QsTExNs2bIFFhYW+Oqrr0qjnYLBmZZcnGmhD3GmRYozLVKcacnFmZZSnGnZt28f2rRpAw0NDVy7dk32O0oSExMxd+7cT2sxERER0UcUu2iZPXs2Vq5ciTVr1sju6AGAxo0b4+pVxb9ZkoiIiOhzFbtouX//Ppo2bZpvuY6ODhISEkqiTURERET5FLtoMTIyUvhXj//66y9YWlqWSKOIiIiI8ip20TJgwACMGDECly5dgkgkwr///ott27ZhzJgxGDx4cGm0kYiIiKj4v1xuwoQJyMrKQosWLfD27Vs0bdoUampqGDNmDIYNG1YabSQiIiIqftEiEokwadIkjB07Fo8ePUJKSgpq164t+6OHRERERKXhk3+Nv6qqquxv9xARERGVtmIXLc2aNcv3F1E/FBgY+FkNIiIiIlKk2EVLnTp15H5+//49wsLCcOvWLfTp06ek2kVEREQkp9hFy6JFixQunz59OlJSUj67QURERESKlNgfTOzZsyfWr19fUpsjIiIiklNiRcs///wDdXX1ktocERERkZxinx769ttv5X6WSCSIjIzE5cuXMWXKlBJrGBEREdGHil206OjoyP0sFotha2uLmTNnonXr1iXWMCIiIqIPFatoyczMxPfffw8nJyfo6uqWVpuIiIiI8inWNS1KSkpo3bo1/5ozERERlbliX4jr6OiIJ0+elEZbiIiIiApU7KJl9uzZGDNmDAICAhAZGYmkpCS5BxEREVFpKPI1LTNnzsTo0aPh4+MDAPDz85P7df4SiQQikQiZmZkl30oiIiL64hW5aJkxYwYGDRqEoKCg0mwPERERkUJFLlokEgkAwNPTs9QaQ0RERFSQYl3TUthfdyYiIiIqTcX6PS02NjYfLVzi4uI+q0FEREREihSraJkxY0a+34hLREREVBZEkpyLVT5CLBbj1atXMDQ0LO02CVpSUhJ0dHQQFZsIbW3t8m5OucrKKtLQ+s8Ti3laFQCSU9+XdxMqBPN+W8u7CRXC8429yrsJFYaKUon97WJBSkpKgmk1XSQmfvxzs8iZ4vUsREREVJ6KXLQUcUKGiIiIqFQU+ZqWrKys0mwHERERUaG+7BNpREREJBgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBOXybgAVzZrdwfjf1jOIjk2Co7UJfh3bCfUdzAuMP3j6KuauPIrnkbGwNDXA9GHt0bqxg+x5iUSCeauOYvPBC0hMSYW7syUWTOiCWjUNy6A3n27tnnNYuk2aBwdrE/wyumOheTh05hrmrgpARGQcLE0NMG3oN2j1QR6OBIVh4/6/cf3ec8QnvcXZLePhZFOjDHryeTgepDbt/wurdgYiJi4Z9rWqY+aIb1GntlmB8QFBYViw7jhevIqDuYkBJg7yRfOGteViHoZHYd7KI7h0/TEyMrNgbV4Nq2Z9D5NquqXdnU/Wv5UdfmznCEMdDdx+Ho8JGy/i6uPXBcYP9K6Nfi3tYFK1MuKS03D4Ujhm7byCtPeZ+WJH+DlharcGWHn8NiZtDinNbny2jfvOY+WO3PEwa9R3qFvYeAgMw+9rj0nHQw0D/Dy4HVp8MB5GzdmGPcdD5dbxdLPDtoWDSq0PJWH93nNYvi0Q0XFJqG1lgrk/dUQ9h4LzcPjMNfy6+igiXsXBooYBpgz1Q8tGuceH39cew8FTV/EyOgGqKkpwtjXFxEG+hR5zSgtnWgRg/8krmLz4AMb7e+PslvFwtDbBd8OWISYuWWH8petP4D95I3p+0xDBWyfga08X9ByzGnce/SuLWbL5NFbtCsbCiV1xasMYVNJQxXfDluFd2vuy6laxHTh1BVOWHMDY/t4I3DQOjlYm6DRieYF5CLnxBAOmbETPdg0RtHk8fJo6o9e4Nbj7ODcPb1PT4eFiiWk/flNW3fhsHA9Sh89cw6xlBzGybxscXTsa9lbV0XPMKryOV5yHyzefYtjMLejytTuOrR2DNk0cMWDSetx/EimLCX/5Gt/9+AdqmRli15Kh+HPDWAzv3RpqqhX3+117DwvM6uWG3/eFofnPh3HrWRz2TGiNqtrqCuO/a2SJqV3r47d9YWg4+gCGr/oLHRpaYHKXevli61pWRZ8Wtrj1LK60u/HZDp+5iplLD2LU921xfN0Y1LYyQc+fVhY6HobO2Iyuvh44sX4M2jZxgv/Edbj3wXgAAC93O1w9NFP2WDa9d1l055MdPH0V0/44gNH92+LUxrFwsDZB11EFHydDbzzBoGmb0L1dQ5zeNA7eTZ3Rd/xaueOkpakh5o7uhLNbJ+DwypEwNdZDlxHLC8xtaaqQRUvfvn3Rvn37QmNSU1Mxbdo02NjYQE1NDVWrVkWnTp1w+/Ztubjp06dDJBJBJBJBSUkJpqam+OGHHxAXl38nvHbtGrp06QJjY2OoqanBzMwMvr6+OHLkCCQSSUl2sViWbw9E7/aN0MOvIewsjbFwYldUUlfF1sP/KIxftfMsWjS0x/BeLWFrYYRJg33hYmeKNXuCAUi/Va/cEYQx/drAx9MZjtYmWDGjN169TsTR4Otl2bViWb4jCL2+aYge7TxgZ2mMBRO6QENdFduOFJCHXWfRwsMew7Lz8PMgXzjbmmLtnnOymC4+bhjr7w1PV9uy6sZn43iQWrv7LLr5NkRnH3fYmBth3uhO0FBXxa6jlxTGr997Dp5udhjUrTmszathjL8PHG1qYOP+87KY39ccQzMPe0wa7AdHmxowN6mK1l85oqquVll1q9iGfO2ALYEPsD34Ee6/TMTodReQmp6BHl7WCuPdbAwR8iAa+y48QcTrFJy9+S/2XXiCerUM5OIqqylj5Y9NMWrN30h4k1YWXfksq3eeRbd2DdHla3fYWBjhl7GdoK6uip0BisfDuj3B8HK3w+DuzWFtboSxA7LHw77zcnFqqsow1NeWPapoVyqL7nyylTuC0NOvEbr5esDWwhi/j+sMDTVV7Ai4qDB+9e5gNHO3x9CeLWBjboQJA7+Gk20NrN+bm4fv2jSAp5stzE2qws7SGDNHdEDym3dyX3zKSoUsWj4mLS0NLVu2xPr16zF79mw8ePAAx44dQ0ZGBtzd3XHxovyb4+DggMjISDx//hwbNmzAiRMnMHjwYLmYQ4cOwcPDAykpKdi0aRPu3r2LEydOoEOHDpg8eTISExPLsosy6e8zEHYvAl5uuR+qYrEYnm62CL35VOE6ITefwsvVTm5Zcw97hN4MBwA8exmLqNgkeLnlxuhoaqC+gzlCb4SXeB9KQvr7DFy/FwHPvHlwtZX1K6/Qm+H5ipHmHnYF5k0IOB6k0t9n4OaDF/iqgY1smVgsxlf1rXH19jOF61y9HY6v6tvILWvqZiuLz8rKQuA/d2Bpaoieo1eirt8U+A1chD/P3yy9jnwmFSUxXCz0EXwr98NDIgGCb0XC1Vrxqb2QB9FwsdBHvVpVAQBmhppoVacGToe9kIv7rV9DnLr2AsG3IhVtpkLJGQ9N8oyHJg1scPV2uMJ1rtwKl4sHAE93O1y5JR//z7VHcPGdjKbd5mDi/N2IT3xT0s0vMenvM3DjfgSauMofH5q62uLyLcXHhyu3wtHUVT4PzdztC4xPf5+BLQcvQFtTAw7WJiXX+CKquHOehVi8eDH++ecfXLt2DS4uLgAAMzMz7Nu3D+7u7ujfvz9u3boFkUgEAFBWVoaRkREAwMTEBJ06dcKGDRtk23vz5g369++Pr7/+Gvv375d7LXt7e/Tv37/cZlpiE1KQmZkFAz35b3oGetp4GB6lcJ3o2CQY6OeN10J0bBIAICr737wxhvq5MRVNbMIbZGZmwVBPW265oZ4WHj4rJA/58qaF6Niyn9IsKRwPUnGJ0vGQdwakqp4WHj+PVrhOTFxy/rzpaiEmTtrH1/EpeJOahuXbzmCsvzcmDmqHs5fu4ofJG7BryRB41LEqnc58Bn1tNSgriRGdmCq3PDoxFdbVdRSus+/CE+hrqeHodB+IIIKKshgbTt3DokM3ZDEdGlrA2VwfLScfKdX2l5Sc8ZD3/a2qp4VHBRwfYuKS842fD8cDAHi528Pb0wWmxnp49vI1fl19FD3HrMLhlSOhpFTxvvPHJSjOg8FHj5Pa+eLzHidP/nULA6duROq796imr43dS4ZAv4pmyXagCARZtGzfvh2tWrWSFSw5xGIxRo0ahR49euD69euoU6dOvnXDw8Px559/QlVVVbbs5MmTiI2Nxbhx4wp8zZwCKK+0tDSkpeVOnSYlVcyDPBEVLiv7i0nrrxzh39kLAOBgbYIrt8Kx9dCFClm0fIrG9kYY2d4ZY9f/gyuPXsOymhbm9nHH6A4uWHDgOqrrVcbcPu74bu6fCi/M/ZJ80zL3Oh/7WtVhX6s6GneZjX+uPZKb5fsSNK5vjcBN4xGbmIKth/7BgMkbcHzt6HwFUmmreKViETx48AD29vYKn8tZ/uDBA9mymzdvQlNTExoaGrCwsMDt27cxfvx4ue0BgK1t7pRaaGgoNDU1ZY+AgACFrzdv3jzo6OjIHqampp/dvw/pV9GEkpI430VUMXFJMNTXVriOob42YmLzxifL4qtl/5s3Jjo2ucBtljf9KpWhpCRGdJx8URgdl5xv9iWHob62grwlw1C/4l6f8DEcD1J6OtLxkPdCwNdxyfm+NeYw0NPKn7f43Hg9ncpQVhLD2qyaXIyVWTW8jIovwdaXnNikNGRkZsFQR0NuuaGOBqITUhWuM7FzXew+/xhbgx7ibkQ8jl5+jtm7rmDkN84QiYA6lvow1NFA0Fw/RG3tg6itffBVbWP80KY2orb2gbiAL3DlKWc85H1/X8cVPIYN9LTyjZ8Px4MiZiZVoVelMsJfxHx+o0uBXhXFeSjsuCc9TiZ9NL6yhhosTA3QwNECiyd1h7KSErYXcD1haarQRcu2bdvkCofz53MvDCrO6RpbW1uEhYUhNDQU48ePR5s2bTBs2LBC13F2dkZYWBjCwsLw5s0bZGRkKIybOHEiEhMTZY+IiIgit6soVFWUUcfOFMGh92XLsrKycC70AVydLBSu4+ZkIRcPAEGX7sHVyRwAYGaij2r62nIxSSmpuHI7HK7O5iXa/pKiqqIMFztTnAvNLUZz82CucB1XJ3Ocu/xAbtnZkPsF5k0IOB6kVFWU4WRTA39fkR8Pf199WOCtnfUczPH3Vfnx8FfoA1m8dIzVxOMI+dNLT1/EoIaRXgn3oGS8z8zC9aexaOpoLFsmEgFNHYwR+lDxaTINVWXkPXxmZkkXiCDCuVv/ovHYA/CccEj2uPY4Bnv/fgzPCYdkM1IVSc54+OvKQ9myrKws/HXlAeoVcFtufUdz/HX5odyy86H3Ud9RcTwA/BudgPjEtzCsqvjUW3lTVVGGs60pzl+W3y/OX76PBo6Kjw/1Hc3l4gEgOORegfGy7UqykP5e8ediaarQRYufn5+scAgLC0ODBg0AADY2Nrh7967CdXKW29jkTt2pqqrCysoKjo6O+OWXX6CkpIQZM2bInre2ll5lf/9+7kFbTU0NVlZWsLIqfEpYTU0N2traco+SNqR7c2w+eAE7Ai7i/tNX+OmXXXiTmoYe7TwAAIOmbcaMpYdk8QO7euHMP3ewdOsZPAh/hV9WH0XY3ecY0MkTgPRU16BuzTB//QkcC76B249eYvD0LTCqqoOvPV0UtqEiGNKtGbYcuoAdRy/h/tNXGPPrbrx9l4buvtI8DJ6+GTOXHZbFD+wizcOybdI8/LrmGMLuPod/p6aymPjEN7j54AXuP30FAHj0LAo3H7yQXedREXE8SPl39sKOgIvYczwED8Oj8POCvXibmo7OPu4AgJFztuGXVbkzpP06NkXwpXtYvTMIj55FYeH6E7hxPwJ9v20iixnYrRkCAsOw/cg/CH8Rg437zuP0hdvo1b5xmfevqJYfvY1ezWzQtakVbKrrYH6/RqikpoztwdIP5OWDm2BK1/qy+D+vRuD7lrbo0NACNQ004eVUHRM71cOfVyOQJZEg5V0G7r1IkHu8SctAXEoa7r1IKKdeftwPXb2w48g/2ePhFSbO34PU1HR0+Vo6HkbM2op5K3Ov0enfyRNnL93Fqh3S8bBg3XHcuBeBvt9Jx8Obt2mYtewQrtwKR0RkLP66/AD9J6yFuUlVeLrZKWxDRTCoWzNsO3wBu45ewoPwVxj32268fZeOrr7SPPw4YwtmL889Tv7Q2RNBF+9ixfZAPAyPwu9rj+H6vQj065idh9Q0zFlxBJdvPUVEZByu33uOEbO34VVMIto1r1vm/avQ17RoaWlBSyv/lFbXrl0xadIkXL9+Xe66lqysLCxatAi1a9fOd73LhyZPnozmzZtj8ODBqF69Olq3bg09PT38+uuvOHDgQKn05XN827o+XiekYO6qo4iOTYaTjQn2/jFUNu354lWc3JStu4sl1szuizkrAjBr+RFYmhpg6/wfUNuquixmRO+WeJuahlFzdyAxJRUeLrWw948hUFdTKfP+FVWHVtI8/LJamgdHGxPsXjxEloeXUfEQi3Pz4OZsidWz+mLOygDMXhEAS1MDbPltAOxr5ebh+PmbGDZrm+xn/8kbAQDj/L0xfoBP2XSsmDgepPxa1EVcQgoWrj+BmOxforVl/kDZOfZ/o+Ll8tDAyQJ/TO2F+WuP4bc1R2FewwBr5vSDrWXuLEXbps6YO7oTlm09jWlLDqBWTQOsmtkXbs6WZd6/ojp48SmqaqtjQse6MKyigVvP4tD5l5OISXwHADCpWlludmTBgeuQAPi5cz0Y61VCbNI7/Hk1ArN3XS2nHpQMvxb1EJvwBvPXHs8dDwtyx0Pe40MDJwssndYbv605il9XB8CihgHWzusPu+zxIFYS4d7jf7H3eCiSUlJRrao2mrraYewAn4r9e3ta1kNsfAp+W3ss+5dw1sCORYNlp9Hz5sHV2RIrZvTBL6uPYu7KI7AwNcTGX/1lx0klsRiPnkVh97EQxCWmQFenMurY18ShFSNkuSpLIkl5/gKSAvTt2xcJCQk4ePCgwuffvXsHLy8v/Pvvv1iwYAHc3d0RFRWFuXPn4tSpUzh9+jQ8PKTfOqdPn46DBw8iLCxMbhvu7u5wdXXF0qVLAQAHDhxAly5d0KpVKwwfPhzW1tZISUnBiRMnMH78eBw+fBjt2rX7aNuTkpKgo6ODqNjEUpl1EZKsrAo3tMrFhweIL1lyasX9RXVlybzf1vJuQoXwfGOv8m5ChaFSAe9EKktJSUkwraaLxMSPf24KMlPq6uoIDAxE79698fPPP8PKygpt27aFkpISLl68KCtYCjNq1CisXbtWdg1Khw4dcOHCBVSqVAm9e/eGra0tmjdvjsDAQOzcuRO+vr6l3S0iIiIqRIWcaREyzrTk4kyLFGdapDjTIsWZFinOtOTiTMt/fKaFiIiIvjwsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQlMu7AfTfJRaLyrsJVIFUUuPhBgCerOtZ3k2oEGq0X1jeTagwYo+OLe8mlCvlYnxWcKaFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQmCcnk3gIpmze5g/G/rGUTHJsHR2gS/ju2E+g7mBcYfPH0Vc1cexfPIWFiaGmD6sPZo3dhB9rxEIsG8VUex+eAFJKakwt3ZEgsmdEGtmoZl0JtPxzxIMQ9S6/acw9Jt0jw4WJvgl9EdUa+QPBw6cw3zVgUgIjIOlqYGmDr0G7T6IA8BQWHYuP9vXL/3HPFJbxG0ZTycbGqUQU8+z+YDf2HVzkDExCXDvlZ1zBjxLerYmxUYfzQoDAvWH8eLV3GwMDHAhEG+aOZRW/a8uecohetNHNQOA7s1L/H2lxR/37oY1tENhrqVcetJNMavOI2rD14pjFVWEmNUFw90a+kAY30tPHoRh+nrg3HmytNP3mZFsVbBflHY8eHQmWuY+8F+MS3PfnEkz35xthz3C860CMD+k1cwefEBjPf3xtkt4+FobYLvhi1DTFyywvhL15/Af/JG9PymIYK3TsDXni7oOWY17jz6VxazZPNprNoVjIUTu+LUhjGopKGK74Ytw7u092XVrWJjHqSYB6kDp65gypIDGNvfG4GbxsHBygSdRiwvMA8hN57ghykb0aNdQwRtHg+fps7oPW4N7j7OzcPb1HS4u1hi6o/flFU3PtuRwGuYvewgRvRpg6NrRqN2reroPWYVXscrzsOVW08xfNYWdPFxx7E1Y9C6iSN+mLQe959EymJC9s+Qe/w2vitEIhG8PZ3LqlvF1qGpHWb/0Ay/bvsbXsM24dbTGOyb3RlVdSopjJ/cpwn6ertg/Ioz8Bi4DhuOhWHLlPZwqmX4ydusCPLuF45F2C8GTNmInh/sF70U7BceLpaYVgH2iwpVtPTt2xcikUj20NfXR9u2bXHjxo0C1wkPD4dIJEJYWFiBMRcuXICPjw90dXWhrq4OJycnLFy4EJmZmflig4KC4OPjA319fVSqVAm1a9fG6NGj8fLly5Lo4idZvj0Qvds3Qg+/hrCzNMbCiV1RSV0VWw//ozB+1c6zaNHQHsN7tYSthREmDfaFi50p1uwJBiD9Vr1yRxDG9GsDH09nOFqbYMWM3nj1OhFHg6+XZdeKhXmQYh6kVuwIQq9vGqJ7Ow/YWhpjwYQu0FBXxfYjBeRh11k097DHsF4tYWNhhImDfOFsa4q1e87JYjr7uGGsvzc8XW3Lqhufbe3us+jq2xCdfdxhbW6EOaM7QUNdFbuPXVIYv37vOXi62WFgt+awMq+G0f194GBTA5sOnJfFGOpryz1O/X0LDetaoWb1qmXVrWIb0qEBNh+/ge2nbuH+81j89L8/8TbtPXq2dlIY37m5AxbtuohToU/w7FUi1h8Nw6nQJ/jxW9dP3mZFsDx7v+jRzgN2H+wX2wrZL1pk7xe2Fkb4WcF+0aUC7RcVqmgBgLZt2yIyMhKRkZE4c+YMlJWV4evr+8nbO3DgADw9PVGjRg0EBQXh3r17GDFiBGbPno2uXbtCIpHIYletWoWWLVvCyMgI+/btw507d7By5UokJiZiwYIFJdG9Ykt/n4GwexHwcssdLGKxGJ5utgi9+VThOiE3n8LL1U5uWXMPe4TeDAcAPHsZi6jYJHi55cboaGqgvoM5Qm+El3gfSgLzIMU8SKW/z8D1exHwzJsHV1tZv/K6fDM830G3mYcdLheQNyFIf5+BWw9eoHF9G9kysViMxvWtcfX2M4XrXLsdLhcPAE1dbQuMj4lLRtA/d9DFx73kGl7CVJTFqGNthLNh4bJlEgkQHPYMrvbVFa6jpqKEd+kZcsvepWfAw6HGJ2+zvH3KfhGqYL9o7mFX4PGkvFW4a1rU1NRgZGQEADAyMsKECRPQpEkTxMTEwMDAoFjbevPmDQYMGAA/Pz+sXr1attzf3x/VqlWDn58fdu/ejS5duuDFixcYPnw4hg8fjkWLFslizc3N0bRpUyQkJJRI/4orNiEFmZlZMNDTkltuoKeNh+FRCteJjk2CgX7eeC1ExyYBAKKy/80bY6ifG1PRMA9SzINUbMKb7Dxoyy030NPCw2eF5CFP3gz1tBAdq3jaXAjiE6V5qKqb5/3V1cLj59EK14mJS1YY/zpO8Xu970QIKldSR5umFffUkL52JSgriRET/1ZueUz8G1jX0FO4TuCVpxjyrSsu3HqBp5Hx8KxjBt9GNlBSEn3yNstbzn5hmGe/MCzmfmFQgfeLCjfT8qGUlBRs3boVVlZW0NfXL/b6J0+eRGxsLMaMGZPvuXbt2sHGxgY7duwAAOzZswfp6ekYN26cwm1VqVJF4fK0tDQkJSXJPYiI/it2Hw9B+5b1oK6mUt5NKVETVp3Bk5fxCFndH9FHxuC3Ia2w/dRNZGVJPr4ylZsKV7QEBARAU1MTmpqa0NLSwuHDh7Fr1y6IxcVv6oMHDwAA9vb2Cp+3s7OTxTx8+BDa2towNjYu1mvMmzcPOjo6soepqWmx21kY/SqaUFIS57uIKiYuCYb62grXMdTXRkxs3vhkWXy17H/zxkTHJhe4zfLGPEgxD1L6VSpn50H+S0JMXHK+b5k5DPW18+UtOi4ZhnlmmIREV0eah7wX3cbEJ+ebhcphoKelML6qgviQ64/x5Hk0uvh6lFyjS0Fs0ltkZGbBQFf+AlkD3cqIjn+jeJ3EVPScdQAmHRbBuc9KuA1Yizfv3iP8VeInb7O85ewX0Xn2i+hi7hcxFXi/qHBFS7NmzRAWFoawsDCEhISgTZs28Pb2xrNnz+Dt7S0raBwcHD6+sWwfXrdSWIxIJCp2eydOnIjExETZIyIiotjbKIyqijLq2JkiOPS+bFlWVhbOhT6Aq5OFwnXcnCzk4gEg6NI9uDqZAwDMTPRRTV9bLiYpJRVXbofD1dm8RNtfUpgHKeZBSlVFGS52pjgX+kC2LDcP5grXaeBkjnOXH8gtCw65jwYF5E0IVFWU4WhTAxeuyOfhwtWHqOeg+Jbnug7mcvEA8NflBwrjdx27BCfbGqhtZVKyDS9h7zOyEPbwFTzr5PZBJAKa1jFD6N1/C1kTSHuficjYFCgridGusQ2O//Pws7dZXj5lv3BVsF+cDblf4PGkvFW4a1oqV64MKysr2c9r166Fjo4O1qxZg7Vr1yI1NRUAoKLy8alKGxvpxWZ3795Fo0aN8j1/9+5d1K5dWxabmJiIyMjIYs22qKmpQU1Nrcjxn2JI9+YYMmML6trXRD0Hc6zYEYQ3qWno0U767WfQtM0wNtCR3Y42sKsXfAcuxtKtZ9D6KwfsP3kFYXefY/HP3QAAIpEIg7o1w/z1J2BpagAzE33MXXkURlV18LWnS6n25XMwD1LMg9Tgbs3w48ytqGNfE/Vqm2HlzrN4+y4N3bJnBYZM3wxjgyqYMtQPADCwixf8Bi3Bsm1n0LqxA/afuoqwu8+xcGJX2TbjE9/gRVQ8XsVIv20/yr4OwFBfWzYjVdH4d/bC6Hnb4WRnijp2Zli3NxhvU9PRyVt64exPc7ahmoEOxv8gvaGhX8em6DJ8KdbsCkIzj9o4EngNN+9HYN6YznLbTX7zDsfOXsekIX5l3qdPsfzAZSwf7YNrD1/h6v1IDG7fAJXVVLDt1E0AwIrRPoiMTcHMjdK7YurbGsNYXxM3n0Sjur4WxvdsDLFIhCV7Q4q8zYpoSLdmGPrBfrEqe7/onr1fDM7eL6Z+sF+0y94vWjV2wIHs/WJRBd0vKlzRkpdIJIJYLEZqaipMTIpX7bdu3Rp6enpYsGBBvqLl8OHDePjwIWbNmgUA6NixIyZMmIDffvtN7kLcHAkJCQVe11Lavm1dH68TUjB31VFExybDycYEe/8YKpu6f/EqDuIPZoncXSyxZnZfzFkRgFnLj8DS1ABb5/+A2la5V7yP6N0Sb1PTMGruDiSmpMLDpRb2/jGkQp+3Zh6kmAepDq3qIzYhBb+slubB0cYEuxcPyc1DVDzE4tw8uDlbYtWsvpi7MgBzVgTA0tQAm38bAPtauXk4cf4mhs3aJvt5wOSNAICx/t4YP8CnbDpWTO2a10VcQgoWrT+BmLgk2FuZYNPvA2UXV76MjofogzzUd7TAkim9sGDdMfy+5ijMaxhg9Zx+sLWU/7J25MxVSCQS+LWoV6b9+VQHzt1DVR0N/NzzKxjqVcbNx9HoOGUPYhKkF9LWMNRG1gez7mqqypjUpwnMjargTWo6ToU+waDfjyLpTVqRt1kRdWglPT4UtF+8VLBfrJ7VF3NWBmB29n6xJc9+cTzPfuGfvV+MK4f9QiQpyrmTMtK3b19ERUVhw4YNAID4+HgsXboUK1asQGBgILy8vPKtEx4eDgsLC+zcuRO2tvK3bTk4OODQoUPo2rUr+vXrhx9//BHa2to4c+YMxo4dixYtWmD37t2y00LLly/Hjz/+iO+//x69e/eGubk5Xrx4gc2bN0NTU7NItz0nJSVBR0cHUbGJ0NaumN/MiMpDJi9wBACkvMv4eNAXwPy7/F8Ov1SxR8eWdxPKVVJSEowNqiAx8eOfmxVupuXEiROy0zNaWlqws7PDnj17FBYsH+ratWu+ZREREejYsSOCgoIwZ84cNGnSBO/evYO1tTUmTZqEkSNHyl3HMmTIENjY2GD+/Pno0KEDUlNTYW5uDl9fX/z0008l2k8iIiIqngo10/JfwJkWIsU40yLFmRYpzrTk4kxL0WdaKtzdQ0RERESKsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQWDRQkRERILAooWIiIgEgUULERERCQKLFiIiIhIEFi1EREQkCCxaiIiISBBYtBAREZEgsGghIiIiQVAu7wYQ0ZdBSSwq7yZUCFrqPOwCQPzxceXdhApD1/XH8m5CuZJkphc5ljMtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQQERGRILBoISIiIkFg0UJERESCwKKFiIiIBIFFCxEREQkCixYiIiISBBYtREREJAgsWoiIiEgQWLQIxJrdwXD2mwqjxiPRsu/vuHI7vND4g6evwq3jLBg1HolGXefg5N+35Z6XSCSYuzIAdm1/hvFXo9B+yP/w+Hl0KfagZDAPUsyDFPMgtXbPOdRpPw3Vm4xCq37zP5qHQ2euwb3zLFRvMgpfdZ+LU3nycCQoDN8NWwarVuOh7z4MNx+8KMXWlxyOByn/Tk1x/dAMRP61CKc2jEG92mYFxioriTHWvy2uHpiGyL8W4fy2CWjR0F4uRiwW4edBXyPs4HT8e34hrh6YhjH925Z2NxRi0SIA+09eweTFBzDe3xtnt4yHo7UJvhu2DDFxyQrjL11/Av/JG9Hzm4YI3joBX3u6oOeY1bjz6F9ZzJLNp7FqVzAWTuyKUxvGoJKGKr4btgzv0t6XVbeKjXmQYh6kmAepA6euYMqSAxjb3xuBm8bB0coEnUYsLzAPITeeYMCUjejZriGCNo+HT1Nn9Bq3Bncf5+bhbWo6PFwsMe3Hb8qqG5+N40GqQ6t6mD2yA35dexxevX7FrYcvse9/Q1FVV1Nh/OTB7dC3w1cY//seeHSZjQ37/8KW3wbAyaaGLGZk71bo910TjPt9D9w7z8b0/x3C8F4t8UMXz7LqlkyFL1r69u2L9u3bF/i8l5cXRo4cWeDzcXFxGDlyJMzMzKCqqorq1aujX79+eP78eb7YV69eYdiwYbC0tISamhpMTU3Rrl07nDlzpgR68umWbw9E7/aN0MOvIewsjbFwYldUUlfF1sP/KIxftfMsWjS0x/BeLWFrYYRJg33hYmeKNXuCAUi/PazcEYQx/drAx9MZjtYmWDGjN169TsTR4Otl2bViYR6kmAcp5kFq+Y4g9PqmIXq084CdpTEWTOgCDXVVbDtSQB52nUULD3sMy87Dz4N84WxrirV7zsliuvi4Yay/NzxdbcuqG5+N40FqSPfm2HzwArYfuYj7T1/hp3k78fZdOnr6NVQY39nHDYs2nsSpC3fw7GUs1u/7C6cu3MGPPZvLYtycLXEs+AZO/n0bEZFxOBwYhqBL91DfoeAZnNJS4YuWzxEXFwcPDw+cPn0aK1euxKNHj7Bz5048evQIrq6uePLkiSw2PDwc9evXR2BgIH7//XfcvHkTJ06cQLNmzTB06NBy60P6+wyE3YuAl1vuwUMsFsPTzRahN58qXCfk5lN4udrJLWvuYY/Qm+EAgGcvYxEVmwQvt9wYHU0N1HcwR+iN8BLvQ0lgHqSYBynmQSr9fQau34uAZ948uNrK+pVX6M3wfMVIcw+7AvMmBBwPUirKSqhjZ4qzIfdlyyQSCYJD7sPVyULhOmoqyvlmjt6lpcPDpZbs55AbT+DpaotaNQ0BAI7WJvBwscTpC3dKoReFUy7zVyxDkyZNwr///otHjx7ByMgIAFCzZk38+eefsLa2xtChQ3H8+HEAwJAhQyASiRASEoLKlSvLtuHg4IB+/fqVS/sBIDYhBZmZWTDQ05JbbqCnjYfhUQrXiY5NgoF+3ngtRMcmAQCisv/NG2OonxtT0TAPUsyDFPMgFZvwBpmZWTDU05ZbbqinhYfPCslDvrxpITpW8WkUIeB4kNKvogllZaV8p8Ri4pJgbV5N4TqBF+9iSI/muHDtEZ6+eA1PV1v4NqsDJbFIFrNo0yloaaojZM9kZGZJoCQWYfaKAOw5cblU+6PIf7ZoycrKws6dO9GjRw9ZwZJDQ0MDQ4YMweTJkxEXFwcAOHHiBObMmSNXsOSoUqVKga+TlpaGtLQ02c9JSRVzMBMREeU1YcFeLJnUDSF7pkAikeDpy9fYfuQierTzkMV0aFkPndq6YsDkTbj3JBJONiaY+1NHRMYkYufRS2Xa3v/s6aGYmBgkJCTA3t5e4fP29vaQSCR49OgRHj16BIlEAjs7O4WxhZk3bx50dHRkD1NT089tuhz9KppQUhIrrJwN9bUVrmOor42Y2LzxybL4atn/5o2Jjk0ucJvljXmQYh6kmAcp/SqVoaQkRnSc/Jel6LjkfLMvOQz1tRXkLRmGeWYUhITjQSo2IQUZGZkKZ5wKmh2KTUhBz7FrYNL0Jzj7TYVbx1l48zYN4f/GymJmjmiPxZtOYf+pK7jz+F/sOh6K5TsCMapvq1LtjyKCKVq2bdsGTU1N2eP8+fNFWk8ikZRITEEmTpyIxMRE2SMiIuKTt6WIqooy6tiZIjg09xxlVlYWzoU+KPAcpZuThVw8AARdugdXJ3MAgJmJPqrpa8vFJKWk4srtcLg6m5do+0sK8yDFPEgxD1KqKspwsTPFudAHsmW5eTBXuI6rkznOXX4gt+xsIdc8CAHHg9T7jEyE3YuQu2ZJJBKhqavNR69ZSkvPQGRMIpSVxGjXvA6OB9+QPaehpoqsrCy5+KwsCcSisi8hBHN6yM/PD+7u7rKfTUxMCo03MDBAlSpVcPfuXYXP3717FyKRCFZWVgCkb+y9e/eK3S41NTWoqakVe73iGPL/9u49qqkr3wP4NyAJAQICIi9TFJGXRbQ+kPauQWaJAStaleKDdmBUKkIV8UVb3+JrrJbRGRGuINiKQq31hQpFa9XRau1olEpEEBGsobUF0SiCkH3/yM2pMbxFIPb3WStrmbP32Wf/tpuTHzvncKb+FZErv8Agt9fwRv/e2LbnJB5V13DLdxHLP4etlRl3e+LMySMwZuY/8e9dJzDqf/rj62/+C6msFP/8ZAoAVawRU3yxcUc2HMVWcLC3xNrEI7DpYYa3fTxfaiwvgsZBhcZBhcZBJXKKL6JW7cJAt9fwhrsDkjK+w+MnNZg6RjUOs1Z8Dlur7lgWNRYAMHPSCARGbMbW9BPwe6s/9udeglRWiviPJ3NtVlY9wp1fKlF+rwoAUPT/18f0tDTlViC6GpoPKgm7v0XC8vdxWVaKS9dKMGuKL4yFAqQfPg8A2LbifcjvVWHV1kMAgMH9HWDbszvybtyBnVV3xH4wGnp6PGz+/DjXZvZ/8jDv7xLcKa+ErFiOAS69EDnVF+mHznd4fDqTtIhEIohELV++1NPTQ3BwMNLT07Fq1SqN61qqq6uRkJAAiUQCCwsLAIBEIsHWrVsxZ84creta7t+/3+R1LS/bhFGD8dt9BdYmHcGvvz+Eh7M9vtoSxS1R3imvgB7vj4umvDwdsX11GNZsy0JcwmE4iq2wa+MHcHey4+pE/20kHlfXIGbtHlQpqjHcsy++2hIJQ4FBh8fXUjQOKjQOKjQOKuP9VOOw/n9V4/C6sz2+/GckNw4//1IJvWcuqhw2wBH/GxeGNYlZWL0tC45iK3yxIRxuff8Yh2Nn8jA7Lp17P2NJGgBg0YwAxIaP7pjAWonmg8r+3Evo0d0En8x8Gz0tRci78TOC5vzx92p62VhA+cy3CwKBARZHjEFv+x54VF2D3LPXELHsczxQVHN1Yj/di08ixmBj7CT0MDdB+W9VSPv6LDYkH+vw+HjsRb4b6QBhYWG4f/8+Dhw40GD5iBEjYG9vj4ULF2pst7W1Rbdu3eDl5QWhUIgNGzbg9ddfx61bt7BkyRIUFBTg+++/h6OjIwCguLgYb731FiwsLLBq1SoMGDAAdXV1yM3NxbZt2xpdsXnegwcPYGZmhl9+r4Kpadf8jYQQ0nmUyi59yu0wzyZSf3bmQz/s7C50KlZfi5q87aiqav5zU2euaWnK7t27MWjQII3X9u3bYWlpifPnz8PX1xczZ85E3759ERwcjL59++LixYtcwgIAjo6OuHTpEnx9fTF//ny8/vrr8PPzw4kTJ7Bt27ZOjI4QQgghgA6stOgaWmkhhDSFVlpUaKXlD7TS8idbaSGEEELIq4+SFkIIIYToBEpaCCGEEKITKGkhhBBCiE6gpIUQQgghOoGSFkIIIYToBEpaCCGEEKITKGkhhBBCiE6gpIUQQgghOoGSFkIIIYToBEpaCCGEEKITKGkhhBBCiE6gpIUQQgghOoGSFkIIIYToBEpaCCGEEKITKGkhhBBCiE6gpIUQQgghOoGSFkIIIYToBEpaCCGEEKITKGkhhBBCiE6gpIUQQgghOoGSFkIIIYToBEpaCCGEEKITKGkhhBBCiE6gpIUQQgghOqFbZ3fgVcMYAwA8fPCgk3tCCOmKlErW2V3oEvT0eJ3dhS6D1dd2dhc6lTp+9ednUyhpaWcPHz4EADj1EXdyTwghhBDd8fDhQ5iZmTVZh8daktqQFlMqlbh79y5EIhF4vM75TeLBgwcQi8UoKyuDqalpp/ShK6BxUKFxUKFxUKFxUKFxUOkK48AYw8OHD2FnZwc9vaavWqGVlnamp6eHXr16dXY3AACmpqZ/6h9GNRoHFRoHFRoHFRoHFRoHlc4eh+ZWWNToQlxCCCGE6ARKWgghhBCiEyhpeQUJBAIsX74cAoGgs7vSqWgcVGgcVGgcVGgcVGgcVHRtHOhCXEIIIYToBFppIYQQQohOoKSFEEIIITqBkhZCCCGE6ARKWgghhBCiEyhpecWUlZVh2rRpsLOzA5/Ph4ODA6Kjo/H77793dtdaLCwsDDwej3tZWlrC398fV69ebXSfkpISrX1GjRqFy5cvc3VGjBihUUf9ioiI4Oo8u93U1BRDhw7FwYMHX2q8LREWFoZ33nmn0fJnYzM0NIS7uzsSEhK48rS0tAZjNzQ01DiGeruBgQH69OmDRYsW4cmTJy8ztEa1ZR6oXbt2DcHBwbCysoJAIICzszOWLVuGx48fa9Tr3bs3176RkRE8PDyQnJys1R5jDNu3b4e3tzdMTU1hYmKC/v37Izo6GkVFRe0Wc3OamwcAUF1djeXLl8PZ2RkCgQA9evTAu+++i2vXrmnUW7FiBRe7vr4+xGIxPvjgA1RUVGi1efnyZUyaNAm2trYQCARwcHDAmDFjcPjw4RY9L6Y9vcj5QSqVNlrn3LlzGD16NMzNzWFoaAgPDw989tlnqK+v16p78uRJjB49GpaWljAyMoK7uzvmz5+Pn3/+uT1CbJWWnBvmzp3baHlFRQXmzp0LBwcH8Pl82NnZYdq0aSgtLdWqW15ejtmzZ8PR0RECgQBisRiBgYE4ceJEO0TSMpS0vEKKi4sxZMgQFBYWYs+ePSgqKkJiYiJOnDgBb2/vBk9GXZW/vz/kcjnkcjlOnDiBbt26YcyYMc3ud/z4ccjlcuTk5EChUCAgIAD379/nysPDw7l21a8NGzZotJGamgq5XI4ff/wRb731FoKCgpCXl9feIbY7dWz5+fkIDg5GVFQU9uzZw5WbmppqxX779m2NNtTjXlxcjPj4eCQlJWH58uUdHYpWf1ozD86fPw8vLy/U1tbiyJEjuHHjBtasWYO0tDT4+fmhtlbz4XSrVq2CXC7HTz/9hPfeew/h4eE4duwYV84Yw9SpUzFnzhyMHj0a33zzDfLz85GSkgJDQ0OsXr36pcTeFjU1NRg5ciR27NiB1atX48aNGzh69Cjq6urg5eWF8+fPa9Tv378/5HI5SktLkZqaiuzsbMyaNUujzsGDBzF8+HAoFArs3LkTMpkM2dnZGD9+PJYsWYKqqqqODBFA288Pjdm/fz98fHzQq1cvnDx5EtevX0d0dDRWr16NyZMnayRmSUlJGDlyJGxsbLBv3z7k5+cjMTERVVVV2LRpU3uE12EqKiowfPhwHD9+HImJiSgqKkJGRgaKioowdOhQFBcXc3VLSkowePBgfPvtt/j000+Rl5eH7Oxs+Pr6IioqquM6zcgrw9/fn/Xq1Ys9fvxYY7tcLmdGRkYsIiKik3rWOqGhoWzcuHEa286cOcMAsF9//bXBfW7dusUAsMuXL3Pbzp49ywCw7OxsxhhjPj4+LDo6usljA2D79+/n3j948IABYJs3b25LKO2moTF5VkOx9evXj02ePJkxxlhqaiozMzNr9TEmTJjABg0a1IYev7i2zAOlUsnc3d3ZkCFDWH19vUaZVCplPB6PrV+/ntvm4ODA4uPjNepZWFiwmJgY7v2ePXsYAHbw4MFGj9lRmpsH69evZzwej0mlUo3t9fX1bMiQIczd3Z3r7/Lly5mnp6dGvXnz5jFzc3PuvUKhYJaWlmz8+PGNHrMj42es/c4PauoYJ0yYoFV26NAhBoBlZGQwxhgrKytjfD6fzZ07t8HjVFZWtiqW9tCWc4NaREQEMzY2ZnK5XGP748ePmb29PfP39+e2BQQEMHt7e6ZQKLTa6ci4aaXlFVFRUYGcnBxERkZCKBRqlNnY2CAkJASZmZkdvpTbHhQKBXbt2gUnJydYWlq2eD/1ODz/m3VL1dXVISUlBQDA5/Pb1EZnEgqFbY4dAH766SecO3euy8TeknkglUqRn5+PefPmaT14zdPTEyNHjtRYfXqWUqnEvn37UFlZqRHznj174OLigrFjxza4X2c9GLUhu3fvhp+fHzw9PTW26+npISYmBvn5+bhy5UqD+5aUlCAnJ0cj9m+++Qa///47Fi1a1OgxOzv+tp4f1NQxLliwQKssMDAQzs7O3JzZu3cvamtrGx2P7t27t/r4nUWpVCIjIwMhISGwsbHRKBMKhYiMjEROTg4qKipQUVGB7OxsREVFwdjYWKutjoybkpZXRGFhIRhjcHNza7Dczc0NlZWVuHfvXgf3rG2ysrJgYmICExMTiEQiHDp0CJmZmc0+AVTt/v37iIuLg4mJCYYNG8ZtT0hI4NpVv9LT0zX2nTJlCkxMTCAQCBATE4PevXsjODi4XeN7merr67Fr1y5cvXoVf/3rX7ntVVVVWrEHBARo7Ksed/V3+r/++isWLlzY0SFo9ael8+DGjRsA0OTPgbqOWmxsLPf/HRQUBHNzc8yYMUOjTRcXF4195s6dy/WrqzwgFVD1tanY1XXU8vLyYGJiAqFQiD59+uDatWuIjY3VaA+ARvwXL17UmENZWVkvI5Qmvej54VnNzRlXV1euTmFhIUxNTWFra9v2zncR9+7dw/3795ucL4wxFBUVoaioCIwxuLq6dnAvtVHS8orRxZWUhvj6+kIqlUIqleKHH36ARCJBQEAAbt++jYCAAO6E1b9/f4393nzzTZiYmMDc3BxXrlxBZmYmrK2tufKQkBCuXfXr+d+g4+PjIZVKcezYMbi7uyM5ORkWFhYdEndz0tPTNT4wzpw5w5WpEzKhUIjw8HDExMRoXJ8gEom0Yn/+olP1uF+4cAGhoaH4+9//jokTJ3ZYfM9r6zxozc/BwoULIZVK8e2338LLywvx8fFwcnJqcp/FixdDKpVi2bJlUCgUbYrtRTQ1D1oTu4uLC6RSKS5evIjY2FhIJBLMnj27yX0GDBjA/Z88evQIdXV1bY6jrdo6L5rSknFjjHX6ylJjmpoTTWlp3F1Ft87uAGkfTk5O4PF4kMlkGD9+vFa5TCaDubk5rKysOqF3rWdsbKzxwZGcnAwzMzNs374dycnJqK6uBgAYGBho7JeZmQl3d3dYWlo2uGRpZmbW7AeSjY0NnJyc4OTkhNTUVIwePRr5+fno2bPniwf2gsaOHQsvLy/uvb29PffvkJAQLF68GEKhELa2tlq/derp6TUb+7PjvmPHDnh6eiIlJQXTp09vxyharrXzwNnZGYBqvg8aNEirPZlMxtVR69GjB/f/vXfvXnh4eGDIkCFwd3cHAPTr1w8FBQUa+1hZWcHKyqrT5kRj88DZ2RkymazBfdTbn42fz+dz47t+/Xq8/fbbWLlyJeLi4gCoYgeAgoICDB8+HIDqWTXNzaOXra3nh4Y8O2fefPNNrXKZTMbNBWdnZ1RVVUEul3e51Zamzg0NsbKyQvfu3ZucLzwejxtnHo+H69evt1+H24hWWl4RlpaW8PPzQ0JCAvcDq1ZeXo709HRMmjSpy/6W0Bwejwc9PT1UV1fD3t6e+5BxcHDQqCcWi9G3b992+4512LBhGDx4MNasWdMu7b0okUjExe7k5KRx/ZI6IbO3t2/TMvnz9PT08Mknn2DJkiVac6qzNDcPBg4cCFdXV8THx0OpVGrse+XKFRw/fhxTpkxptH2xWIxJkybh448/5rZNmTIFBQUFXeLWd7XG5sHkyZNx/PhxretWlEol4uPj4e7urnW9y7OWLFmCjRs34u7duwCAUaNGwcLCAv/4xz9eXjDtoKXnh4aoY2zozp9Dhw6hsLCQmzNBQUHg8/ladxyqPXunYkdr6tzQED09PQQHB2P37t0oLy/XKKuurkZCQgIkEgksLCxgYWEBiUSCrVu34tGjR1ptdWTclLS8Qv7973+jpqYGEokEp0+fRllZGbKzs+Hn5wd7e/su88HbEjU1NSgvL0d5eTlkMhlmz54NhUKBwMDAF2r38ePHXLvqV2VlZZP7zJ07F0lJSZ3yNxjaE2NMK/by8nKtD/dnvfvuu9DX18fWrVs7sKd/aO084PF4SElJQX5+PiZOnIgffvgBpaWl2Lt3LwIDA+Ht7d3k36wAgOjoaBw+fBg//vgjAFUiEBQUhMmTJ2PVqlW4cOECSkpKcOrUKWRmZkJfX7+9w26zmJgYDBs2DIGBgdi7dy9KS0tx8eJFTJw4ETKZDCkpKU3+4uLt7Y0BAwZg7dq1AAATExMkJyfjyJEjePvtt5GTk4Pi4mJcvXqV++DujPjben4oKCjQ+oqUz+cjKSkJBw8exAcffICrV6+ipKQEKSkpCAsLQ1BQEHdNm1gsRnx8PDZv3ozp06fj1KlTuH37Ns6ePYuZM2dyK1Rdzb1797Ti/uWXX7B27VrY2NjAz88Px44dQ1lZGU6fPg2JRIKnT59q/Nxv3boV9fX1GDZsGPbt24fCwkLIZDJs2bIF3t7eHRdMh92nRDpESUkJCw0NZdbW1szAwICJxWI2e/Zs9ttvv3V211osNDSUAeBeIpGIDR06lH311VeN7tPULY1qPj4+Gu2qXxKJhKuD5255Zkx1S6erqyubNWvWi4bWZi9yWyNjqlueG4odAHe7Y2PHWLduHbOysmrwVseXqS3zQO3q1ats4sSJzMLCghkYGLC+ffuyJUuWsEePHmnUa+iWZ8YYk0gkLCAggHtfX1/PEhMTmZeXFzM2NmZ8Pp85Ojqy8PBwlp+f/8KxtlRz84Axxh49esQWL17MnJycmIGBAbOwsGATJ05keXl5GvUauuWZMdUt3gKBgJWWlnLbLl68yIKCgljPnj1Zt27dmKWlJZNIJCwjI6NTbnlu6/mhoVdZWRljjLHTp08ziUTCTE1NGZ/PZ/3792cbN25kdXV1Wu3l5uYyiUTCzM3NmaGhIXN1dWULFixgd+/efWlxN6Yl54aG4o6Li2OMMXbv3j02e/ZsJhaLmYGBAbO2tmZhYWHs9u3bWm3dvXuXRUVFMQcHB8bn85m9vT0bO3YsO3ny5EuKThuPsS50hQ0hhBBCSCPo6yFCCCGE6ARKWgghhBCiEyhpIYQQQohOoKSFEEIIITqBkhZCCCGE6ARKWgghhBCiEyhpIYQQQohOoKSFEEIIITqBkhZCSJcSFhaGd955h3s/YsSIZv/0/svw3XffgcfjNflcFR6PhwMHDrS4zRUrVmDgwIEv1K+SkhLweDxIpdIXaocQXURJCyGkWWFhYeDxeODxeNyTgVetWoW6urqXfuyvv/66xc90aUmiQQjRXd06uwOEEN3g7++P1NRU1NTU4OjRo4iKioKBgYHGE5HVamtrwefz2+W4FhYW7dIOIUT30UoLIaRFBAIBbGxs4ODggFmzZmHkyJE4dOgQgD++0lmzZg3s7Ozg4uICACgrK0NwcDC6d+8OCwsLjBs3DiUlJVyb9fX1mDdvHrp37w5LS0ssWrQIzz8O7fmvh2pqahAbGwuxWAyBQAAnJyekpKSgpKQEvr6+AABzc3PweDyEhYUBAJRKJdatW4c+ffpAKBTC09MTX331lcZxjh49CmdnZwiFQvj6+mr0s6ViY2Ph7OwMIyMjODo6YunSpXj69KlWvaSkJIjFYhgZGSE4OBhVVVUa5cnJyXBzc4OhoSFcXV2RkJDQ6r4Q8iqipIUQ0iZCoRC1tbXc+xMnTqCgoAC5ubnIysrC06dPIZFIIBKJcObMGZw9exYmJibw9/fn9tu0aRPS0tKwY8cO/Oc//0FFRQX279/f5HH/9re/Yc+ePdiyZQtkMhmSkpJgYmICsViMffv2AQAKCgogl8uxefNmAMC6devw+eefIzExEdeuXUNMTAzee+89nDp1CoAquZowYQICAwMhlUoxY8YMfPTRR60eE5FIhLS0NOTn52Pz5s3Yvn074uPjNeoUFRXhyy+/xOHDh5GdnY3Lly8jMjKSK09PT8eyZcuwZs0ayGQyrF27FkuXLsXOnTtb3R9CXjkd9jxpQojOCg0NZePGjWOMMaZUKllubi4TCARswYIFXLm1tTWrqanh9vniiy+Yi4sLUyqV3LaamhomFApZTk4OY4wxW1tbtmHDBq786dOnrFevXtyxGGPMx8eHRUdHM8YYKygoYABYbm5ug/08efIkA8AqKyu5bU+ePGFGRkbs3LlzGnWnT5/OpkyZwhhj7OOPP2bu7u4a5bGxsVptPQ8A279/f6Pln376KRs8eDD3fvny5UxfX5/duXOH23bs2DGmp6fH5HI5Y4yxvn37st27d2u0ExcXx7y9vRljjN26dYsBYJcvX270uIS8quiaFkJIi2RlZcHExARPnz6FUqnE1KlTsWLFCq7cw8ND4zqWK1euoKioCCKRSKOdJ0+e4ObNm6iqqoJcLoeXlxdX1q1bNwwZMkTrKyI1qVQKfX19+Pj4tLjfRUVFePz4Mfz8/DS219bWYtCgQQAAmUym0Q8A8Pb2bvEx1DIzM7FlyxbcvHkTCoUCdXV1MDU11ajz2muvwd7eXuM4SqUSBQUFEIlEuHnzJqZPn47w8HCuTl1dHczMzFrdH0JeNZS0EEJaxNfXF9u2bQOfz4ednR26ddM8fRgbG2u8VygUGDx4MNLT07XasrKyalMfhEJhq/dRKBQAgCNHjmgkC4DqOp328v333yMkJAQrV66ERCKBmZkZMjIysGnTplb3dfv27VpJlL6+frv1lRBdRUkLIaRFjI2N4eTk1OL6b7zxBjIzM9GzZ0+t1QY1W1tbXLhwAX/5y18AqFYU/vvf/+KNN95osL6HhweUSiVOnTqFkSNHapWrV3rq6+u5be7u7hAIBCgtLW10hcbNzY27qFjt/PnzzQf5jHPnzsHBwQGLFy/mtt2+fVurXmlpKe7evQs7OzvuOHp6enBxcYG1tTXs7OxQXFyMkJCQVh2fkD8DuhCXEPJShISEoEePHhg3bhzOnDmDW7du4bvvvsOcOXNw584dAEB0dDTWr1+PAwcO4Pr164iMjGzyb6z07t0boaGhmDZtGg4cOMC1+eWXXwIAHBwcwOPxkJWVhXv37kGhUEAkEmHBggWIiYnBzp07cfPmTVy6dAn/+te/uItbIyIiUFhYiIULF6KgoAC7d+9GWlpaq+Lt168fSktLkZGRgZs3b2LLli0NXlRsaGiI0NBQXLlyBWfOnMGcOXMQHBwMGxsbAMDKlSuxbt06bNmyBTdu3EBeXh5SU1Px2Weftao/hLyKKGkhhLwURkZGOH36NF577TVMmDABbm5umD59Op48ecKtvMyfPx/vv/8+QkND4e3tDZFIhPHjxzfZ7rZt2xAUFITIyEi4uroiPDwcjx49AgDY29tj5cqV+Oijj2BtbY0PP/wQABAXF4elS5di3bp1cHNzg7+/P44cOYI+ffoAUF1nsm/fPhw4cACenp5ITEzE2rVrWxXv2LFjERMTgw8//BADBw7EuXPnsHTpUq16Tk5OmDBhAkaPHo1Ro0ZhwIABGrc0z5gxA8nJyUhNTYWHhwd8fHyQlpbG9ZWQPzMea+yKN0IIIYSQLoRWWgghhBCiEyhpIYQQQohOoKSFEEIIITqBkhZCCCGE6ARKWgghhBCiEyhpIYQQQohOoKSFEEIIITqBkhZCCCGE6ARKWgghhBCiEyhpIYQQQohOoKSFEEIIITrh/wCSJnBon508jQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    _, ax = plt.subplots(figsize=(6,6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Matriz de confus√£o normalizada\")\n",
    "    plt.show()\n",
    "plot_confusion_matrix(df_tokens[\"labels\"], df_tokens[\"predicted_label\"], tags.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora analisamos a n√≠vel de token, vamos avaliar alguns exemplos (sequ√™ncias). Para isso, voltamos para nosso dataset n√£o explodido e somamos as losses de cada token na sequ√™ncia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(df):\n",
    "    for _, row in df.iterrows():\n",
    "        labels, preds, tokens, losses = [], [], [], []\n",
    "        for i, _ in enumerate(row[\"attention_mask\"]):\n",
    "            if i not in {0, len(row[\"attention_mask\"])}:\n",
    "                labels.append(row[\"labels\"][i])\n",
    "                preds.append(row[\"predicted_label\"][i])\n",
    "                tokens.append(row[\"input_tokens\"][i])\n",
    "                losses.append(f\"{row['loss'][i]:.2f}\")\n",
    "        df_tmp = pd.DataFrame({\"tokens\": tokens, \"labels\": labels, \"preds\": preds, \"losses\": losses}).T\n",
    "        yield df_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo podemos ver os 2 registros com maior loss total. Algumas coisas interessantes nesses registros:\n",
    "- Temos um token `_alt` classificado `B-ORG`, mas √© uma classifica√ß√£o errada, assim como `Justin Timberlake` n√£o √© n√£o √© uma organiza√ß√£o, nosso modelo na verdade est√° correto. Isso pode acontecer, visto que os dados do PAN-X foram gerados em um process autom√°tico. Essas classifica√ß√µes s√£o consideradas \"padr√£o prata\", contrastando com as classifica√ß√µes \"padr√£o ouro\" feitas por humanos. Mesmo com classifica√ß√µes \"padr√£o ouro\", ainde podemos ter erros nos labels dos nossos dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>‚ñÅalt</td>\n",
       "      <td>=</td>\n",
       "      <td>High</td>\n",
       "      <td>‚ñÅschool</td>\n",
       "      <td>‚ñÅbuilding</td>\n",
       "      <td>‚ñÅwith</td>\n",
       "      <td>‚ñÅa</td>\n",
       "      <td>‚ñÅtwo</td>\n",
       "      <td>-</td>\n",
       "      <td>story</td>\n",
       "      <td>...</td>\n",
       "      <td>ground</td>\n",
       "      <td>‚ñÅand</td>\n",
       "      <td>‚ñÅa</td>\n",
       "      <td>‚ñÅround</td>\n",
       "      <td>‚ñÅauditori</td>\n",
       "      <td>um</td>\n",
       "      <td>‚ñÅin</td>\n",
       "      <td>‚ñÅthe</td>\n",
       "      <td>‚ñÅbackground</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>...</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>4.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.82</td>\n",
       "      <td>8.49</td>\n",
       "      <td>8.72</td>\n",
       "      <td>6.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.20</td>\n",
       "      <td>9.22</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.42</td>\n",
       "      <td>8.47</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1      2        3          4      5      6      7     8   \\\n",
       "tokens   ‚ñÅalt     =   High  ‚ñÅschool  ‚ñÅbuilding  ‚ñÅwith     ‚ñÅa   ‚ñÅtwo     -   \n",
       "labels  B-ORG   IGN    IGN    I-ORG      I-ORG  I-ORG  I-ORG  I-ORG   IGN   \n",
       "preds       O     O  B-ORG    I-ORG      I-LOC      O      O      O     O   \n",
       "losses   4.27  0.00   0.00     0.60       0.82   8.49   8.72   6.42  0.00   \n",
       "\n",
       "           9   ...      20     21     22      23         24    25     26  \\\n",
       "tokens  story  ...  ground   ‚ñÅand     ‚ñÅa  ‚ñÅround  ‚ñÅauditori    um    ‚ñÅin   \n",
       "labels    IGN  ...     IGN  I-ORG  I-ORG   I-ORG      I-ORG   IGN  I-ORG   \n",
       "preds   I-LOC  ...       O      O      O       O          O     O      O   \n",
       "losses   0.00  ...    0.00   9.20   9.22    6.12       3.95  0.00   8.42   \n",
       "\n",
       "           27           28    29  \n",
       "tokens   ‚ñÅthe  ‚ñÅbackground  </s>  \n",
       "labels  I-ORG        I-ORG   IGN  \n",
       "preds       O            O     O  \n",
       "losses   8.47         8.37  0.00  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>‚ñÅ'</td>\n",
       "      <td>‚ñÅ''</td>\n",
       "      <td>‚ñÅJustin</td>\n",
       "      <td>‚ñÅTim</td>\n",
       "      <td>ber</td>\n",
       "      <td>la</td>\n",
       "      <td>ke</td>\n",
       "      <td>‚ñÅ-</td>\n",
       "      <td>‚ñÅMirror</td>\n",
       "      <td>s</td>\n",
       "      <td>...</td>\n",
       "      <td>‚ñÅ40</td>\n",
       "      <td>‚ñÅ1</td>\n",
       "      <td>‚ñÅ</td>\n",
       "      <td>,</td>\n",
       "      <td>‚ñÅFebruary</td>\n",
       "      <td>‚ñÅ11</td>\n",
       "      <td>‚ñÅ)</td>\n",
       "      <td>‚ñÅ''</td>\n",
       "      <td>‚ñÅ'</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>...</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>...</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.02</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.44</td>\n",
       "      <td>7.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.97</td>\n",
       "      <td>8.72</td>\n",
       "      <td>10.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.25</td>\n",
       "      <td>9.64</td>\n",
       "      <td>10.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1        2      3      4      5      6      7        8   \\\n",
       "tokens    ‚ñÅ'   ‚ñÅ''  ‚ñÅJustin   ‚ñÅTim    ber     la     ke     ‚ñÅ-  ‚ñÅMirror   \n",
       "labels     O     O    B-ORG  I-ORG    IGN    IGN    IGN  I-ORG    I-ORG   \n",
       "preds      O     O    B-PER  I-PER  I-PER  I-PER  I-PER      O    B-ORG   \n",
       "losses  0.00  0.00     6.02   5.37   0.00   0.00   0.00  10.44     7.66   \n",
       "\n",
       "           9   ...     13     14     15    16         17     18     19    20  \\\n",
       "tokens      s  ...    ‚ñÅ40     ‚ñÅ1      ‚ñÅ     ,  ‚ñÅFebruary    ‚ñÅ11     ‚ñÅ)   ‚ñÅ''   \n",
       "labels    IGN  ...  I-ORG  I-ORG  I-ORG   IGN      I-ORG  I-ORG  I-ORG     O   \n",
       "preds   I-ORG  ...  I-LOC      O      O     O          O      O      O     O   \n",
       "losses   0.00  ...   2.97   8.72  10.24  0.00       9.25   9.64  10.04  0.00   \n",
       "\n",
       "          21    22  \n",
       "tokens    ‚ñÅ'  </s>  \n",
       "labels     O   IGN  \n",
       "preds      O     O  \n",
       "losses  0.00  0.00  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"total_loss\"] = df[\"loss\"].apply(sum)\n",
    "df_tmp = df.sort_values(by=\"total_loss\", ascending=False).head(2)\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme vimos anteriormente, par√™nteses tinham uma loss relativamente alta, vamos ver alguns exemplos?\n",
    "<br> Em geral os par√™nteses e seus conte√∫dos n√£o fazem parte das entidades nomeadas, mas em alguns casos parece que isso est√° acontecendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>‚ñÅ'</td>\n",
       "      <td>‚ñÅ''</td>\n",
       "      <td>‚ñÅJustin</td>\n",
       "      <td>‚ñÅTim</td>\n",
       "      <td>ber</td>\n",
       "      <td>la</td>\n",
       "      <td>ke</td>\n",
       "      <td>‚ñÅ-</td>\n",
       "      <td>‚ñÅMirror</td>\n",
       "      <td>s</td>\n",
       "      <td>...</td>\n",
       "      <td>‚ñÅ40</td>\n",
       "      <td>‚ñÅ1</td>\n",
       "      <td>‚ñÅ</td>\n",
       "      <td>,</td>\n",
       "      <td>‚ñÅFebruary</td>\n",
       "      <td>‚ñÅ11</td>\n",
       "      <td>‚ñÅ)</td>\n",
       "      <td>‚ñÅ''</td>\n",
       "      <td>‚ñÅ'</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>...</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>...</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.02</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.44</td>\n",
       "      <td>7.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.97</td>\n",
       "      <td>8.72</td>\n",
       "      <td>10.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.25</td>\n",
       "      <td>9.64</td>\n",
       "      <td>10.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1        2      3      4      5      6      7        8   \\\n",
       "tokens    ‚ñÅ'   ‚ñÅ''  ‚ñÅJustin   ‚ñÅTim    ber     la     ke     ‚ñÅ-  ‚ñÅMirror   \n",
       "labels     O     O    B-ORG  I-ORG    IGN    IGN    IGN  I-ORG    I-ORG   \n",
       "preds      O     O    B-PER  I-PER  I-PER  I-PER  I-PER      O    B-ORG   \n",
       "losses  0.00  0.00     6.02   5.37   0.00   0.00   0.00  10.44     7.66   \n",
       "\n",
       "           9   ...     13     14     15    16         17     18     19    20  \\\n",
       "tokens      s  ...    ‚ñÅ40     ‚ñÅ1      ‚ñÅ     ,  ‚ñÅFebruary    ‚ñÅ11     ‚ñÅ)   ‚ñÅ''   \n",
       "labels    IGN  ...  I-ORG  I-ORG  I-ORG   IGN      I-ORG  I-ORG  I-ORG     O   \n",
       "preds   I-ORG  ...  I-LOC      O      O     O          O      O      O     O   \n",
       "losses   0.00  ...   2.97   8.72  10.24  0.00       9.25   9.64  10.04  0.00   \n",
       "\n",
       "          21    22  \n",
       "tokens    ‚ñÅ'  </s>  \n",
       "labels     O   IGN  \n",
       "preds      O     O  \n",
       "losses  0.00  0.00  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>‚ñÅIron</td>\n",
       "      <td>‚ñÅMan</td>\n",
       "      <td>‚ñÅ:</td>\n",
       "      <td>‚ñÅAr</td>\n",
       "      <td>mo</td>\n",
       "      <td>red</td>\n",
       "      <td>‚ñÅAdventure</td>\n",
       "      <td>s</td>\n",
       "      <td>‚ñÅ''</td>\n",
       "      <td>‚ñÅ‚Äì</td>\n",
       "      <td>...</td>\n",
       "      <td>‚ñÅVan</td>\n",
       "      <td>ko</td>\n",
       "      <td>‚ñÅ(</td>\n",
       "      <td>‚ñÅCri</td>\n",
       "      <td>m</td>\n",
       "      <td>son</td>\n",
       "      <td>‚ñÅDyna</td>\n",
       "      <td>mo</td>\n",
       "      <td>‚ñÅ)</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>5.65</td>\n",
       "      <td>6.56</td>\n",
       "      <td>6.94</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.13</td>\n",
       "      <td>9.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.73</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2      3      4      5           6      7     8   \\\n",
       "tokens  ‚ñÅIron   ‚ñÅMan     ‚ñÅ:    ‚ñÅAr     mo    red  ‚ñÅAdventure      s   ‚ñÅ''   \n",
       "labels  B-PER  I-PER  I-PER  I-PER    IGN    IGN       I-PER    IGN     O   \n",
       "preds   B-ORG  I-ORG  I-ORG  I-ORG  I-ORG  I-ORG       I-ORG  I-ORG     O   \n",
       "losses   5.65   6.56   6.94   6.96   0.00   0.00        5.99   0.00  0.00   \n",
       "\n",
       "          9   ...     11     12     13     14     15     16     17     18  \\\n",
       "tokens    ‚ñÅ‚Äì  ...   ‚ñÅVan     ko     ‚ñÅ(   ‚ñÅCri      m    son  ‚ñÅDyna     mo   \n",
       "labels     O  ...  I-PER    IGN  I-PER  I-PER    IGN    IGN  I-PER    IGN   \n",
       "preds      O  ...  I-PER  I-PER      O  B-ORG  I-ORG  I-ORG  I-ORG  I-ORG   \n",
       "losses  0.00  ...   0.01   0.00   7.13   9.24   0.00   0.00   4.71   0.00   \n",
       "\n",
       "           19     20  \n",
       "tokens     ‚ñÅ)   </s>  \n",
       "labels  I-PER    IGN  \n",
       "preds       O  I-ORG  \n",
       "losses   8.73   0.00  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tmp = df.loc[\n",
    "    df[\"input_tokens\"].apply(lambda x: u\"\\u2581(\" in x)\n",
    "].sort_values(by=\"total_loss\", ascending=False).head(2)\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com algumas an√°lises simples, j√° conseguimos identificar fraquezas e for√ßas dentro do nosso modelo e dos nossos dados. Agora podemos iterar sobre ele para limpar nossos labels, nossos dados, fazer otimiza√ß√£o de hiperpar√¢metro como fizemos no modelo de an√°lise de sentimento da aula passada, reanalisar os errors, e ir cada vez melhorando mais nosso modelo at√© estarmos satisfeitos com seus performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
