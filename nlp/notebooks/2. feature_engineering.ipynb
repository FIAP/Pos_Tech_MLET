{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP\n",
    "### Bag-of-Words, Word2Vec e Embeddings\n",
    "<b>Objetivo: </b> Entender como transformar texto em representações vetoriais numéricas que alimentarão um modelo.\n",
    "<br><b>Autora:</b> Renata Gotler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos continuar usando os dados de comentários da americanas que exploramos na aula passada.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec, Phrases\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from src.preprocessing import TextPreprocessing\n",
    "\n",
    "prep = TextPreprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"rslp\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "lemmatizer = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_687/1634640095.py:3: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_reviews = pd.read_csv(url)\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/americanas-tech/b2w-reviews01/main/B2W-Reviews01.csv'\n",
    "\n",
    "df_reviews = pd.read_csv(url)\n",
    "df_reviews = df_reviews[[\"review_text\", \"overall_rating\"]].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag-of-Words\n",
    "Representa cada documento como um vetor de frequências de palavras. Esse vetor será de números inteiros, visto que é uma contagem de palavras, e terá tamanho fixo, o tamanho do vocabulário passado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_full = CountVectorizer()\n",
    "X_raw = vectorizer_full.fit_transform(df_reviews[\"review_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O X será terá formato: número de registros x tamanho do vocabulário. Na aula passada usamos esses mesmos dados e sem limpeza, obtivemos um vocabulário de cerca de 75k tokens, aqui temos cerca de 50k, isso acontece porque o CountVectorizer por padrão já transforma o texto para minúsculo e já aplica algumas limpezas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129098, 50336)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo podemos ver que alguns tokens são formados somente por números e podem prejudicar e deixar nosso modelo mais complexo, tendo ainda espaço para melhorias. Vamos aplicar algumas limpezas da aula passada para melhorar esses vetores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '0000' '00000' '000000']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer_full.get_feature_names_out()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews[\"review_text_cleaned\"] = df_reviews[\"review_text\"].apply(lambda x: prep.preprocess_text(\n",
    "    text=x,\n",
    "    apply_lower=True,\n",
    "    remove_ponctuation=True,\n",
    "    remove_numbers=True,\n",
    "    clean_html=True,\n",
    "    apply_unidecode=True,\n",
    "    remove_stopwords=True,\n",
    "    remove_short_tokens=True,\n",
    "    min_tokens_size=2,\n",
    "    limit_consecutive_chars=True,\n",
    "    max_consecutive_char=2,\n",
    "    apply_lemmitization=True,\n",
    "    lemmatizer=lemmatizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129098, 37539)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cleaned = vectorizer_full.fit_transform(df_reviews[\"review_text_cleaned\"])\n",
    "X_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda temos algumas oportunidades de melhoria, mas por hora vamos seguir, 37539 já é bem melhor do que 50336."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1a' '2e' 'aa' 'aabar'\n",
      " 'aabbgdzfhijvfgjkbghjhgfvfefvhycfjufvgjchhfdfbnkoufdcmkjtexnjg']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer_full.get_feature_names_out()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo podemos ver que é bem difícil limpar um texto 100%, dessa forma, o ideal é ir testando e vendo o impacto até chegar no resultado desejado. Por exemplo, abaixo vemos alguns erros de digitação, como o `Aabei` deveria ser `Acabei`, que poderiamos corrigir com as correspondências fuzzy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aabei de instalar.Muito facil e rapido de ser instalada.Sua imagem e otima tanto durante o dia quanto a noite.Eu recomendo.Excelente produto cumpre o que diz perfeitamente.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews[df_reviews[\"review_text_cleaned\"].str.contains(\"aabar\")][\"review_text\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aabar instalar facil rapir instalar imagem otimo tanto durante dia quanto noite recomer excelente produto cumprir dizer perfeitamente'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews[df_reviews[\"review_text_cleaned\"].str.contains(\"aabar\")][\"review_text_cleaned\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fins didáticos, vou reduzir a quantidade de dados para poder mostrar como é a matriz resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 37)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_small = CountVectorizer()\n",
    "X_small = vectorizer_small.fit_transform(df_reviews[\"review_text_cleaned\"][:3])\n",
    "X_small.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teremos o vetor registro x tamanho de vocabulário. Abaixo podemos ver que o CountVectorizer somente conta a frequência de quantas vezes um token apareceu naquele texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acrilico', 'agilidade', 'americano', 'apenas', 'arroz', 'compra',\n",
       "       'comprar', 'conseguir', 'consumidor', 'contente', 'copo',\n",
       "       'costumar', 'cozimento', 'devolucao', 'eletrica', 'em', 'entregar',\n",
       "       'esperar', 'esse', 'exatamente', 'japonês', 'levar', 'lir',\n",
       "       'minuto', 'outro', 'panela', 'praticidade', 'problema', 'produto',\n",
       "       'raper', 'rapir', 'recomer', 'superar', 'tempo', 'trocar', 'unico',\n",
       "       'usar'], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_small.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        0, 2, 2, 3, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_small.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por exemplo, podemos ver que temos um 3 no terceiro registro. Vamos ver se confere?\n",
    "<br> Para isso, primeiro vamos encontrar o token do terceiro registro que aparece três vezes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'panela'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_index = list(X_small.toarray()[2]).index(3)\n",
    "vectorizer_small.get_feature_names_out()[token_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realmente, `panela` aparece três vezes no terceiro registro! Viu? CountVectorizer é simplesmente uma matrix que conta quantos tokens aparecem em cada registro, onde cada token vira uma coluna e cada registro, uma linha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'superar agilidade praticidade outro panela eletrica costumar usar outro panela cozimento arroz japonês levar tempo minuto em esse panela rapir exatamente minuto recomer'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews[\"review_text_cleaned\"].iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A limpeza dos textos é bem difícil de ser feita 100%, podemos ver abaixo que já fizemos um excelente trabalho, então vamos ver os resultados que temos com a limpeza feita até agora, se o resultado atingido não for tão bom quanto o que queremos, iteramos para limpar mais. Isso é lidar com dados da vida real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of n-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um parâmetro bem interessante que podemos explorar é o `ngram_range`, criando uma bag of n-grams. Esse parâmetro ajuda na geração de contexto, criando um conjunto de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 75)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_n_gram = CountVectorizer(ngram_range=(1, 2))\n",
    "X_n_gram = vectorizer_n_gram.fit_transform(df_reviews[\"review_text_cleaned\"][:3])\n",
    "X_n_gram.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, veja que de um vocabulário de 37 tokens, agora com as combinações chegamos a 75. Dessa forma, temos que usar o n-gram com cuidado, visto que ele aumenta bastante a cardinalidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acrilico', 'agilidade', 'agilidade praticidade', 'americano',\n",
       "       'americano trocar', 'apenas', 'apenas conseguir', 'arroz',\n",
       "       'arroz japonês', 'compra', 'compra entregar', 'comprar',\n",
       "       'comprar lir', 'conseguir', 'conseguir comprar', 'consumidor',\n",
       "       'consumidor problema', 'contente', 'contente compra', 'copo',\n",
       "       'copo acrilico', 'costumar', 'costumar usar', 'cozimento',\n",
       "       'cozimento arroz', 'devolucao', 'devolucao produto', 'eletrica',\n",
       "       'eletrica costumar', 'em', 'em esse', 'entregar', 'entregar raper',\n",
       "       'esperar', 'esse', 'esse panela', 'exatamente',\n",
       "       'exatamente minuto', 'japonês', 'japonês levar', 'levar',\n",
       "       'levar tempo', 'lir', 'lir copo', 'minuto', 'minuto em',\n",
       "       'minuto recomer', 'outro', 'outro panela', 'panela',\n",
       "       'panela cozimento', 'panela eletrica', 'panela rapir',\n",
       "       'praticidade', 'praticidade outro', 'problema',\n",
       "       'problema americano', 'problema esperar', 'produto',\n",
       "       'produto consumidor', 'raper', 'raper unico', 'rapir',\n",
       "       'rapir exatamente', 'recomer', 'superar', 'superar agilidade',\n",
       "       'tempo', 'tempo minuto', 'trocar', 'trocar devolucao', 'unico',\n",
       "       'unico problema', 'usar', 'usar outro'], dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_n_gram.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pondera as palavras com base na frequência no documento e na inversa da frequência nos documentos. Dessa forma, esse algoritmo ajuda a reduzir o peso de palavras comuns e aumentar o peso de palavras distintivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O TF-IDF tem as mesmas dimensões que o CountVectorizer, o que vão mudar são os números na matrix. Ao invés de uma contagem, temos uma ponderação de acordo com a frequência do token dentro do registro e da frequência do token nos demais registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129098, 37539)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer(norm=\"l1\", smooth_idf=False)\n",
    "X_tf_idf = tf_idf.fit_transform(df_reviews[\"review_text_cleaned\"])\n",
    "X_tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{True}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(tf_idf.get_feature_names_out() == vectorizer_full.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver mais a fundo como funciona o TF-IDF? Começando pelo TF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.07692308, 0.        , 0.        ,\n",
       "        0.07692308, 0.        , 0.        , 0.07692308, 0.07692308,\n",
       "        0.        , 0.        , 0.        , 0.07692308, 0.        ,\n",
       "        0.        , 0.07692308, 0.07692308, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15384615, 0.07692308, 0.07692308,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.07692308,\n",
       "        0.07692308, 0.        ],\n",
       "       [0.16666667, 0.        , 0.        , 0.16666667, 0.        ,\n",
       "        0.        , 0.16666667, 0.16666667, 0.        , 0.        ,\n",
       "        0.16666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.16666667, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.04347826, 0.        , 0.        , 0.04347826,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04347826, 0.04347826, 0.        , 0.04347826,\n",
       "        0.04347826, 0.        , 0.        , 0.04347826, 0.04347826,\n",
       "        0.04347826, 0.04347826, 0.        , 0.08695652, 0.08695652,\n",
       "        0.13043478, 0.04347826, 0.        , 0.        , 0.        ,\n",
       "        0.04347826, 0.04347826, 0.04347826, 0.04347826, 0.        ,\n",
       "        0.        , 0.04347826]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = TfidfVectorizer(norm=\"l1\", use_idf=False)\n",
    "X_tf = tf.fit_transform(df_reviews[\"review_text_cleaned\"][:3])\n",
    "X_tf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já vimos que o token `panela` se repete 3 vezes no terceiro registro, por isso, ele possui um valor (0.13043478) que é o triplo dos demais valores (0.043478260869565216), com exceção do token `minutos`, que aparece duas vezes, com valor 0.08695652, enquanto todos os demais ficaram com 0.04347826 (equivalente a aparecer uma vez no registro). Isso porque no TF, temos uma normalização da quantidade de vezes que um token aparece em um registro pela quantidade total de tokens do registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043478260869565216"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / len(df_reviews[\"review_text_cleaned\"].iloc[2].split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa forma, todas as linhas somam 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tf[0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 3 registros nesse treinamento, então o IDF será calculado como log(3/quantidade de registros que o token apareceu)+1. Como vemos, os tokens apareceram unicamente em seus registros, isso aconteceu muito porque limpamos bastante o texto, retirando stopwords ,por exemplo, que se repetiram mais entre os registros, com isso todos os tokens tiveram o valor log(3/1) + 1 = 2.09861229.\n",
    "<br> Percebam também que o IDF será uma matrix do tamanho da quantidade do vocabulário (quantidade de variáveis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       2.09861229, 2.09861229])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_small = TfidfVectorizer(norm=\"l1\", smooth_idf=False)\n",
    "X_tf_idf_small = tf_idf_small.fit_transform(df_reviews[\"review_text_cleaned\"][:3])\n",
    "tf_idf_small.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, (3, 37))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_idf_small.idf_), X_tf_idf_small.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, podemos multiplicar nossas matrixes (TF x IDF) temos o TF-IDF. O TfidfVectorizer ainda aplica uma normalização final, para que a soma dos valores de cada registro resulte em 1, o que acabou sendo igual ao TF porque nosso IDF ficou igual para todos os tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.07692308, 0.        , 0.        ,\n",
       "        0.07692308, 0.        , 0.        , 0.07692308, 0.07692308,\n",
       "        0.        , 0.        , 0.        , 0.07692308, 0.        ,\n",
       "        0.        , 0.07692308, 0.07692308, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15384615, 0.07692308, 0.07692308,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.07692308,\n",
       "        0.07692308, 0.        ],\n",
       "       [0.16666667, 0.        , 0.        , 0.16666667, 0.        ,\n",
       "        0.        , 0.16666667, 0.16666667, 0.        , 0.        ,\n",
       "        0.16666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.16666667, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.04347826, 0.        , 0.        , 0.04347826,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04347826, 0.04347826, 0.        , 0.04347826,\n",
       "        0.04347826, 0.        , 0.        , 0.04347826, 0.04347826,\n",
       "        0.04347826, 0.04347826, 0.        , 0.08695652, 0.08695652,\n",
       "        0.13043478, 0.04347826, 0.        , 0.        , 0.        ,\n",
       "        0.04347826, 0.04347826, 0.04347826, 0.04347826, 0.        ,\n",
       "        0.        , 0.04347826]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tf_idf_small.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O TF-IDF é bem interessante por penalisar tokens que se repetem muito entre registros, assumindo que se um token aparece frequentemente, ele não é um token importante para ajudar a distinguir entre os registros. Imagine um classificador de spam, as sentenças: \"Assinado\", \"Fico à disposição\", \"Abraços\", se repetem em vários emails e não nos ajudam a identificar um spam, certo? Já as sentenças: \"Perca peso\", \"Cem por cento garantido\", já não se repetem tanto nos emails e nos ajudam mais na classificação.\n",
    "<br> Assim como o CountVectorizer, o TfidfVectorizer também possui parâmetros bem interessantes como o `ngram_range` que funciona da mesma forma e nos dá mais contexto ao custo de uma maior cardinalidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Família de arquitetura de modelos e otimizações para criação de embeddings que cria vetores de palavras com base em contextos locais. Dessa forma, vetores distantes possuem significados diferentes e vetores próximos representam palavras com significados similares. Por exemplo, as palavras “mulher” e “rainha” estão perto no espaço vetorial, enquanto “mulher” e “muralha” estão mais distantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo vamos usar biblioteca gensim para testar o modelo padrão, que é o CBoW.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_reviews[\"review_text_cleaned\"].str.split(\" \").to_list()\n",
    "model = Word2Vec(sentences, vector_size=10, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceba que o vetor tem tamanho definido pelo parâmetro vector_size, no caso, 10. Em geral, você deve fazer otimizações de hiperâmetros, como o vector_size, window_size e os demais para entender o melhor modelo para o seu caso.\n",
    "<br>Por exemplo, um vector_size pequeno (50, 100) reduz a quantidade de recursos computacionais necessários e overfitting, indicado quando a quantidade de recursos é baixa ou você tem um dataset pequeno. Já maiores (200, 300) captura melhor as relações semânticas entre as palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0856761 ,  0.9885719 ,  1.3500437 , -0.815709  ,  1.0313131 ,\n",
       "        0.970741  , -0.34947467,  1.6502775 , -2.5394058 , -1.1652255 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panela_vector = model.wv['panela']\n",
    "panela_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesmo com somente um vetor de tamanho 10 e janela de 2, já conseguimos ver que a distância entre as palavras faz sentido, onde panela e prato fica mais perto do que panela e minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cama', 0.9742375612258911)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('panela', topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81594384"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('panela', 'prato')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5390221"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('panela', 'minutos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar o skip-gram no lugar do CBoW, basta alterar o parâmetro `sg` para 1, conforme [documentação](https://radimrehurek.com/gensim/models/word2vec.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você quiser, pode salvar seu modelo para reutilizar posteriormente, ou retreiná-lo com novos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/americanas_cbow.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec.load(\"../models/americanas_cbow.model\")\n",
    "model.train([[\"hello\", \"world\"]], total_examples=1, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-grams Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biblioteca gensim possui uma classe chamada Phrases que automaticamente detecta frases comuns e cria tokens agrupando os tokens detectados com um demilitador _."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_reviews[\"review_text_cleaned\"].str.split(\" \").to_list()\n",
    "bigram_transformer = Phrases(sentences)\n",
    "bigram_model = Word2Vec(bigram_transformer[sentences], min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['antes_prazo', 'chegar_antes', 'super_rapir', 'custo_beneficio', 'ate_agora']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[key for key,_ in bigram_model.wv.key_to_index.items() if key not in model.wv.key_to_index.keys()][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do vocabulário com n gram: 42899\n",
      "Tamanho do vocabulário sem n gram: 39012\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Tamanho do vocabulário com n gram: {len(bigram_model.wv.key_to_index)}\n",
    "Tamanho do vocabulário sem n gram: {len(model.wv.key_to_index)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sempre precisamos analisar questões como bases enviesadas, mesmo em datasets onde não esperamos esse comportamento, como em comentário de produtos. Abaixo vemos um exemplo claro de viés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('familia', 0.9137730598449707)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model.wv.most_similar('mulher', topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('desafio', 0.9510673880577087)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model.wv.most_similar('homem', topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos inclusive fazer operações algebricas como: homem + familia - desafio e o resultado voltará mulher. Ruim né? Por isso é sempre importante estar atento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mulher', 0.899430513381958)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model.wv.most_similar(\n",
    "    positive=['homem', 'familia'], \n",
    "    negative=['desafio'], topn=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A característica chave dessa representação é que pontos em um espaço vetorial que estão próximos uns aos outros possuem similaridades semânticas próximas. Abaixo, primeiro reduzimos os vetores para 2D para conseguirmos visualizar as palavras em um gráfico de dispersão. Nele, podemos ver que `desafio` e `futebol` ficaram agrupados, já utensílios de cozinha e objetos de casa ficaram apartados. No entanto, ainda temos somente uma representação vetorial para cada palavra, não conseguindo entender contextos em sentenças."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "componente 1=%{x}<br>componente 2=%{y}<br>text=%{text}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "text": [
          "homem",
          "mulher",
          "familia",
          "desafio",
          "panela",
          "cama",
          "bola",
          "futebol",
          "quarto",
          "cozinha"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          -1.5438158512115479,
          -1.1436606645584106,
          -1.1021636724472046,
          -1.9984793663024902,
          3.335791826248169,
          1.7489798069000244,
          -1.347589373588562,
          -2.2831406593322754,
          1.081589937210083,
          3.2524869441986084
         ],
         "xaxis": "x",
         "y": [
          0.09297347813844681,
          -0.3787631690502167,
          -0.45409518480300903,
          0.38517117500305176,
          2.756227493286133,
          1.0987203121185303,
          0.8004605174064636,
          0.1294838786125183,
          -2.140681028366089,
          -2.2894954681396484
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "PCA de Embeddings de Palavra"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "componente 1"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "componente 2"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"5e956098-2c2c-4d24-9918-00fdcbaa3cb1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5e956098-2c2c-4d24-9918-00fdcbaa3cb1\")) {                    Plotly.newPlot(                        \"5e956098-2c2c-4d24-9918-00fdcbaa3cb1\",                        [{\"hovertemplate\":\"componente 1=%{x}\\u003cbr\\u003ecomponente 2=%{y}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"homem\",\"mulher\",\"familia\",\"desafio\",\"panela\",\"cama\",\"bola\",\"futebol\",\"quarto\",\"cozinha\"],\"x\":[-1.5438158512115479,-1.1436606645584106,-1.1021636724472046,-1.9984793663024902,3.335791826248169,1.7489798069000244,-1.347589373588562,-2.2831406593322754,1.081589937210083,3.2524869441986084],\"xaxis\":\"x\",\"y\":[0.09297347813844681,-0.3787631690502167,-0.45409518480300903,0.38517117500305176,2.756227493286133,1.0987203121185303,0.8004605174064636,0.1294838786125183,-2.140681028366089,-2.2894954681396484],\"yaxis\":\"y\",\"type\":\"scatter\",\"textposition\":\"top center\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"componente 1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"componente 2\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"PCA de Embeddings de Palavra\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('5e956098-2c2c-4d24-9918-00fdcbaa3cb1');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "palavras = [\"homem\", \"mulher\", \"familia\", \"desafio\", \"panela\", \"cama\", \"bola\", \"futebol\", \"quarto\", \"cozinha\"]\n",
    "vetores = np.array([bigram_model.wv[palavra] for palavra in palavras])\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "vectors_pca = pca.fit_transform(vetores)\n",
    "\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=vectors_pca[:, 0],\n",
    "    y=vectors_pca[:, 1],\n",
    "    title='PCA de Embeddings de Palavra',\n",
    "    text=palavras,\n",
    "    labels={'x': 'componente 1', 'y':'componente 2'}\n",
    ")\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embeddings com contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo vamos utilizar o BERT para entender como funciona seus embeddings na prática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"neuralmind/bert-base-portuguese-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_checkpoint, cache_dir=\"../models/\")\n",
    "model = BertModel.from_pretrained(model_checkpoint, \"../models/\")\n",
    "\n",
    "def get_bert_embeddings(sentence, word):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    word_tokens = tokenizer.tokenize(sentence)\n",
    "    word_index = word_tokens.index(word)\n",
    "    word_embedding = last_hidden_states[0, word_index + 1, :]  # +1 por causa do token [CLS]\n",
    "    return word_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo vamos testar o BERT usando duas sentenças diferentes, ambas usando a palavra `cabeça` em contextos diferentes e depois vamos ver como ficou o embedding `cabeça` em ambas as sentenças. Na primeira, `cabeça` tem o sentido anatomico, é parte do corpo humano, enquanto na segunda, `cabeça` é no sentido de liderança."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"Ele sempre traz um boné na cabeça\"\n",
    "sentence2 = \"Rodrigo é o cabeça da equipe.\"\n",
    "\n",
    "word = \"cabeça\"\n",
    "\n",
    "bert_embedding1 = get_bert_embeddings(sentence1, word).detach().numpy()\n",
    "bert_embedding2 = get_bert_embeddings(sentence2, word).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o contexto é diferente, a palavra 'cabeça' possui embeddings diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Embedding para 'cabeça' na sentença 1: [ 0.6289185   0.02376817  0.5080008  -0.03347447  0.12856108]\n",
      "BERT Embedding para 'cabeça' na sentença 2: [-0.3262949  -0.32981738  0.7123761  -0.45160568  0.15020438]\n"
     ]
    }
   ],
   "source": [
    "print(f\"BERT Embedding para '{word}' na sentença 1:\", bert_embedding1[:5])\n",
    "print(f\"BERT Embedding para '{word}' na sentença 2:\", bert_embedding2[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
