{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP\n",
    "### Bag-of-Words, Word2Vec e Embeddings\n",
    "<b>Objetivo: </b> Entender como transformar texto em representações vetoriais numéricas que alimentarão um modelo.\n",
    "<br><b>Autora:</b> Renata Gotler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos continuar usando os dados de comentários da americanas que exploramos na aula passada.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec, Phrases\n",
    "\n",
    "from src.preprocessing import TextPreprocessing\n",
    "\n",
    "prep = TextPreprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"rslp\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "lemmatizer = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_939/1634640095.py:3: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_reviews = pd.read_csv(url)\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/americanas-tech/b2w-reviews01/main/B2W-Reviews01.csv'\n",
    "\n",
    "df_reviews = pd.read_csv(url)\n",
    "df_reviews = df_reviews[[\"review_text\", \"overall_rating\"]].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag-of-Words\n",
    "Representa cada documento como um vetor de frequências de palavras. Esse vetor será de números inteiros, visto que é uma contagem de palavras, e terá tamanho fixo, o tamanho do vocabulário passado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_full = CountVectorizer()\n",
    "X_raw = vectorizer_full.fit_transform(df_reviews[\"review_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O X será terá formato: número de registros x tamanho do vocabulário. Na aula passada usamos esses mesmos dados e sem limpeza, obtivemos um vocabulário de cerca de 75k tokens, aqui temos cerca de 50k, isso acontece porque o CountVectorizer por padrão já transforma o texto para minúsculo e já aplica algumas limpezas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129098, 50336)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo podemos ver que alguns tokens são formados somente por números e podem prejudicar e deixar nosso modelo mais complexo, tendo ainda espaço para melhorias. Vamos aplicar algumas limpezas da aula passada para melhorar esses vetores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '0000' '00000' '000000']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer_full.get_feature_names_out()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews[\"review_text_cleaned\"] = df_reviews[\"review_text\"].apply(lambda x: prep.preprocess_text(\n",
    "    text=x,\n",
    "    apply_lower=True,\n",
    "    remove_ponctuation=True,\n",
    "    remove_numbers=True,\n",
    "    clean_html=True,\n",
    "    apply_unidecode=True,\n",
    "    remove_stopwords=True,\n",
    "    remove_short_tokens=True,\n",
    "    min_tokens_size=2,\n",
    "    limit_consecutive_chars=True,\n",
    "    max_consecutive_char=2,\n",
    "    apply_lemmitization=True,\n",
    "    lemmatizer=lemmatizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129098, 37539)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cleaned = vectorizer_full.fit_transform(df_reviews[\"review_text_cleaned\"])\n",
    "X_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda temos algumas oportunidades de melhoria, mas por hora vamos seguir, 37539 já é bem melhor do que 50336."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1a' '2e' 'aa' 'aabar'\n",
      " 'aabbgdzfhijvfgjkbghjhgfvfefvhycfjufvgjchhfdfbnkoufdcmkjtexnjg']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer_full.get_feature_names_out()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo podemos ver que é bem difícil limpar um texto 100%, dessa forma, o ideal é ir testando e vendo o impacto até chegar no resultado desejado. Por exemplo, abaixo vemos alguns erros de digitação, como o `Aabei` deveria ser `Acabei`, que poderiamos corrigir com as correspondências fuzzy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aabei de instalar.Muito facil e rapido de ser instalada.Sua imagem e otima tanto durante o dia quanto a noite.Eu recomendo.Excelente produto cumpre o que diz perfeitamente.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews[df_reviews[\"review_text_cleaned\"].str.contains(\"aabar\")][\"review_text\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aabar instalar facil rapir instalar imagem otimo tanto durante dia quanto noite recomer excelente produto cumprir dizer perfeitamente'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews[df_reviews[\"review_text_cleaned\"].str.contains(\"aabar\")][\"review_text_cleaned\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fins didáticos, vou reduzir a quantidade de dados para poder mostrar como é a matriz resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 37)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_small = CountVectorizer()\n",
    "X_small = vectorizer_small.fit_transform(df_reviews[\"review_text_cleaned\"][:3])\n",
    "X_small.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teremos o vetor registro x tamanho de vocabulário. Abaixo podemos ver que o CountVectorizer somente conta a frequência de quantas vezes um token apareceu naquele texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acrilico', 'agilidade', 'americano', 'apenas', 'arroz', 'compra',\n",
       "       'comprar', 'conseguir', 'consumidor', 'contente', 'copo',\n",
       "       'costumar', 'cozimento', 'devolucao', 'eletrica', 'em', 'entregar',\n",
       "       'esperar', 'esse', 'exatamente', 'japonês', 'levar', 'lir',\n",
       "       'minuto', 'outro', 'panela', 'praticidade', 'problema', 'produto',\n",
       "       'raper', 'rapir', 'recomer', 'superar', 'tempo', 'trocar', 'unico',\n",
       "       'usar'], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_small.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        0, 2, 2, 3, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_small.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por exemplo, podemos ver que temos um 3 no terceiro registro. Vamos ver se confere?\n",
    "<br> Para isso, primeiro vamos encontrar o token do terceiro registro que aparece três vezes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'panela'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_index = list(X_small.toarray()[2]).index(3)\n",
    "vectorizer_small.get_feature_names_out()[token_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realmente, `panela` aparece três vezes no terceiro registro! Viu? CountVectorizer é simplesmente uma matrix que conta quantos tokens aparecem em cada registro, onde cada token vira uma coluna e cada registro, uma linha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'superar agilidade praticidade outro panela eletrica costumar usar outro panela cozimento arroz japonês levar tempo minuto em esse panela rapir exatamente minuto recomer'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews[\"review_text_cleaned\"].iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A limpeza dos textos é bem difícil de ser feita 100%, podemos ver abaixo que já fizemos um excelente trabalho, então vamos ver os resultados que temos com a limpeza feita até agora, se o resultado atingido não for tão bom quanto o que queremos, iteramos para limpar mais. Isso é lidar com dados da vida real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of n-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um parâmetro bem interessante que podemos explorar é o `ngram_range`, criando uma bag of n-grams. Esse parâmetro ajuda na geração de contexto, criando um conjunto de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 75)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_n_gram = CountVectorizer(ngram_range=(1, 2))\n",
    "X_n_gram = vectorizer_n_gram.fit_transform(df_reviews[\"review_text_cleaned\"][:3])\n",
    "X_n_gram.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, veja que de um vocabulário de 37 tokens, agora com as combinações chegamos a 75. Dessa forma, temos que usar o n-gram com cuidado, visto que ele aumenta bastante a cardinalidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acrilico', 'agilidade', 'agilidade praticidade', 'americano',\n",
       "       'americano trocar', 'apenas', 'apenas conseguir', 'arroz',\n",
       "       'arroz japonês', 'compra', 'compra entregar', 'comprar',\n",
       "       'comprar lir', 'conseguir', 'conseguir comprar', 'consumidor',\n",
       "       'consumidor problema', 'contente', 'contente compra', 'copo',\n",
       "       'copo acrilico', 'costumar', 'costumar usar', 'cozimento',\n",
       "       'cozimento arroz', 'devolucao', 'devolucao produto', 'eletrica',\n",
       "       'eletrica costumar', 'em', 'em esse', 'entregar', 'entregar raper',\n",
       "       'esperar', 'esse', 'esse panela', 'exatamente',\n",
       "       'exatamente minuto', 'japonês', 'japonês levar', 'levar',\n",
       "       'levar tempo', 'lir', 'lir copo', 'minuto', 'minuto em',\n",
       "       'minuto recomer', 'outro', 'outro panela', 'panela',\n",
       "       'panela cozimento', 'panela eletrica', 'panela rapir',\n",
       "       'praticidade', 'praticidade outro', 'problema',\n",
       "       'problema americano', 'problema esperar', 'produto',\n",
       "       'produto consumidor', 'raper', 'raper unico', 'rapir',\n",
       "       'rapir exatamente', 'recomer', 'superar', 'superar agilidade',\n",
       "       'tempo', 'tempo minuto', 'trocar', 'trocar devolucao', 'unico',\n",
       "       'unico problema', 'usar', 'usar outro'], dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_n_gram.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pondera as palavras com base na frequência no documento e na inversa da frequência nos documentos. Dessa forma, esse algoritmo ajuda a reduzir o peso de palavras comuns e aumentar o peso de palavras distintivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O TF-IDF tem as mesmas dimensões que o CountVectorizer, o que vão mudar são os números na matrix. Ao invés de uma contagem, temos uma ponderação de acordo com a frequência do token dentro do registro e da frequência do token nos demais registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129098, 37539)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer(norm=\"l1\", smooth_idf=False)\n",
    "X_tf_idf = tf_idf.fit_transform(df_reviews[\"review_text_cleaned\"])\n",
    "X_tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{True}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(tf_idf.get_feature_names_out() == vectorizer_full.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver mais a fundo como funciona o TF-IDF? Começando pelo TF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.07692308, 0.        , 0.        ,\n",
       "        0.07692308, 0.        , 0.        , 0.07692308, 0.07692308,\n",
       "        0.        , 0.        , 0.        , 0.07692308, 0.        ,\n",
       "        0.        , 0.07692308, 0.07692308, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15384615, 0.07692308, 0.07692308,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.07692308,\n",
       "        0.07692308, 0.        ],\n",
       "       [0.16666667, 0.        , 0.        , 0.16666667, 0.        ,\n",
       "        0.        , 0.16666667, 0.16666667, 0.        , 0.        ,\n",
       "        0.16666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.16666667, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.04347826, 0.        , 0.        , 0.04347826,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04347826, 0.04347826, 0.        , 0.04347826,\n",
       "        0.04347826, 0.        , 0.        , 0.04347826, 0.04347826,\n",
       "        0.04347826, 0.04347826, 0.        , 0.08695652, 0.08695652,\n",
       "        0.13043478, 0.04347826, 0.        , 0.        , 0.        ,\n",
       "        0.04347826, 0.04347826, 0.04347826, 0.04347826, 0.        ,\n",
       "        0.        , 0.04347826]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = TfidfVectorizer(norm=\"l1\", use_idf=False)\n",
    "X_tf = tf.fit_transform(df_reviews[\"review_text_cleaned\"][:3])\n",
    "X_tf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já vimos que o token `panela` se repete 3 vezes no terceiro registro, por isso, ele possui um valor (0.13043478) que é o triplo dos demais valores (0.043478260869565216), com exceção do token `minutos`, que aparece duas vezes, com valor 0.08695652, enquanto todos os demais ficaram com 0.04347826 (equivalente a aparecer uma vez no registro). Isso porque no TF, temos uma normalização da quantidade de vezes que um token aparece em um registro pela quantidade total de tokens do registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043478260869565216"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / len(df_reviews[\"review_text_cleaned\"].iloc[2].split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa forma, todas as linhas somam 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tf[0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 3 registros nesse treinamento, então o IDF será calculado como log(3/quantidade de registros que o token apareceu)+1. Como vemos, os tokens apareceram unicamente em seus registros, isso aconteceu muito porque limpamos bastante o texto, retirando stopwords ,por exemplo, que se repetiram mais entre os registros, com isso todos os tokens tiveram o valor log(3/1) + 1 = 2.09861229.\n",
    "<br> Percebam também que o IDF será uma matrix do tamanho da quantidade do vocabulário (quantidade de variáveis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
       "       2.09861229, 2.09861229])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_small = TfidfVectorizer(norm=\"l1\", smooth_idf=False)\n",
    "X_tf_idf_small = tf_idf_small.fit_transform(df_reviews[\"review_text_cleaned\"][:3])\n",
    "tf_idf_small.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, (3, 37))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_idf_small.idf_), X_tf_idf_small.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, podemos multiplicar nossas matrixes (TF x IDF) temos o TF-IDF. O TfidfVectorizer ainda aplica uma normalização final, para que a soma dos valores de cada registro resulte em 1, o que acabou sendo igual ao TF porque nosso IDF ficou igual para todos os tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.07692308, 0.        , 0.        ,\n",
       "        0.07692308, 0.        , 0.        , 0.07692308, 0.07692308,\n",
       "        0.        , 0.        , 0.        , 0.07692308, 0.        ,\n",
       "        0.        , 0.07692308, 0.07692308, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15384615, 0.07692308, 0.07692308,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.07692308,\n",
       "        0.07692308, 0.        ],\n",
       "       [0.16666667, 0.        , 0.        , 0.16666667, 0.        ,\n",
       "        0.        , 0.16666667, 0.16666667, 0.        , 0.        ,\n",
       "        0.16666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.16666667, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.04347826, 0.        , 0.        , 0.04347826,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04347826, 0.04347826, 0.        , 0.04347826,\n",
       "        0.04347826, 0.        , 0.        , 0.04347826, 0.04347826,\n",
       "        0.04347826, 0.04347826, 0.        , 0.08695652, 0.08695652,\n",
       "        0.13043478, 0.04347826, 0.        , 0.        , 0.        ,\n",
       "        0.04347826, 0.04347826, 0.04347826, 0.04347826, 0.        ,\n",
       "        0.        , 0.04347826]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tf_idf_small.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O TF-IDF é bem interessante por penalisar tokens que se repetem muito entre registros, assumindo que se um token aparece frequentemente, ele não é um token importante para ajudar a distinguir entre os registros. Imagine um classificador de spam, as sentenças: \"Assinado\", \"Fico à disposição\", \"Abraços\", se repetem em vários emails e não nos ajudam a identificar um spam, certo? Já as sentenças: \"Perca peso\", \"Cem por cento garantido\", já não se repetem tanto nos emails e nos ajudam mais na classificação.\n",
    "<br> Assim como o CountVectorizer, o TfidfVectorizer também possui parâmetros bem interessantes como o `ngram_range` que funciona da mesma forma e nos dá mais contexto ao custo de uma maior cardinalidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Família de arquitetura de modelos e otimizações para criação de embeddings que cria vetores de palavras com base em contextos locais. Dessa forma, vetores distantes possuem significados diferentes e vetores próximos representam palavras com significados similares. Por exemplo, as palavras “mulher” e “rainha” estão perto no espaço vetorial, enquanto “mulher” e “muralha” estão mais distantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo vamos usar biblioteca gensim para testar o modelo padrão, que é o CBoW.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_reviews[\"review_text_cleaned\"].str.split(\" \").to_list()\n",
    "model = Word2Vec(sentences, vector_size=10, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceba que o vetor tem tamanho definido pelo parâmetro vector_size, no caso, 10. Em geral, você deve fazer otimizações de hiperâmetros, como o vector_size, window_size e os demais para entender o melhor modelo para o seu caso.\n",
    "<br>Por exemplo, um vector_size pequeno (50, 100) reduz a quantidade de recursos computacionais necessários e overfitting, indicado quando a quantidade de recursos é baixa ou você tem um dataset pequeno. Já maiores (200, 300) captura melhor as relações semânticas entre as palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0856761 ,  0.9885719 ,  1.3500437 , -0.815709  ,  1.0313131 ,\n",
       "        0.970741  , -0.34947467,  1.6502775 , -2.5394058 , -1.1652255 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panela_vector = model.wv['panela']\n",
    "panela_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesmo com somente um vetor de tamanho 10 e janela de 2, já conseguimos ver que a distância entre as palavras faz sentido, onde panela e prato fica mais perto do que panela e minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cama', 0.9742375612258911)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('panela', topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81594384"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('panela', 'prato')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5390221"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('panela', 'minutos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar o skip-gram no lugar do CBoW, basta alterar o parâmetro `sg` para 1, conforme [documentação](https://radimrehurek.com/gensim/models/word2vec.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você quiser, pode salvar seu modelo para reutilizar posteriormente, ou retreiná-lo com novos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/americanas_cbow.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec.load(\"../models/americanas_cbow.model\")\n",
    "model.train([[\"hello\", \"world\"]], total_examples=1, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-grams Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biblioteca gensim possui uma classe chamada Phrases que automaticamente detecta frases comuns e cria tokens agrupando os tokens detectados com um demilitador _."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_reviews[\"review_text_cleaned\"].str.split(\" \").to_list()\n",
    "bigram_transformer = Phrases(sentences)\n",
    "bigram_model = Word2Vec(bigram_transformer[sentences], min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['antes_prazo', 'chegar_antes', 'super_rapir', 'custo_beneficio', 'ate_agora']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[key for key,_ in bigram_model.wv.key_to_index.items() if key not in model.wv.key_to_index.keys()][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do vocabulário com n gram: 42899\n",
      "Tamanho do vocabulário sem n gram: 39012\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Tamanho do vocabulário com n gram: {len(bigram_model.wv.key_to_index)}\n",
    "Tamanho do vocabulário sem n gram: {len(model.wv.key_to_index)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sempre precisamos analisar questões como bases enviesadas, mesmo em datasets onde não esperamos esse comportamento, como em comentário de produtos. Abaixo vemos um exemplo claro de viés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('familia', 0.9137730598449707)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model.wv.most_similar('mulher', topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('desafio', 0.9510673880577087)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model.wv.most_similar('homem', topn=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
